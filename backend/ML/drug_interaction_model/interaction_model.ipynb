{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36bfc29e",
   "metadata": {},
   "source": [
    "# Hybrid Drug–Drug Interaction Risk Model (Rules + ML)\n",
    "\n",
    "This notebook builds a safety-critical hybrid system:\n",
    "\n",
    "1) **Hard rule engine first** (non-negotiable overrides)\n",
    "2) **ML classifier second** (trained from `combos.json`)\n",
    "\n",
    "Outputs are **exactly** one of:\n",
    "- `Low Risk & Synergy`\n",
    "- `Low Risk & No Synergy`\n",
    "- `Low Risk & Decrease`\n",
    "- `Caution`\n",
    "- `Unsafe`\n",
    "- `Dangerous`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1714b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports loaded\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "print('✓ Imports loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a555222a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRUGS_PATH: C:\\Users\\USER\\dev\\code\\mobile_drug_use_app\\backend\\ML\\drugs.json\n",
      "COMBOS_PATH: C:\\Users\\USER\\dev\\code\\mobile_drug_use_app\\backend\\ML\\combos.json\n",
      "YAML_PATH: C:\\Users\\USER\\dev\\code\\mobile_drug_use_app\\backend\\ML\\drug_interaction_model\\drug_interaction.yaml\n",
      "✓ Paths set\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "HERE = Path.cwd()\n",
    "# This notebook lives at backend/ML/drug_interaction_model/interaction_model.ipynb\n",
    "# so ../drugs.json and ../combos.json are correct relative paths.\n",
    "DRUGS_PATH = Path('..') / 'drugs.json'\n",
    "COMBOS_PATH = Path('..') / 'combos.json'\n",
    "YAML_PATH = Path('drug_interaction.yaml')\n",
    "\n",
    "print('DRUGS_PATH:', DRUGS_PATH.resolve())\n",
    "print('COMBOS_PATH:', COMBOS_PATH.resolve())\n",
    "print('YAML_PATH:', YAML_PATH.resolve())\n",
    "print('✓ Paths set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26ed121a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Risk classes configured\n"
     ]
    }
   ],
   "source": [
    "# Fixed output classes (enum-like)\n",
    "RISK_CLASSES = [\n",
    "    'Low Risk & Synergy',\n",
    "    'Low Risk & No Synergy',\n",
    "    'Low Risk & Decrease',\n",
    "    'Caution',\n",
    "    'Unsafe',\n",
    "    'Dangerous',\n",
    "]\n",
    "RISK_CLASS_SET = set(RISK_CLASSES)\n",
    "\n",
    "# For guardrails: ensure we never downgrade rule-based results\n",
    "RISK_SEVERITY = {\n",
    "    'Low Risk & Synergy': 0,\n",
    "    'Low Risk & No Synergy': 0,\n",
    "    'Low Risk & Decrease': 0,\n",
    "    'Caution': 1,\n",
    "    'Unsafe': 2,\n",
    "    'Dangerous': 3,\n",
    "}\n",
    "\n",
    "def max_risk(a: str, b: str) -> str:\n",
    "    if a not in RISK_SEVERITY or b not in RISK_SEVERITY:\n",
    "        raise ValueError(f'Unknown risk class: {a} or {b}')\n",
    "    return a if RISK_SEVERITY[a] >= RISK_SEVERITY[b] else b\n",
    "\n",
    "print('✓ Risk classes configured')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9e2e9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded drugs.json entries: 551\n",
      "✓ Loaded combos.json root keys: 31\n",
      "Example drug key: 1,4-butanediol\n",
      "Example combo key: 2c-t-x\n"
     ]
    }
   ],
   "source": [
    "def load_json(path: Path) -> dict:\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "drugs_raw = load_json(DRUGS_PATH)\n",
    "combos_raw = load_json(COMBOS_PATH)\n",
    "\n",
    "print(f'✓ Loaded drugs.json entries: {len(drugs_raw)}')\n",
    "print(f'✓ Loaded combos.json root keys: {len(combos_raw)}')\n",
    "\n",
    "# quick peek\n",
    "some_drug = next(iter(drugs_raw.keys()))\n",
    "some_combo = next(iter(combos_raw.keys()))\n",
    "print('Example drug key:', some_drug)\n",
    "print('Example combo key:', some_combo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c9ca175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded drug_interaction.yaml config\n",
      "  exclude: 11 aliases: 11 groups: 10 separate: 1\n",
      "benzodiazepines -> None canon= benzodiazepines\n",
      "diazepam -> diazepam canon= benzodiazepines\n",
      "opioids -> None canon= opioids\n",
      "alcohol -> alcohol canon= alcohol\n",
      "ghb -> ghb canon= ghb\n",
      "ghb/gbl -> None canon= ghb/gbl\n",
      "maois -> None canon= maois\n",
      "ssris -> None canon= ssri\n",
      "ssri -> None canon= ssri\n",
      "amphetamines -> amphetamine canon= amphetamine\n",
      "amphetamine -> amphetamine canon= amphetamine\n"
     ]
    }
   ],
   "source": [
    "def normalize_name(name: str) -> str:\n",
    "    return (name or '').strip().lower()\n",
    "\n",
    "def load_yaml(path: Path) -> dict:\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        obj = yaml.safe_load(f)\n",
    "    return obj if isinstance(obj, dict) else {}\n",
    "\n",
    "INTERACTION_CFG = load_yaml(YAML_PATH) if YAML_PATH.exists() else {}\n",
    "\n",
    "EXCLUDE_SET = {normalize_name(x) for x in (INTERACTION_CFG.get('exclude') or []) if isinstance(x, str)}\n",
    "SEPARATE_SET = {normalize_name(x) for x in (INTERACTION_CFG.get('separate') or []) if isinstance(x, str)}\n",
    "ALIASES = {normalize_name(k): normalize_name(v) for k, v in (INTERACTION_CFG.get('aliases') or {}).items() if isinstance(k, str) and isinstance(v, str)}\n",
    "\n",
    "# Groups: map member -> canonical (unless member is in SEPARATE_SET). Also map the group key name itself -> canonical.\n",
    "GROUP_MEMBERS: Dict[str, set] = {}\n",
    "GROUP_CANONICAL_BY_MEMBER: Dict[str, str] = {}\n",
    "for group_name, g in (INTERACTION_CFG.get('groups') or {}).items():\n",
    "    if not isinstance(g, dict):\n",
    "        continue\n",
    "    group_norm = normalize_name(group_name)\n",
    "    canon = normalize_name(g.get('canonical', group_name))\n",
    "    members = set()\n",
    "    for m in (g.get('members') or []):\n",
    "        if isinstance(m, str):\n",
    "            members.add(normalize_name(m))\n",
    "    members.add(canon)\n",
    "    members.add(group_norm)\n",
    "    GROUP_MEMBERS[group_norm] = members\n",
    "    # group name itself -> canonical\n",
    "    if group_norm not in SEPARATE_SET:\n",
    "        GROUP_CANONICAL_BY_MEMBER[group_norm] = canon\n",
    "    for m in members:\n",
    "        if m in SEPARATE_SET:\n",
    "            continue\n",
    "        GROUP_CANONICAL_BY_MEMBER[m] = canon\n",
    "\n",
    "def is_excluded(name: str) -> bool:\n",
    "    return normalize_name(name) in EXCLUDE_SET\n",
    "\n",
    "def canonicalize_name(name: str) -> str:\n",
    "    \"\"\"Apply aliases + group merging; respect exclude + separate.\"\"\"\n",
    "    n = normalize_name(name)\n",
    "    if not n:\n",
    "        return n\n",
    "    # First, aliases\n",
    "    n = ALIASES.get(n, n)\n",
    "    # Keep 'separate' as-is (even if it appears in groups)\n",
    "    if n in SEPARATE_SET:\n",
    "        return n\n",
    "    # Then group merge\n",
    "    n = GROUP_CANONICAL_BY_MEMBER.get(n, n)\n",
    "    return n\n",
    "\n",
    "def in_group(name: str, group: str) -> bool:\n",
    "    g = normalize_name(group)\n",
    "    members = GROUP_MEMBERS.get(g)\n",
    "    if not members:\n",
    "        return False\n",
    "    return canonicalize_name(name) in members\n",
    "\n",
    "def drug_categories(drug_key: str, drugs: dict) -> List[str]:\n",
    "    entry = drugs.get(drug_key) or {}\n",
    "    cats = entry.get('categories') or []\n",
    "    return [normalize_name(c) for c in cats if isinstance(c, str)]\n",
    "\n",
    "# Map from normalized drugs.json key -> original key\n",
    "DRUG_KEY_BY_NORM = {normalize_name(k): k for k in drugs_raw.keys()}\n",
    "\n",
    "def resolve_drug_key(name: str) -> Optional[str]:\n",
    "    canon = canonicalize_name(name)\n",
    "    if is_excluded(canon):\n",
    "        return None\n",
    "    return DRUG_KEY_BY_NORM.get(canon) or DRUG_KEY_BY_NORM.get(normalize_name(name))\n",
    "\n",
    "print('✓ Loaded drug_interaction.yaml config')\n",
    "print('  exclude:', len(EXCLUDE_SET), 'aliases:', len(ALIASES), 'groups:', len(GROUP_MEMBERS), 'separate:', len(SEPARATE_SET))\n",
    "\n",
    "# sanity checks for group-ish keys used by combos.json\n",
    "for k in ['benzodiazepines', 'diazepam', 'opioids', 'alcohol', 'ghb', 'ghb/gbl', 'maois', 'ssris', 'ssri', 'amphetamines', 'amphetamine']:\n",
    "    print(k, '->', resolve_drug_key(k), 'canon=', canonicalize_name(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd6cef2",
   "metadata": {},
   "source": [
    "## Hard Rule Engine (runs first)\n",
    "\n",
    "Non-negotiable guardrails:\n",
    "- Benzodiazepines + opioids → **Dangerous**\n",
    "- Two CNS depressants (benzos, opioids, alcohol, GHB/GBL) → **minimum Unsafe**\n",
    "- MAOI + serotonergic drugs → **Dangerous**\n",
    "- Opioid + opioid → **minimum Unsafe**\n",
    "- GABAergic + GABAergic → **minimum Unsafe**\n",
    "\n",
    "If any rule triggers, we return immediately and skip ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d63adb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Rule engine ready\n"
     ]
    }
   ],
   "source": [
    "@dataclass(frozen=True)\n",
    "class RuleResult:\n",
    "    risk: str\n",
    "    reason: str\n",
    "\n",
    "def has_any(categories: List[str], needles: List[str]) -> bool:\n",
    "    s = set(categories)\n",
    "    return any(n in s for n in needles)\n",
    "\n",
    "def _identity_text(drug_key: str, drugs: dict) -> str:\n",
    "    \"\"\"Conservative: only use identity + declared categories (avoid scanning free-text that may mention other drugs).\"\"\"\n",
    "    entry = drugs.get(drug_key) or {}\n",
    "    cats = drug_categories(drug_key, drugs)\n",
    "    parts = [normalize_name(drug_key), normalize_name(entry.get('name', '')), normalize_name(entry.get('pretty_name', ''))]\n",
    "    parts.extend(cats)\n",
    "    return ' '.join([p for p in parts if p])\n",
    "\n",
    "def _pweffects_keys_text(drug_key: str, drugs: dict) -> str:\n",
    "    entry = drugs.get(drug_key) or {}\n",
    "    pwe = entry.get('pweffects') or {}\n",
    "    if isinstance(pwe, dict):\n",
    "        return ' '.join([normalize_name(k) for k in pwe.keys()])\n",
    "    return ''\n",
    "\n",
    "def _has_token(hay: str, tokens: List[str]) -> bool:\n",
    "    hay = hay.lower()\n",
    "    return any(normalize_name(t) in hay for t in tokens)\n",
    "\n",
    "def apply_hard_rules(drug_a: str, drug_b: str, drugs: dict) -> Optional[RuleResult]:\n",
    "    # Canonicalize first (aliases + group merging); keep 'separate' distinct\n",
    "    a_c = canonicalize_name(drug_a)\n",
    "    b_c = canonicalize_name(drug_b)\n",
    "\n",
    "    if is_excluded(a_c) or is_excluded(b_c):\n",
    "        return None\n",
    "\n",
    "    # Use drugs.json key if present; otherwise keep canonical string key\n",
    "    a_key = resolve_drug_key(a_c) or a_c\n",
    "    b_key = resolve_drug_key(b_c) or b_c\n",
    "\n",
    "    cats_a = drug_categories(a_key, drugs)\n",
    "    cats_b = drug_categories(b_key, drugs)\n",
    "\n",
    "    id_a = _identity_text(a_key, drugs)\n",
    "    id_b = _identity_text(b_key, drugs)\n",
    "    pwe_a = _pweffects_keys_text(a_key, drugs)\n",
    "    pwe_b = _pweffects_keys_text(b_key, drugs)\n",
    "\n",
    "    # Prefer YAML groups (more reliable than free-text/categories when present)\n",
    "    is_benzo_a = in_group(a_key, 'benzodiazepines') or has_any(cats_a, ['benzodiazepine', 'benzodiazepines']) or _has_token(id_a, ['benzodiazepine', 'benzodiazepines'])\n",
    "    is_benzo_b = in_group(b_key, 'benzodiazepines') or has_any(cats_b, ['benzodiazepine', 'benzodiazepines']) or _has_token(id_b, ['benzodiazepine', 'benzodiazepines'])\n",
    "    is_opioid_a = in_group(a_key, 'opioids') or has_any(cats_a, ['opioid', 'opioids']) or _has_token(id_a, ['opioid', 'opioids', 'opiate'])\n",
    "    is_opioid_b = in_group(b_key, 'opioids') or has_any(cats_b, ['opioid', 'opioids']) or _has_token(id_b, ['opioid', 'opioids', 'opiate'])\n",
    "    is_ghb_a = in_group(a_key, 'ghb') or normalize_name(a_key) in ['ghb', 'ghb/gbl', 'gbl']\n",
    "    is_ghb_b = in_group(b_key, 'ghb') or normalize_name(b_key) in ['ghb', 'ghb/gbl', 'gbl']\n",
    "    is_alcohol_a = normalize_name(a_key) == 'alcohol'\n",
    "    is_alcohol_b = normalize_name(b_key) == 'alcohol'\n",
    "\n",
    "    # MAOI is not in the YAML yet; keep conservative detection\n",
    "    is_maoi_a = normalize_name(a_key) in ['maois', 'maoi'] or has_any(cats_a, ['maoi', 'maois']) or _has_token(id_a, ['maoi', 'maois'])\n",
    "    is_maoi_b = normalize_name(b_key) in ['maois', 'maoi'] or has_any(cats_b, ['maoi', 'maois']) or _has_token(id_b, ['maoi', 'maois'])\n",
    "\n",
    "    # Serotonergic heuristic: SSRI group OR explicit serotonin mechanisms OR empathogen\n",
    "    is_ssri_a = in_group(a_key, 'ssris') or normalize_name(a_key) in ['ssri', 'ssris']\n",
    "    is_ssri_b = in_group(b_key, 'ssris') or normalize_name(b_key) in ['ssri', 'ssris']\n",
    "    is_serotonergic_a = (is_ssri_a\n",
    "                         or has_any(cats_a, ['serotonergic', 'empathogen', 'entactogen'])\n",
    "                         or _has_token(pwe_a, ['serotonin', '5-ht', '5ht']))\n",
    "    is_serotonergic_b = (is_ssri_b\n",
    "                         or has_any(cats_b, ['serotonergic', 'empathogen', 'entactogen'])\n",
    "                         or _has_token(pwe_b, ['serotonin', '5-ht', '5ht']))\n",
    "\n",
    "    # GABAergic heuristic: benzos/alcohol/GHB or explicit GABA mechanisms\n",
    "    is_gabaergic_a = is_benzo_a or is_alcohol_a or is_ghb_a or has_any(cats_a, ['gaba', 'gabaergic', 'depressant']) or _has_token(pwe_a, ['gaba'])\n",
    "    is_gabaergic_b = is_benzo_b or is_alcohol_b or is_ghb_b or has_any(cats_b, ['gaba', 'gabaergic', 'depressant']) or _has_token(pwe_b, ['gaba'])\n",
    "\n",
    "    # CNS depressants: benzos/opioids/alcohol/GHB or declared depressant\n",
    "    is_cns_dep_a = is_benzo_a or is_opioid_a or is_alcohol_a or is_ghb_a or has_any(cats_a, ['depressant'])\n",
    "    is_cns_dep_b = is_benzo_b or is_opioid_b or is_alcohol_b or is_ghb_b or has_any(cats_b, ['depressant'])\n",
    "\n",
    "    # 1) Benzodiazepines + opioids → always Dangerous\n",
    "    if (is_benzo_a and is_opioid_b) or (is_benzo_b and is_opioid_a):\n",
    "        return RuleResult('Dangerous', 'Hard rule: Benzodiazepines + opioids')\n",
    "\n",
    "    # 2) MAOI + serotonergic → always Dangerous\n",
    "    if (is_maoi_a and is_serotonergic_b) or (is_maoi_b and is_serotonergic_a):\n",
    "        return RuleResult('Dangerous', 'Hard rule: MAOI + serotonergic')\n",
    "\n",
    "    # 3) Opioid + opioid → minimum Unsafe\n",
    "    if is_opioid_a and is_opioid_b:\n",
    "        return RuleResult('Unsafe', 'Hard rule: Opioid + opioid (min Unsafe)')\n",
    "\n",
    "    # 4) GABAergic + GABAergic → minimum Unsafe\n",
    "    if is_gabaergic_a and is_gabaergic_b:\n",
    "        return RuleResult('Unsafe', 'Hard rule: GABAergic + GABAergic (min Unsafe)')\n",
    "\n",
    "    # 5) Two CNS depressants → minimum Unsafe\n",
    "    if is_cns_dep_a and is_cns_dep_b:\n",
    "        return RuleResult('Unsafe', 'Hard rule: CNS depressant stacking (min Unsafe)')\n",
    "\n",
    "    return None\n",
    "\n",
    "print('✓ Rule engine ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca6e3ce",
   "metadata": {},
   "source": [
    "## Training Schema from combos.json\n",
    "\n",
    "`combos.json` is a nested mapping: `combos[a][b].status`.\n",
    "We flatten it into a dataset of `(drug_a, drug_b, label)` and derive features using `drugs.json` categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70b64c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Flattened labeled pairs (after canonicalization/exclude): 839\n",
      "✓ Kept pairs with valid labels: 839\n",
      "✓ Undirected merged pairs: 392 | conflicts resolved: 34\n",
      "label\n",
      "Caution                  102\n",
      "Low Risk & Synergy        97\n",
      "Dangerous                 74\n",
      "Low Risk & Decrease       47\n",
      "Unsafe                    44\n",
      "Low Risk & No Synergy     28\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drug_a</th>\n",
       "      <th>drug_b</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2c-t-x</td>\n",
       "      <td>2c-x</td>\n",
       "      <td>Caution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2c-t-x</td>\n",
       "      <td>5-meo-xxt</td>\n",
       "      <td>Caution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2c-t-x</td>\n",
       "      <td>alcohol</td>\n",
       "      <td>Low Risk &amp; Decrease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2c-t-x</td>\n",
       "      <td>amphetamine</td>\n",
       "      <td>Unsafe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2c-t-x</td>\n",
       "      <td>amt</td>\n",
       "      <td>Dangerous</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   drug_a       drug_b                label\n",
       "0  2c-t-x         2c-x              Caution\n",
       "1  2c-t-x    5-meo-xxt              Caution\n",
       "2  2c-t-x      alcohol  Low Risk & Decrease\n",
       "3  2c-t-x  amphetamine               Unsafe\n",
       "4  2c-t-x          amt            Dangerous"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def flatten_combos(combos: dict) -> List[Tuple[str, str, str]]:\n",
    "    rows: List[Tuple[str, str, str]] = []\n",
    "    for a, inner in combos.items():\n",
    "        if not isinstance(inner, dict):\n",
    "            continue\n",
    "        for b, obj in inner.items():\n",
    "            if not isinstance(obj, dict):\n",
    "                continue\n",
    "            status = obj.get('status')\n",
    "            if not isinstance(status, str):\n",
    "                continue\n",
    "            a_c = canonicalize_name(a)\n",
    "            b_c = canonicalize_name(b)\n",
    "            if not a_c or not b_c:\n",
    "                continue\n",
    "            if is_excluded(a_c) or is_excluded(b_c):\n",
    "                continue\n",
    "            if a_c == b_c:\n",
    "                continue\n",
    "            rows.append((a_c, b_c, status.strip()))\n",
    "    return rows\n",
    "\n",
    "pairs = flatten_combos(combos_raw)\n",
    "print('✓ Flattened labeled pairs (after canonicalization/exclude):', len(pairs))\n",
    "\n",
    "# keep only the fixed classes\n",
    "pairs = [(a, b, y) for (a, b, y) in pairs if y in RISK_CLASS_SET]\n",
    "print('✓ Kept pairs with valid labels:', len(pairs))\n",
    "\n",
    "# Merge any conflicts introduced by canonicalization by keeping the most severe label per undirected pair\n",
    "merged: Dict[Tuple[str, str], str] = {}\n",
    "conflicts = 0\n",
    "for a, b, y in pairs:\n",
    "    k = tuple(sorted([a, b]))\n",
    "    if k not in merged:\n",
    "        merged[k] = y\n",
    "        continue\n",
    "    if merged[k] != y:\n",
    "        conflicts += 1\n",
    "        merged[k] = max_risk(merged[k], y)\n",
    "pairs = [(a, b, y) for (a, b), y in merged.items()]\n",
    "print('✓ Undirected merged pairs:', len(pairs), '| conflicts resolved:', conflicts)\n",
    "\n",
    "df_pairs = pd.DataFrame(pairs, columns=['drug_a', 'drug_b', 'label'])\n",
    "print(df_pairs['label'].value_counts())\n",
    "df_pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a95cb6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Feature dicts: 392\n",
      "✓ Example feature keys: ['pair:2c-t-x|2c-x', 'pair:2c-x|2c-t-x', 'is_benzo_opioid', 'is_cns_dep_stack']\n"
     ]
    }
   ],
   "source": [
    "def make_features(drug_a: str, drug_b: str, drugs: dict) -> Dict[str, float]:\n",
    "    a_c = canonicalize_name(drug_a)\n",
    "    b_c = canonicalize_name(drug_b)\n",
    "\n",
    "    a_key = resolve_drug_key(a_c) or a_c\n",
    "    b_key = resolve_drug_key(b_c) or b_c\n",
    "\n",
    "    cats_a = set(drug_categories(a_key, drugs))\n",
    "    cats_b = set(drug_categories(b_key, drugs))\n",
    "\n",
    "    feats: Dict[str, float] = {}\n",
    "    # category indicator features\n",
    "    for c in cats_a:\n",
    "        feats[f'a_cat:{c}'] = 1.0\n",
    "    for c in cats_b:\n",
    "        feats[f'b_cat:{c}'] = 1.0\n",
    "    for c in (cats_a & cats_b):\n",
    "        feats[f'both_cat:{c}'] = 1.0\n",
    "\n",
    "    # pair identity (learn frequent exact pairs; use canonicalized names)\n",
    "    feats[f'pair:{a_c}|{b_c}'] = 1.0\n",
    "    feats[f'pair:{b_c}|{a_c}'] = 1.0\n",
    "\n",
    "    # archetype flags (rules still override; these just help ML when rules don't trigger)\n",
    "    feats['is_benzo_opioid'] = float(\n",
    "        (in_group(a_key, 'benzodiazepines') and in_group(b_key, 'opioids'))\n",
    "        or (in_group(b_key, 'benzodiazepines') and in_group(a_key, 'opioids'))\n",
    "    )\n",
    "    feats['is_cns_dep_stack'] = float(\n",
    "        (in_group(a_key, 'benzodiazepines') or in_group(a_key, 'opioids') or normalize_name(a_key) == 'alcohol' or in_group(a_key, 'ghb'))\n",
    "        and (in_group(b_key, 'benzodiazepines') or in_group(b_key, 'opioids') or normalize_name(b_key) == 'alcohol' or in_group(b_key, 'ghb'))\n",
    "    )\n",
    "\n",
    "    return feats\n",
    "\n",
    "# Build training matrices\n",
    "X_dicts = [make_features(a, b, drugs_raw) for (a, b, _) in pairs]\n",
    "y = [label for (_, _, label) in pairs]\n",
    "\n",
    "print('✓ Feature dicts:', len(X_dicts))\n",
    "print('✓ Example feature keys:', list(X_dicts[0].keys())[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a423107",
   "metadata": {},
   "source": [
    "## ML Classifier (runs only if rules don’t trigger)\n",
    "\n",
    "We use a deterministic multiclass `LogisticRegression` (good interpretability + fast)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5157171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Trained ML classifier\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "   Low Risk & Synergy       0.75      0.32      0.44        19\n",
      "Low Risk & No Synergy       0.40      0.33      0.36         6\n",
      "  Low Risk & Decrease       0.25      0.78      0.38         9\n",
      "              Caution       0.50      0.19      0.28        21\n",
      "               Unsafe       0.09      0.22      0.13         9\n",
      "            Dangerous       0.25      0.13      0.17        15\n",
      "\n",
      "             accuracy                           0.29        79\n",
      "            macro avg       0.37      0.33      0.29        79\n",
      "         weighted avg       0.43      0.29      0.30        79\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_dicts, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "clf: Pipeline = Pipeline([\n",
    "    ('vec', DictVectorizer(sparse=True)),\n",
    "    ('lr', LogisticRegression(\n",
    "        solver='lbfgs',\n",
    "        max_iter=500,\n",
    "        random_state=RANDOM_STATE,\n",
    "        class_weight='balanced',\n",
    "    )),\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "print('✓ Trained ML classifier')\n",
    "print(classification_report(y_test, pred, labels=RISK_CLASSES, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73ad17b",
   "metadata": {},
   "source": [
    "## Resolver: Rules + ML (safe composition)\n",
    "\n",
    "- If a hard rule triggers: return immediately.\n",
    "- Otherwise: use ML prediction.\n",
    "- Always return one of the fixed strings.\n",
    "- Provide an explanation: rule reason OR top contributing features (log-reg coefficients × feature values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6def7746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Resolver ready\n"
     ]
    }
   ],
   "source": [
    "def explain_logreg_top_features(pipeline: Pipeline, x_dict: Dict[str, float], top_k: int = 8) -> List[Tuple[str, float]]:\n",
    "    vec: DictVectorizer = pipeline.named_steps['vec']\n",
    "    lr: LogisticRegression = pipeline.named_steps['lr']\n",
    "\n",
    "    X = vec.transform([x_dict])  # sparse row\n",
    "    feature_names = np.array(vec.get_feature_names_out())\n",
    "\n",
    "    proba = lr.predict_proba(X)[0]\n",
    "    class_idx = int(np.argmax(proba))\n",
    "    class_name = lr.classes_[class_idx]\n",
    "\n",
    "    coef = lr.coef_[class_idx]\n",
    "    X_dense = X.toarray()[0]\n",
    "    contrib = coef * X_dense\n",
    "    top_idx = np.argsort(np.abs(contrib))[::-1][:top_k]\n",
    "\n",
    "    items = [(feature_names[i], float(contrib[i])) for i in top_idx if X_dense[i] != 0]\n",
    "    return [(f'{class_name} :: {k}', v) for (k, v) in items]\n",
    "\n",
    "def predict_hybrid(drug_a: str, drug_b: str, drugs: dict, model: Pipeline) -> dict:\n",
    "    a_c = canonicalize_name(drug_a)\n",
    "    b_c = canonicalize_name(drug_b)\n",
    "    if is_excluded(a_c) or is_excluded(b_c):\n",
    "        raise ValueError(f'Excluded substance in prediction: {drug_a} or {drug_b}')\n",
    "\n",
    "    rr = apply_hard_rules(a_c, b_c, drugs)\n",
    "    if rr is not None:\n",
    "        if rr.risk not in RISK_CLASS_SET:\n",
    "            raise ValueError(f'Rule produced invalid risk: {rr.risk}')\n",
    "        return {\n",
    "            'drug_a': a_c,\n",
    "            'drug_b': b_c,\n",
    "            'risk': rr.risk,\n",
    "            'source': 'rules',\n",
    "            'reason': rr.reason,\n",
    "            'explanation': [rr.reason],\n",
    "        }\n",
    "\n",
    "    x = make_features(a_c, b_c, drugs)\n",
    "    pred = model.predict([x])[0]\n",
    "    if pred not in RISK_CLASS_SET:\n",
    "        raise ValueError(f'Model produced invalid risk: {pred}')\n",
    "\n",
    "    proba = model.predict_proba([x])[0]\n",
    "    classes = list(model.named_steps['lr'].classes_)\n",
    "    conf = float(np.max(proba))\n",
    "\n",
    "    top = explain_logreg_top_features(model, x, top_k=10)\n",
    "    return {\n",
    "        'drug_a': a_c,\n",
    "        'drug_b': b_c,\n",
    "        'risk': pred,\n",
    "        'source': 'ml',\n",
    "        'confidence': conf,\n",
    "        'class_probs': {classes[i]: float(proba[i]) for i in range(len(classes))},\n",
    "        'explanation': [f'{k}: {v:+.4f}' for (k, v) in top],\n",
    "    }\n",
    "\n",
    "print('✓ Resolver ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29697801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================\n",
      "benzodiazepines + opioids -> Dangerous  (source=rules)\n",
      "Reason: Hard rule: Benzodiazepines + opioids\n",
      "\n",
      "========================================================================\n",
      "alcohol + benzodiazepines -> Unsafe  (source=rules)\n",
      "Reason: Hard rule: GABAergic + GABAergic (min Unsafe)\n",
      "\n",
      "========================================================================\n",
      "opioids + opioids -> Unsafe  (source=rules)\n",
      "Reason: Hard rule: Opioid + opioid (min Unsafe)\n",
      "\n",
      "========================================================================\n",
      "maois + ssris -> Dangerous  (source=rules)\n",
      "Reason: Hard rule: MAOI + serotonergic\n",
      "\n",
      "========================================================================\n",
      "cannabis + caffeine -> Low Risk & No Synergy  (source=ml)\n",
      "Confidence: 0.582\n",
      "   Low Risk & No Synergy :: b_cat:nootropic: +1.2879\n",
      "   Low Risk & No Synergy :: a_cat:stimulant: +0.9851\n",
      "   Low Risk & No Synergy :: a_cat:psychedelic: -0.7068\n",
      "   Low Risk & No Synergy :: pair:cannabis|caffeine: +0.5998\n",
      "   Low Risk & No Synergy :: pair:caffeine|cannabis: +0.5998\n",
      "   Low Risk & No Synergy :: both_cat:habit-forming: -0.4804\n",
      "\n",
      "========================================================================\n",
      "lsd + cannabis -> Low Risk & Synergy  (source=ml)\n",
      "Confidence: 0.591\n",
      "   Low Risk & Synergy :: a_cat:psychedelic: +1.7090\n",
      "   Low Risk & Synergy :: b_cat:psychedelic: +1.3133\n",
      "   Low Risk & Synergy :: b_cat:common: +0.7232\n",
      "   Low Risk & Synergy :: b_cat:stimulant: -0.7225\n",
      "   Low Risk & Synergy :: both_cat:psychedelic: +0.5793\n",
      "   Low Risk & Synergy :: a_cat:common: +0.5551\n",
      "\n",
      "========================================================================\n",
      "mdma + alcohol -> Unsafe  (source=ml)\n",
      "Confidence: 0.654\n",
      "   Unsafe :: both_cat:habit-forming: +0.7763\n",
      "   Unsafe :: b_cat:depressant: +0.6866\n",
      "   Unsafe :: a_cat:psychedelic: -0.5950\n",
      "   Unsafe :: a_cat:empathogen: +0.4742\n",
      "   Unsafe :: b_cat:habit-forming: +0.4021\n",
      "   Unsafe :: a_cat:habit-forming: +0.3338\n",
      "\n",
      "✓ Sanity tests complete\n"
     ]
    }
   ],
   "source": [
    "# Sanity tests\n",
    "tests = [\n",
    "    # should trigger hard rules\n",
    "    ('benzodiazepines', 'opioids'),\n",
    "    ('alcohol', 'benzodiazepines'),\n",
    "    ('opioids', 'opioids'),\n",
    "    ('maois', 'ssris'),\n",
    "    # should likely fall back to ML\n",
    "    ('cannabis', 'caffeine'),\n",
    "    ('lsd', 'cannabis'),\n",
    "    ('mdma', 'alcohol'),\n",
    "]\n",
    "\n",
    "for a, b in tests:\n",
    "    out = predict_hybrid(a, b, drugs_raw, clf)\n",
    "    print('\\n' + '='*72)\n",
    "    print(f'{a} + {b} -> {out[\"risk\"]}  (source={out[\"source\"]})')\n",
    "    if out['source'] == 'rules':\n",
    "        print('Reason:', out['reason'])\n",
    "    else:\n",
    "        print('Confidence:', f\"{out['confidence']:.3f}\")\n",
    "        for line in out['explanation'][:6]:\n",
    "            print('  ', line)\n",
    "\n",
    "print('\\n✓ Sanity tests complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea7c62b",
   "metadata": {},
   "source": [
    "## Export: all pairwise combinations to JSON\n",
    "\n",
    "This will evaluate **every substance vs every other substance** (undirected pairs) using the hybrid resolver and write a JSON file grouped by risk class.\n",
    "\n",
    "Note: with ~551 substances, this is ~151k pairs and can take a few minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a17cd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... 10/60 substances processed | 545/1770 pairs | 1,120 pairs/s\n",
      "... 20/60 substances processed | 990/1770 pairs | 1,131 pairs/s\n",
      "... 30/60 substances processed | 1335/1770 pairs | 1,128 pairs/s\n",
      "... 40/60 substances processed | 1580/1770 pairs | 1,126 pairs/s\n",
      "... 50/60 substances processed | 1725/1770 pairs | 1,128 pairs/s\n",
      "... 60/60 substances processed | 1770/1770 pairs | 1,130 pairs/s\n",
      "\n",
      "✓ Wrote: C:\\Users\\USER\\dev\\code\\mobile_drug_use_app\\backend\\ML\\drug_interaction_model\\outputs\\pairwise_risks_by_class.json\n",
      "Counts:\n",
      "  Low Risk & Synergy   593\n",
      "  Low Risk & No Synergy 0\n",
      "  Low Risk & Decrease  7\n",
      "  Caution              47\n",
      "  Unsafe               6\n",
      "  Dangerous            1117\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timezone\n",
    "\n",
    "def list_export_substances(drugs: dict) -> List[str]:\n",
    "    # Start from drugs.json keys, canonicalize, exclude, and make unique\n",
    "    keys = set()\n",
    "    for k in drugs.keys():\n",
    "        c = canonicalize_name(k)\n",
    "        if not c or is_excluded(c):\n",
    "            continue\n",
    "        keys.add(c)\n",
    "    # Also include canonical group targets and alias targets (even if not present in drugs.json)\n",
    "    for c in set(GROUP_CANONICAL_BY_MEMBER.values()):\n",
    "        if c and not is_excluded(c):\n",
    "            keys.add(c)\n",
    "    for v in ALIASES.values():\n",
    "        c = canonicalize_name(v)\n",
    "        if c and not is_excluded(c):\n",
    "            keys.add(c)\n",
    "    return sorted(keys)\n",
    "\n",
    "def export_all_pairwise_risks(\n",
    "    output_path: Path = Path('outputs') / 'pairwise_risks_by_class.json',\n",
    "    max_substances: Optional[int] = None,\n",
    "    progress_every: int = 25,\n",
    "    include_groups_only_if_present_in_drugs_json: bool = False,\n",
    " ):\n",
    "    \"\"\"\n",
    "    Export all undirected pairs to JSON grouped by risk class.\n",
    "\n",
    "    Output format:\n",
    "    {\n",
    "      \"generated_at\": \"...\",\n",
    "      \"n_substances\": 551,\n",
    "      \"n_pairs\": 151525,\n",
    "      \"counts\": {\"Caution\": 123, ...},\n",
    "      \"pairs_by_risk\": {\n",
    "        \"Dangerous\": [[\"a\",\"b\"], ...],\n",
    "        ...\n",
    "      }\n",
    "    }\n",
    "    \"\"\"\n",
    "    keys = list_export_substances(drugs_raw)\n",
    "    if include_groups_only_if_present_in_drugs_json:\n",
    "        present = {normalize_name(k) for k in drugs_raw.keys()}\n",
    "        keys = [k for k in keys if normalize_name(k) in present]\n",
    "    if max_substances is not None:\n",
    "        keys = keys[:max_substances]\n",
    "\n",
    "    n = len(keys)\n",
    "    total_pairs = n * (n - 1) // 2\n",
    "    pairs_by_risk = {risk: [] for risk in RISK_CLASSES}\n",
    "\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    processed = 0\n",
    "    started = datetime.now(timezone.utc)\n",
    "\n",
    "    for i in range(n):\n",
    "        a = keys[i]\n",
    "        for j in range(i + 1, n):\n",
    "            b = keys[j]\n",
    "            risk = predict_hybrid(a, b, drugs_raw, clf)['risk']\n",
    "            pairs_by_risk[risk].append([a, b])\n",
    "            processed += 1\n",
    "\n",
    "        if progress_every and (i + 1) % progress_every == 0:\n",
    "            elapsed = (datetime.now(timezone.utc) - started).total_seconds()\n",
    "            rate = processed / elapsed if elapsed > 0 else 0.0\n",
    "            print(f'... {i+1}/{n} substances processed | {processed}/{total_pairs} pairs | {rate:,.0f} pairs/s')\n",
    "\n",
    "    counts = {risk: len(pairs_by_risk[risk]) for risk in RISK_CLASSES}\n",
    "    payload = {\n",
    "        'generated_at': datetime.now(timezone.utc).isoformat(),\n",
    "        'n_substances': n,\n",
    "        'n_pairs': total_pairs,\n",
    "        'risk_classes': list(RISK_CLASSES),\n",
    "        'counts': counts,\n",
    "        'pairs_by_risk': pairs_by_risk,\n",
    "        'config': {\n",
    "            'yaml_path': str(YAML_PATH),\n",
    "            'exclude': sorted(EXCLUDE_SET),\n",
    "            'aliases': ALIASES,\n",
    "            'groups': {k: {'canonical': canonicalize_name(v.get('canonical', k))} for k, v in (INTERACTION_CFG.get('groups') or {}).items() if isinstance(v, dict)},\n",
    "            'separate': sorted(SEPARATE_SET),\n",
    "        },\n",
    "        'notes': 'Pairs are undirected (a,b) checked once; substances are canonicalized via drug_interaction.yaml before prediction.',\n",
    "    }\n",
    "\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(payload, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    return output_path, counts\n",
    "\n",
    "\n",
    "# Quick test export (set to None for full)\n",
    "out_path, out_counts = export_all_pairwise_risks(max_substances=60, progress_every=10)\n",
    "print('\\n✓ Wrote:', out_path.resolve())\n",
    "print('Counts:')\n",
    "for k, v in out_counts.items():\n",
    "    print(f'  {k:20} {v}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
