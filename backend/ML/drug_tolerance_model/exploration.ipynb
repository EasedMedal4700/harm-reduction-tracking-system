{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fdb529",
   "metadata": {
    "vscode": {
     "languageId": "code"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e1f227",
   "metadata": {},
   "source": [
    "## Step 1: Load Drug Profiles with Tolerance Data\n",
    "\n",
    "Load substances that have documented tolerance models.\n",
    "\n",
    "Expected tolerance parameters:\n",
    "- **Neuro bucket weights**: How much each mechanism contributes to tolerance\n",
    "- **Tolerance gain rate**: How quickly tolerance builds (0.5 = slow, 1.0 = normal, 2.0 = fast)\n",
    "- **Tolerance decay days**: Time for tolerance to reset (7-90 days typical)\n",
    "- **Cross-tolerance patterns**: Which substances share tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63de2e79",
   "metadata": {
    "vscode": {
     "languageId": "code"
    }
   },
   "outputs": [],
   "source": [
    "def load_tolerance_data(data_path='../../data_collector/processed/tolerance_models.json'):\n",
    "    \"\"\"\n",
    "    Load documented tolerance models.\n",
    "    \n",
    "    Expected structure:\n",
    "    {\n",
    "        \"MDMA\": {\n",
    "            \"neuro_buckets\": {\n",
    "                \"serotonin_release\": {\"weight\": 0.9},\n",
    "                \"dopamine_release\": {\"weight\": 0.3},\n",
    "                \"stimulant\": {\"weight\": 0.6}\n",
    "            },\n",
    "            \"tolerance_gain_rate\": 1.0,\n",
    "            \"tolerance_decay_days\": 90,\n",
    "            \"half_life_hours\": 8,\n",
    "            \"duration_hours\": 6,\n",
    "            \"categories\": [\"stimulant\", \"entactogen\"],\n",
    "            \"model_origin\": \"manual\",\n",
    "            \"confidence\": \"High\"\n",
    "        }\n",
    "    }\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(data_path, 'r') as f:\n",
    "            tolerance_data = json.load(f)\n",
    "        print(f\"✓ Loaded {len(tolerance_data)} tolerance models\")\n",
    "        return tolerance_data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"⚠ File not found: {data_path}\")\n",
    "        print(\"Creating synthetic sample tolerance data...\")\n",
    "        return create_sample_tolerance_data()\n",
    "\n",
    "def create_sample_tolerance_data():\n",
    "    \"\"\"Create sample tolerance models for demonstration\"\"\"\n",
    "    return {\n",
    "        \"MDMA\": {\n",
    "            \"neuro_buckets\": {\n",
    "                \"serotonin_release\": {\"weight\": 0.9},\n",
    "                \"dopamine_release\": {\"weight\": 0.3},\n",
    "                \"stimulant\": {\"weight\": 0.6}\n",
    "            },\n",
    "            \"tolerance_gain_rate\": 1.0,\n",
    "            \"tolerance_decay_days\": 90,\n",
    "            \"half_life_hours\": 8,\n",
    "            \"duration_hours\": 6,\n",
    "            \"categories\": [\"stimulant\", \"entactogen\"],\n",
    "            \"model_origin\": \"manual\",\n",
    "            \"confidence\": \"High\"\n",
    "        },\n",
    "        \"LSD\": {\n",
    "            \"neuro_buckets\": {\n",
    "                \"serotonin_agonist\": {\"weight\": 0.95},\n",
    "                \"dopamine_modulation\": {\"weight\": 0.2}\n",
    "            },\n",
    "            \"tolerance_gain_rate\": 2.0,\n",
    "            \"tolerance_decay_days\": 14,\n",
    "            \"half_life_hours\": 5,\n",
    "            \"duration_hours\": 12,\n",
    "            \"categories\": [\"psychedelic\"],\n",
    "            \"model_origin\": \"manual\",\n",
    "            \"confidence\": \"High\"\n",
    "        },\n",
    "        \"Psilocybin\": {\n",
    "            \"neuro_buckets\": {\n",
    "                \"serotonin_agonist\": {\"weight\": 0.9}\n",
    "            },\n",
    "            \"tolerance_gain_rate\": 2.0,\n",
    "            \"tolerance_decay_days\": 7,\n",
    "            \"half_life_hours\": 3,\n",
    "            \"duration_hours\": 6,\n",
    "            \"categories\": [\"psychedelic\"],\n",
    "            \"model_origin\": \"manual\",\n",
    "            \"confidence\": \"High\"\n",
    "        },\n",
    "        \"Amphetamine\": {\n",
    "            \"neuro_buckets\": {\n",
    "                \"dopamine_release\": {\"weight\": 0.8},\n",
    "                \"stimulant\": {\"weight\": 0.9}\n",
    "            },\n",
    "            \"tolerance_gain_rate\": 1.5,\n",
    "            \"tolerance_decay_days\": 21,\n",
    "            \"half_life_hours\": 10,\n",
    "            \"duration_hours\": 8,\n",
    "            \"categories\": [\"stimulant\"],\n",
    "            \"model_origin\": \"manual\",\n",
    "            \"confidence\": \"High\"\n",
    "        },\n",
    "        \"Cocaine\": {\n",
    "            \"neuro_buckets\": {\n",
    "                \"dopamine_reuptake\": {\"weight\": 0.9},\n",
    "                \"stimulant\": {\"weight\": 0.95}\n",
    "            },\n",
    "            \"tolerance_gain_rate\": 1.2,\n",
    "            \"tolerance_decay_days\": 14,\n",
    "            \"half_life_hours\": 1,\n",
    "            \"duration_hours\": 2,\n",
    "            \"categories\": [\"stimulant\"],\n",
    "            \"model_origin\": \"manual\",\n",
    "            \"confidence\": \"High\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Load tolerance data\n",
    "tolerance_data = load_tolerance_data()\n",
    "print(f\"\\nSubstances with tolerance models: {list(tolerance_data.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8e9460",
   "metadata": {},
   "source": [
    "## Step 2: Extract Tolerance-Relevant Features\n",
    "\n",
    "Extract features that correlate with tolerance development patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0703b3dc",
   "metadata": {
    "vscode": {
     "languageId": "code"
    }
   },
   "outputs": [],
   "source": [
    "def extract_tolerance_features(substance_data):\n",
    "    \"\"\"\n",
    "    Extract features relevant to tolerance modeling.\n",
    "    \n",
    "    Returns both:\n",
    "    - Input features (X): mechanism profile, pharmacokinetics\n",
    "    - Target values (y): tolerance parameters to predict\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    targets = {}\n",
    "    \n",
    "    # Neurotransmitter bucket weights (input features)\n",
    "    neuro_buckets = substance_data.get('neuro_buckets', {})\n",
    "    for bucket in ['serotonin_release', 'serotonin_agonist', 'dopamine_release', \n",
    "                   'dopamine_reuptake', 'dopamine_modulation', 'gaba_positive', \n",
    "                   'nmda_antagonist', 'stimulant', 'cb1_agonist', 'opioid']:\n",
    "        weight = neuro_buckets.get(bucket, {}).get('weight', 0.0) if isinstance(neuro_buckets.get(bucket), dict) else neuro_buckets.get(bucket, 0.0)\n",
    "        features[f'neuro_{bucket}'] = weight\n",
    "    \n",
    "    # Pharmacokinetics (input features)\n",
    "    features['half_life_hours'] = substance_data.get('half_life_hours', 0)\n",
    "    features['duration_hours'] = substance_data.get('duration_hours', 0)\n",
    "    \n",
    "    # Category indicators (input features)\n",
    "    categories = substance_data.get('categories', [])\n",
    "    for cat in ['stimulant', 'depressant', 'psychedelic', 'entactogen', 'dissociative']:\n",
    "        features[f'cat_{cat}'] = 1 if cat in categories else 0\n",
    "    \n",
    "    # Tolerance parameters (target values to predict)\n",
    "    targets['tolerance_gain_rate'] = substance_data.get('tolerance_gain_rate', 1.0)\n",
    "    targets['tolerance_decay_days'] = substance_data.get('tolerance_decay_days', 28)\n",
    "    \n",
    "    return features, targets\n",
    "\n",
    "# Extract features for all substances with tolerance models\n",
    "X_data = []\n",
    "y_gain_rate = []\n",
    "y_decay_days = []\n",
    "substance_names = []\n",
    "\n",
    "for substance_name, data in tolerance_data.items():\n",
    "    features, targets = extract_tolerance_features(data)\n",
    "    X_data.append(features)\n",
    "    y_gain_rate.append(targets['tolerance_gain_rate'])\n",
    "    y_decay_days.append(targets['tolerance_decay_days'])\n",
    "    substance_names.append(substance_name)\n",
    "\n",
    "X_df = pd.DataFrame(X_data)\n",
    "y_gain_rate = np.array(y_gain_rate)\n",
    "y_decay_days = np.array(y_decay_days)\n",
    "\n",
    "print(f\"✓ Extracted features for {len(X_df)} substances\")\n",
    "print(f\"Feature dimensions: {X_df.shape}\")\n",
    "print(f\"\\nTarget statistics:\")\n",
    "print(f\"  Gain rate: min={y_gain_rate.min():.2f}, max={y_gain_rate.max():.2f}, mean={y_gain_rate.mean():.2f}\")\n",
    "print(f\"  Decay days: min={y_decay_days.min():.0f}, max={y_decay_days.max():.0f}, mean={y_decay_days.mean():.0f}\")\n",
    "print(\"\\nSample data:\")\n",
    "X_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269214a6",
   "metadata": {},
   "source": [
    "## Step 3: Train K-Nearest Neighbors Regressor\n",
    "\n",
    "Use KNN to predict tolerance parameters based on mechanism similarity to known substances.\n",
    "\n",
    "KNN is ideal here because:\n",
    "- Interpretable: \"similar to X, Y, Z\"\n",
    "- Naturally handles mechanism similarity\n",
    "- Conservative: averages nearby known values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5650cc8",
   "metadata": {
    "vscode": {
     "languageId": "code"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_df)\n",
    "\n",
    "# Train KNN for tolerance gain rate\n",
    "knn_gain = KNeighborsRegressor(n_neighbors=3, weights='distance')\n",
    "knn_gain.fit(X_scaled, y_gain_rate)\n",
    "\n",
    "# Train KNN for tolerance decay days\n",
    "knn_decay = KNeighborsRegressor(n_neighbors=3, weights='distance')\n",
    "knn_decay.fit(X_scaled, y_decay_days)\n",
    "\n",
    "# Cross-validation scores\n",
    "cv_gain = cross_val_score(knn_gain, X_scaled, y_gain_rate, cv=3, scoring='r2')\n",
    "cv_decay = cross_val_score(knn_decay, X_scaled, y_decay_days, cv=3, scoring='r2')\n",
    "\n",
    "print(\"✓ Models trained successfully\")\n",
    "print(f\"\\nCross-validation R² scores:\")\n",
    "print(f\"  Gain rate: {cv_gain.mean():.3f} ± {cv_gain.std():.3f}\")\n",
    "print(f\"  Decay days: {cv_decay.mean():.3f} ± {cv_decay.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379ec0fb",
   "metadata": {},
   "source": [
    "## Step 4: Implement Tolerance Inference Function\n",
    "\n",
    "Create a function that estimates tolerance parameters for substances without documented models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7797cc3",
   "metadata": {
    "vscode": {
     "languageId": "code"
    }
   },
   "outputs": [],
   "source": [
    "def estimate_tolerance_model(substance_profile, \n",
    "                            tolerance_data, \n",
    "                            scaler, \n",
    "                            knn_gain, \n",
    "                            knn_decay,\n",
    "                            X_df,\n",
    "                            substance_names):\n",
    "    \"\"\"\n",
    "    Estimate tolerance model for a substance using ML inference.\n",
    "    \n",
    "    Returns:\n",
    "    {\n",
    "        \"model_origin\": \"ml_inferred\",\n",
    "        \"confidence\": str,\n",
    "        \"confidence_score\": float,\n",
    "        \"derived_from\": list[str],\n",
    "        \"neuro_buckets\": dict,\n",
    "        \"tolerance_gain_rate\": float,\n",
    "        \"tolerance_decay_days\": int,\n",
    "        \"notes\": str\n",
    "    }\n",
    "    \"\"\"\n",
    "    # Extract features from substance profile\n",
    "    features, _ = extract_tolerance_features(substance_profile)\n",
    "    X_new = pd.DataFrame([features])\n",
    "    \n",
    "    # Ensure all columns match training data\n",
    "    for col in X_df.columns:\n",
    "        if col not in X_new.columns:\n",
    "            X_new[col] = 0\n",
    "    X_new = X_new[X_df.columns]\n",
    "    \n",
    "    # Scale features\n",
    "    X_new_scaled = scaler.transform(X_new)\n",
    "    \n",
    "    # Predict tolerance parameters\n",
    "    gain_rate_pred = knn_gain.predict(X_new_scaled)[0]\n",
    "    decay_days_pred = knn_decay.predict(X_new_scaled)[0]\n",
    "    \n",
    "    # Find nearest neighbors for explanation\n",
    "    distances, indices = knn_gain.kneighbors(X_new_scaled, n_neighbors=3)\n",
    "    similar_substances = [substance_names[idx] for idx in indices[0]]\n",
    "    avg_distance = distances[0].mean()\n",
    "    \n",
    "    # Compute confidence based on distance to nearest neighbors\n",
    "    # Lower distance = higher confidence\n",
    "    confidence_score = 1.0 / (1.0 + avg_distance)\n",
    "    \n",
    "    if confidence_score >= 0.7:\n",
    "        confidence = \"Medium\"  # Never \"High\" for ML-inferred\n",
    "    elif confidence_score >= 0.5:\n",
    "        confidence = \"Medium-Low\"\n",
    "    else:\n",
    "        confidence = \"Low\"\n",
    "    \n",
    "    # Apply conservative adjustments\n",
    "    # Slightly increase decay time for uncertainty\n",
    "    decay_days_pred = int(decay_days_pred * 1.1)\n",
    "    \n",
    "    # Extract neuro bucket weights from substance profile\n",
    "    neuro_buckets = substance_profile.get('neuro_buckets', {})\n",
    "    \n",
    "    # Generate notes\n",
    "    notes = f\"Estimated via pharmacological similarity to {', '.join(similar_substances)}. \"\n",
    "    if confidence_score < 0.6:\n",
    "        notes += \"Conservative decay applied due to limited mechanistic similarity. \"\n",
    "    notes += \"This is a guideline-level estimate, not authoritative data.\"\n",
    "    \n",
    "    return {\n",
    "        \"model_origin\": \"ml_inferred\",\n",
    "        \"confidence\": confidence,\n",
    "        \"confidence_score\": float(confidence_score),\n",
    "        \"derived_from\": similar_substances,\n",
    "        \"neuro_buckets\": neuro_buckets,\n",
    "        \"tolerance_gain_rate\": float(round(gain_rate_pred, 2)),\n",
    "        \"tolerance_decay_days\": int(decay_days_pred),\n",
    "        \"notes\": notes\n",
    "    }\n",
    "\n",
    "print(\"✓ Tolerance estimation function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ca139f",
   "metadata": {},
   "source": [
    "## Step 5: Test Tolerance Estimation\n",
    "\n",
    "Test the model on substances with and without known tolerance data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beddf8f4",
   "metadata": {
    "vscode": {
     "languageId": "code"
    }
   },
   "outputs": [],
   "source": [
    "# Test on known substances (should be similar to documented values)\n",
    "print(\"=\" * 60)\n",
    "print(\"Testing on KNOWN substances (validation):\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "test_substances = [\"MDMA\", \"LSD\"]\n",
    "\n",
    "for substance_name in test_substances:\n",
    "    documented = tolerance_data[substance_name]\n",
    "    \n",
    "    print(f\"\\n{substance_name}\")\n",
    "    print(f\"  Documented:\")\n",
    "    print(f\"    Gain rate: {documented['tolerance_gain_rate']}\")\n",
    "    print(f\"    Decay days: {documented['tolerance_decay_days']}\")\n",
    "    \n",
    "    # Estimate using ML (simulating unknown substance)\n",
    "    estimated = estimate_tolerance_model(\n",
    "        documented, tolerance_data, scaler, \n",
    "        knn_gain, knn_decay, X_df, substance_names\n",
    "    )\n",
    "    \n",
    "    print(f\"  ML Estimate:\")\n",
    "    print(f\"    Gain rate: {estimated['tolerance_gain_rate']}\")\n",
    "    print(f\"    Decay days: {estimated['tolerance_decay_days']}\")\n",
    "    print(f\"    Confidence: {estimated['confidence']} ({estimated['confidence_score']:.2f})\")\n",
    "    print(f\"    Derived from: {', '.join(estimated['derived_from'])}\")\n",
    "\n",
    "# Test on hypothetical new substances\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Testing on HYPOTHETICAL new substances:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Example: Novel serotonergic entactogen\n",
    "novel_entactogen = {\n",
    "    \"neuro_buckets\": {\n",
    "        \"serotonin_release\": {\"weight\": 0.85},\n",
    "        \"dopamine_release\": {\"weight\": 0.4},\n",
    "        \"stimulant\": {\"weight\": 0.5}\n",
    "    },\n",
    "    \"half_life_hours\": 6,\n",
    "    \"duration_hours\": 5,\n",
    "    \"categories\": [\"entactogen\", \"stimulant\"]\n",
    "}\n",
    "\n",
    "print(\"\\nNovel Serotonergic Entactogen (MDMA-like)\")\n",
    "estimated = estimate_tolerance_model(\n",
    "    novel_entactogen, tolerance_data, scaler,\n",
    "    knn_gain, knn_decay, X_df, substance_names\n",
    ")\n",
    "print(f\"  Estimated Gain rate: {estimated['tolerance_gain_rate']}\")\n",
    "print(f\"  Estimated Decay days: {estimated['tolerance_decay_days']}\")\n",
    "print(f\"  Confidence: {estimated['confidence']} ({estimated['confidence_score']:.2f})\")\n",
    "print(f\"  Derived from: {', '.join(estimated['derived_from'])}\")\n",
    "print(f\"  Notes: {estimated['notes']}\")\n",
    "\n",
    "# Example: Novel psychedelic\n",
    "novel_psychedelic = {\n",
    "    \"neuro_buckets\": {\n",
    "        \"serotonin_agonist\": {\"weight\": 0.92}\n",
    "    },\n",
    "    \"half_life_hours\": 4,\n",
    "    \"duration_hours\": 8,\n",
    "    \"categories\": [\"psychedelic\"]\n",
    "}\n",
    "\n",
    "print(\"\\nNovel 5-HT2A Agonist Psychedelic\")\n",
    "estimated = estimate_tolerance_model(\n",
    "    novel_psychedelic, tolerance_data, scaler,\n",
    "    knn_gain, knn_decay, X_df, substance_names\n",
    ")\n",
    "print(f\"  Estimated Gain rate: {estimated['tolerance_gain_rate']}\")\n",
    "print(f\"  Estimated Decay days: {estimated['tolerance_decay_days']}\")\n",
    "print(f\"  Confidence: {estimated['confidence']} ({estimated['confidence_score']:.2f})\")\n",
    "print(f\"  Derived from: {', '.join(estimated['derived_from'])}\")\n",
    "print(f\"  Notes: {estimated['notes']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba81672",
   "metadata": {},
   "source": [
    "## Step 6: Visualize Feature Importance\n",
    "\n",
    "Understand which mechanisms most strongly correlate with tolerance parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5610ebb",
   "metadata": {
    "vscode": {
     "languageId": "code"
    }
   },
   "outputs": [],
   "source": [
    "# Train Random Forest for feature importance analysis\n",
    "rf_gain = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_gain.fit(X_scaled, y_gain_rate)\n",
    "\n",
    "rf_decay = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_decay.fit(X_scaled, y_decay_days)\n",
    "\n",
    "# Create feature importance dataframes\n",
    "importance_gain = pd.DataFrame({\n",
    "    'feature': X_df.columns,\n",
    "    'importance': rf_gain.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "importance_decay = pd.DataFrame({\n",
    "    'feature': X_df.columns,\n",
    "    'importance': rf_decay.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 10 features for Tolerance Gain Rate:\")\n",
    "print(importance_gain.head(10).to_string(index=False))\n",
    "\n",
    "print(\"\\n\\nTop 10 features for Tolerance Decay Days:\")\n",
    "print(importance_decay.head(10).to_string(index=False))\n",
    "\n",
    "# Visualize\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "importance_gain.head(10).plot(x='feature', y='importance', kind='barh', ax=ax1, legend=False)\n",
    "ax1.set_title('Feature Importance: Tolerance Gain Rate')\n",
    "ax1.set_xlabel('Importance')\n",
    "\n",
    "importance_decay.head(10).plot(x='feature', y='importance', kind='barh', ax=ax2, legend=False)\n",
    "ax2.set_title('Feature Importance: Tolerance Decay Days')\n",
    "ax2.set_xlabel('Importance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "print(\"\\n✓ Feature importance plot saved to feature_importance.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d09211",
   "metadata": {},
   "source": [
    "## Step 7: Save Models for API Integration\n",
    "\n",
    "Export trained models and preprocessing objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4cfd23",
   "metadata": {
    "vscode": {
     "languageId": "code"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Create models directory\n",
    "models_dir = Path('models')\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save models\n",
    "with open(models_dir / 'tolerance_gain_knn.pkl', 'wb') as f:\n",
    "    pickle.dump(knn_gain, f)\n",
    "\n",
    "with open(models_dir / 'tolerance_decay_knn.pkl', 'wb') as f:\n",
    "    pickle.dump(knn_decay, f)\n",
    "\n",
    "with open(models_dir / 'tolerance_scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(\"✓ Models saved:\")\n",
    "print(f\"  - {models_dir / 'tolerance_gain_knn.pkl'}\")\n",
    "print(f\"  - {models_dir / 'tolerance_decay_knn.pkl'}\")\n",
    "print(f\"  - {models_dir / 'tolerance_scaler.pkl'}\")\n",
    "\n",
    "# Save feature columns and substance names for reference\n",
    "metadata = {\n",
    "    'feature_columns': X_df.columns.tolist(),\n",
    "    'substance_names': substance_names,\n",
    "    'training_substances': {\n",
    "        name: {\n",
    "            'gain_rate': float(tolerance_data[name]['tolerance_gain_rate']),\n",
    "            'decay_days': int(tolerance_data[name]['tolerance_decay_days'])\n",
    "        }\n",
    "        for name in substance_names\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(models_dir / 'tolerance_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"  - {models_dir / 'tolerance_metadata.json'}\")\n",
    "print(\"\\n✓ Model export complete. Ready for API integration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8cba50",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook implements ML-assisted tolerance model inference:\n",
    "\n",
    "✅ **Estimates tolerance parameters** for under-documented substances  \n",
    "✅ **Based on mechanism similarity** to well-studied drugs  \n",
    "✅ **Conservative by design** - applies safety margins to predictions  \n",
    "✅ **Never overrides manual models** - only fills gaps  \n",
    "✅ **Provides derivation metadata** for transparency  \n",
    "\n",
    "### Key Outputs\n",
    "\n",
    "The model predicts:\n",
    "- `tolerance_gain_rate`: How quickly tolerance develops (0.5-2.0)\n",
    "- `tolerance_decay_days`: Time for tolerance reset (7-90+ days)\n",
    "- `confidence`: Reliability of estimate (Low/Medium)\n",
    "- `derived_from`: Similar substances used for inference\n",
    "\n",
    "### Integration Points\n",
    "\n",
    "1. `tolerance_service.py` - API service layer\n",
    "2. Flutter app - Tolerance calculator logic\n",
    "3. Database - Store inferred models with metadata\n",
    "\n",
    "**Important**: ML-inferred models are labeled as estimates and never presented as authoritative data."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
