{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84e447fa",
   "metadata": {},
   "source": [
    "# Tolerance Model: Neuro Bucket Inference\n",
    "\n",
    "Uses:\n",
    "- `../drugs.json` for per-substance metadata\n",
    "- `baseline.json` for the canonical bucket set\n",
    "- `inspo.json` as a reference target set to calibrate against\n",
    "\n",
    "Outputs:\n",
    "- `outputs/tolerance_neuro_buckets.json` (single JSON document; JSONB-ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0e95596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRUGS_PATH: C:\\Users\\USER\\dev\\code\\mobile_drug_use_app\\backend\\ML\\drugs.json\n",
      "BASELINE_PATH: C:\\Users\\USER\\dev\\code\\mobile_drug_use_app\\backend\\ML\\drug_tolerance_model\\baseline.json\n",
      "INSPO_PATH: C:\\Users\\USER\\dev\\code\\mobile_drug_use_app\\backend\\ML\\drug_tolerance_model\\inspo.json\n",
      "YAML_PATH: C:\\Users\\USER\\dev\\code\\mobile_drug_use_app\\backend\\ML\\drug_interaction.yaml\n",
      "OUTPUT_JSON: C:\\Users\\USER\\dev\\code\\mobile_drug_use_app\\backend\\ML\\drug_tolerance_model\\outputs\\tolerance_neuro_buckets.json\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "rng = np.random.default_rng(RANDOM_STATE)\n",
    "\n",
    "HERE = Path.cwd()\n",
    "DRUGS_PATH = Path('..') / 'drugs.json'\n",
    "BASELINE_PATH = Path('baseline.json')\n",
    "INSPO_PATH = Path('inspo.json')\n",
    "# Shared canonicalization config (exclude/aliases/groups)\n",
    "YAML_PATH = Path('..') / 'drug_interaction.yaml'\n",
    "OUTPUT_DIR = Path('outputs')\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_JSON = OUTPUT_DIR / 'tolerance_neuro_buckets.json'\n",
    "\n",
    "print('DRUGS_PATH:', DRUGS_PATH.resolve())\n",
    "print('BASELINE_PATH:', BASELINE_PATH.resolve())\n",
    "print('INSPO_PATH:', INSPO_PATH.resolve())\n",
    "print('YAML_PATH:', YAML_PATH.resolve())\n",
    "print('OUTPUT_JSON:', OUTPUT_JSON.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ccea2020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded drugs: 551\n",
      "✓ Loaded baseline buckets: ['stimulant', 'serotonin_release', 'serotonin_psychedelic', 'gaba', 'opioid', 'nmda', 'cannabinoid']\n",
      "✓ Loaded inspo substances: 19\n"
     ]
    }
   ],
   "source": [
    "def load_json(path: Path) -> dict:\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "drugs_raw = load_json(DRUGS_PATH)\n",
    "baseline = load_json(BASELINE_PATH)\n",
    "inspo = load_json(INSPO_PATH)\n",
    "\n",
    "BUCKETS: List[str] = list((baseline.get('buckets') or {}).keys())\n",
    "if not BUCKETS:\n",
    "    raise ValueError('No buckets found in baseline.json')\n",
    "\n",
    "print('✓ Loaded drugs:', len(drugs_raw))\n",
    "print('✓ Loaded baseline buckets:', BUCKETS)\n",
    "print('✓ Loaded inspo substances:', len((inspo.get('substances') or {})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "00810a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded drug_interaction.yaml for tolerance\n",
      "  exclude_all: 23 exclude_neuro: 4 aliases: 11 groups: 10 separate: 1\n"
     ]
    }
   ],
   "source": [
    "# Load shared YAML canonicalization (exclude/aliases/groups)\n",
    "import yaml\n",
    "\n",
    "def normalize_name(name: str) -> str:\n",
    "    return (name or '').strip().lower()\n",
    "\n",
    "def load_yaml(path: Path) -> dict:\n",
    "    if not path.exists():\n",
    "        return {}\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        obj = yaml.safe_load(f)\n",
    "    return obj if isinstance(obj, dict) else {}\n",
    "\n",
    "def _yaml_list(cfg: dict, *keys: str) -> List[str]:\n",
    "    out: List[str] = []\n",
    "    for k in keys:\n",
    "        v = cfg.get(k)\n",
    "        if isinstance(v, list):\n",
    "            out.extend([x for x in v if isinstance(x, str)])\n",
    "    return out\n",
    "\n",
    "TOL_CFG = load_yaml(YAML_PATH)\n",
    "\n",
    "# YAML schema supports multiple keys (user-editable)\n",
    "# - exclude from all: excluded everywhere\n",
    "# - exlude from neuro-bucket: excluded only from tolerance model (typo preserved)\n",
    "EXCLUDE_ALL = _yaml_list(TOL_CFG, 'exclude', 'exclude from all', 'exclude_from_all')\n",
    "EXCLUDE_NEURO = _yaml_list(TOL_CFG, 'exclude from neuro-bucket', 'exlude from neuro-bucket', 'exclude_from_neuro_bucket', 'exclude_from_neuro-bucket')\n",
    "\n",
    "TOL_EXCLUDE_SET = {normalize_name(x) for x in (EXCLUDE_ALL + EXCLUDE_NEURO) if isinstance(x, str)}\n",
    "TOL_SEPARATE_SET = {normalize_name(x) for x in (TOL_CFG.get('separate') or []) if isinstance(x, str)}\n",
    "TOL_ALIAS_MAP = {\n",
    "    normalize_name(k): normalize_name(v)\n",
    "    for k, v in (TOL_CFG.get('aliases') or {}).items()\n",
    "    if isinstance(k, str) and isinstance(v, str)\n",
    "}\n",
    "\n",
    "# Groups: we do NOT merge for tolerance; we use them to share the same bucket *set* across members.\n",
    "TOL_GROUPS: Dict[str, dict] = {}\n",
    "TOL_MEMBER_TO_GROUP: Dict[str, str] = {}\n",
    "for group_name, g in (TOL_CFG.get('groups') or {}).items():\n",
    "    if not isinstance(g, dict):\n",
    "        continue\n",
    "    group_norm = normalize_name(group_name)\n",
    "    canon = normalize_name(g.get('canonical', group_name))\n",
    "    members = []\n",
    "    for m in (g.get('members') or []):\n",
    "        if isinstance(m, str):\n",
    "            members.append(normalize_name(m))\n",
    "    # also treat the group key itself as a member label\n",
    "    if group_norm not in members:\n",
    "        members.append(group_norm)\n",
    "    if canon not in members:\n",
    "        members.append(canon)\n",
    "\n",
    "    TOL_GROUPS[group_norm] = {\n",
    "        'canonical': canon,\n",
    "        'members': sorted(set(members)),\n",
    "    }\n",
    "    for m in TOL_GROUPS[group_norm]['members']:\n",
    "        # Respect separate: keep separate members un-grouped\n",
    "        if m in TOL_SEPARATE_SET:\n",
    "            continue\n",
    "        TOL_MEMBER_TO_GROUP[m] = group_norm\n",
    "\n",
    "# Map from normalized drugs.json key -> original key\n",
    "DRUG_KEY_BY_NORM = {normalize_name(k): k for k in drugs_raw.keys()}\n",
    "\n",
    "def is_excluded(name: str) -> bool:\n",
    "    return normalize_name(name) in TOL_EXCLUDE_SET\n",
    "\n",
    "def apply_alias(name: str) -> str:\n",
    "    n = normalize_name(name)\n",
    "    return TOL_ALIAS_MAP.get(n, n)\n",
    "\n",
    "def resolve_drugs_key(name: str) -> Optional[str]:\n",
    "    \"\"\"Resolve name -> drugs.json key after aliasing; None if excluded.\"\"\"\n",
    "    n = apply_alias(name)\n",
    "    if not n or is_excluded(n):\n",
    "        return None\n",
    "    return DRUG_KEY_BY_NORM.get(n)\n",
    "\n",
    "def tolerance_group_id(name: str) -> Optional[str]:\n",
    "    n = normalize_name(name)\n",
    "    return TOL_MEMBER_TO_GROUP.get(n)\n",
    "\n",
    "print('✓ Loaded drug_interaction.yaml for tolerance')\n",
    "print('  exclude_all:', len(EXCLUDE_ALL), 'exclude_neuro:', len(EXCLUDE_NEURO), 'aliases:', len(TOL_ALIAS_MAP), 'groups:', len(TOL_GROUPS), 'separate:', len(TOL_SEPARATE_SET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3a32e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Supabase category refresh: ok (524 rows)\n"
     ]
    }
   ],
   "source": [
    "# Optional: Refresh categories from Supabase (drug_profiles table) to补 missing/updated categories in drugs.json\n",
    "# - Uses SUPABASE_URL and SUPABASE_ANON_KEY from .env at workspace root\n",
    "# - Does NOT print secrets\n",
    "import os\n",
    "import requests\n",
    "\n",
    "def load_dotenv_simple(dotenv_path: Path) -> None:\n",
    "    if not dotenv_path.exists():\n",
    "        return\n",
    "    for raw in dotenv_path.read_text(encoding='utf-8').splitlines():\n",
    "        line = raw.strip()\n",
    "        if not line or line.startswith('#') or '=' not in line:\n",
    "            continue\n",
    "        k, v = line.split('=', 1)\n",
    "        k = k.strip()\n",
    "        v = v.strip().strip('\"').strip(\"'\")\n",
    "        # don't override existing env vars\n",
    "        os.environ.setdefault(k, v)\n",
    "\n",
    "# repo root is two levels up from this notebook folder: backend/ML/drug_tolerance_model\n",
    "DOTENV_PATH = Path('..') / '..' / '..' / '.env'\n",
    "DOTENV_PATH = DOTENV_PATH.resolve()\n",
    "load_dotenv_simple(DOTENV_PATH)\n",
    "\n",
    "SUPABASE_URL = os.environ.get('SUPABASE_URL')\n",
    "SUPABASE_ANON_KEY = os.environ.get('SUPABASE_ANON_KEY')\n",
    "\n",
    "def _postgrest_get(table: str, select: str, limit: int = 10000) -> list:\n",
    "    if not SUPABASE_URL or not SUPABASE_ANON_KEY:\n",
    "        return []\n",
    "    url = SUPABASE_URL.rstrip('/') + f'/rest/v1/{table}'\n",
    "    headers = {\n",
    "        'apikey': SUPABASE_ANON_KEY,\n",
    "        'Authorization': f'Bearer {SUPABASE_ANON_KEY}',\n",
    "        'Accept': 'application/json',\n",
    "    }\n",
    "    params = {\n",
    "        'select': select,\n",
    "        'limit': str(limit),\n",
    "    }\n",
    "    resp = requests.get(url, headers=headers, params=params, timeout=20)\n",
    "    if resp.status_code >= 400:\n",
    "        raise RuntimeError(f'PostgREST error {resp.status_code}: {resp.text[:300]}')\n",
    "    data = resp.json()\n",
    "    return data if isinstance(data, list) else []\n",
    "\n",
    "def _extract_row_key(row: dict) -> Optional[str]:\n",
    "    # Try a few common column names\n",
    "    for k in ['substance', 'substance_key', 'drug_key', 'drug', 'name', 'slug', 'id']:\n",
    "        v = row.get(k)\n",
    "        if isinstance(v, str) and v.strip():\n",
    "            return v.strip()\n",
    "    return None\n",
    "\n",
    "def _normalize_categories(value) -> List[str]:\n",
    "    if value is None:\n",
    "        return []\n",
    "    if isinstance(value, list):\n",
    "        return [normalize_name(x) for x in value if isinstance(x, str) and x.strip()]\n",
    "    if isinstance(value, str):\n",
    "        # allow comma-separated strings\n",
    "        parts = [p.strip() for p in value.split(',')]\n",
    "        return [normalize_name(p) for p in parts if p]\n",
    "    return []\n",
    "\n",
    "DB_CATEGORIES_BY_NORM: Dict[str, List[str]] = {}\n",
    "DB_FETCH_STATUS = 'skipped'\n",
    "try:\n",
    "    if SUPABASE_URL and SUPABASE_ANON_KEY:\n",
    "        # Try a conservative select first; if schema differs, fall back to '*'\n",
    "        rows = []\n",
    "        try:\n",
    "            rows = _postgrest_get('drug_profiles', 'substance,categories')\n",
    "        except Exception:\n",
    "            rows = _postgrest_get('drug_profiles', '*')\n",
    "        for row in rows:\n",
    "            if not isinstance(row, dict):\n",
    "                continue\n",
    "            key = _extract_row_key(row)\n",
    "            if not key:\n",
    "                continue\n",
    "            cats = _normalize_categories(row.get('categories'))\n",
    "            if not cats:\n",
    "                continue\n",
    "            n = apply_alias(key)\n",
    "            if is_excluded(n):\n",
    "                continue\n",
    "            DB_CATEGORIES_BY_NORM[normalize_name(n)] = cats\n",
    "        DB_FETCH_STATUS = f'ok ({len(DB_CATEGORIES_BY_NORM)} rows)'\n",
    "    else:\n",
    "        DB_FETCH_STATUS = 'missing SUPABASE_URL/SUPABASE_ANON_KEY'\n",
    "except Exception as e:\n",
    "    DB_FETCH_STATUS = f'error: {type(e).__name__}: {e}'\n",
    "    DB_CATEGORIES_BY_NORM = {}\n",
    "\n",
    "def get_categories_for(drugs_key: str, entry: dict) -> List[str]:\n",
    "    \"\"\"Return categories using DB override when available; otherwise fall back to drugs.json.\"\"\"\n",
    "    n = normalize_name(drugs_key)\n",
    "    if n in DB_CATEGORIES_BY_NORM:\n",
    "        return DB_CATEGORIES_BY_NORM[n]\n",
    "    cats = entry.get('categories') or []\n",
    "    return [normalize_name(c) for c in cats if isinstance(c, str)]\n",
    "\n",
    "print('✓ Supabase category refresh:', DB_FETCH_STATUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "010cbe50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Feature extractor ready\n"
     ]
    }
   ],
   "source": [
    "def norm(s: str) -> str:\n",
    "    return (s or '').strip().lower()\n",
    "\n",
    "def _iter_str_list(x) -> List[str]:\n",
    "    if isinstance(x, list):\n",
    "        return [norm(v) for v in x if isinstance(v, str)]\n",
    "    return []\n",
    "\n",
    "def extract_features(substance: str, entry: dict) -> Dict[str, float]:\n",
    "    feats: Dict[str, float] = {}\n",
    "\n",
    "    # Categories are the most stable structured signal we have (DB-refreshed when available).\n",
    "    for c in get_categories_for(substance, entry):\n",
    "        feats[f'cat:{c}'] = 1.0\n",
    "\n",
    "    # PsychonautWiki effect keys (structured-ish, useful for mechanism hints)\n",
    "    pwe = entry.get('pweffects') or {}\n",
    "    if isinstance(pwe, dict):\n",
    "        for k in pwe.keys():\n",
    "            if isinstance(k, str):\n",
    "                feats[f'pwe:{norm(k)}'] = 1.0\n",
    "\n",
    "    # Formatted effects list (e.g., Sedative, Stimulation)\n",
    "    for fx in _iter_str_list(entry.get('formatted_effects')):\n",
    "        feats[f'fx:{fx}'] = 1.0\n",
    "\n",
    "    # Minimal parsing from properties.avoid (warning-like field)\n",
    "    props = entry.get('properties') or {}\n",
    "    if isinstance(props, dict):\n",
    "        avoid = props.get('avoid')\n",
    "        if isinstance(avoid, str):\n",
    "            a = norm(avoid)\n",
    "            if 'cns depressant' in a:\n",
    "                feats['warn:cns_depressant'] = 1.0\n",
    "            if 'serotonergic' in a:\n",
    "                feats['warn:serotonergic'] = 1.0\n",
    "            if 'maoi' in a:\n",
    "                feats['warn:maoi'] = 1.0\n",
    "\n",
    "    return feats\n",
    "\n",
    "print('✓ Feature extractor ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "839cd44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Heuristic prior ready\n"
     ]
    }
   ],
   "source": [
    "# Heuristic prior: fast rule-based mapping from categories/effects -> bucket weights\n",
    "# These priors do most of the work; ML learns residual corrections against inspo.json.\n",
    "PRIOR_KEYWORDS = {\n",
    "    'stimulant': [\n",
    "        'stimulant', 'dopamine', 'norepinephrine', 'adrenergic', 'amphetamine', 'cathinone',\n",
    "        'pwe:stimulation', 'fx:stimulation',\n",
    "    ],\n",
    "    'serotonin_release': [\n",
    "        'entactogen', 'empathogen', 'serotonin', 'mdma', 'mda',\n",
    "        'pwe:empathy, love, and sociability enhancement',\n",
    "        'fx:empathy',\n",
    "        'warn:serotonergic',\n",
    "    ],\n",
    "    'serotonin_psychedelic': [\n",
    "        'psychedelic', 'tryptamine', 'lysergamide', 'phenethylamine', '5-ht2a',\n",
    "        'pwe:hallucinations', 'fx:hallucinations',\n",
    "    ],\n",
    "    'gaba': [\n",
    "        'benzodiazepine', 'benzo', 'z-drug', 'depressant', 'sedative', 'gaba',\n",
    "        'pwe:sedation', 'fx:sedative', 'fx:hypnotic',\n",
    "        'warn:cns_depressant',\n",
    "    ],\n",
    "    'opioid': [\n",
    "        'opioid', 'opiate', 'pwe:respiratory depression',\n",
    "    ],\n",
    "    'nmda': [\n",
    "        'dissociative', 'nmda', 'ketamine',\n",
    "        'pwe:dissociation',\n",
    "    ],\n",
    "    'cannabinoid': [\n",
    "        'cannabinoid', 'thc', 'cannabis',\n",
    "    ],\n",
    "}\n",
    "\n",
    "def heuristic_prior(substance: str, entry: dict) -> np.ndarray:\n",
    "    feats = extract_features(substance, entry)\n",
    "    # Token set: feature keys + raw cat values + raw name string\n",
    "    tokens = set(feats.keys())\n",
    "    tokens |= {k.split(':', 1)[1] for k in feats.keys() if k.startswith('cat:')}\n",
    "    tokens.add(norm(substance))\n",
    "    w = np.zeros(len(BUCKETS), dtype=float)\n",
    "    for i, b in enumerate(BUCKETS):\n",
    "        kws = PRIOR_KEYWORDS.get(b, [])\n",
    "        score = 0\n",
    "        for kw in kws:\n",
    "            if kw in tokens:\n",
    "                score += 2 if (kw.startswith('pwe:') or kw.startswith('fx:') or kw.startswith('warn:')) else 1\n",
    "        # convert score -> weight\n",
    "        if score >= 3:\n",
    "            w[i] = 1.0\n",
    "        elif score == 2:\n",
    "            w[i] = 0.7\n",
    "        elif score == 1:\n",
    "            w[i] = 0.4\n",
    "        else:\n",
    "            w[i] = 0.0\n",
    "    return w\n",
    "\n",
    "print('✓ Heuristic prior ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "050fcb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Training rows: 19\n",
      "Missing inspo entries in drugs.json: []\n",
      "Excluded inspo entries (yaml exclude): []\n",
      "Target buckets: ['stimulant', 'serotonin_release', 'serotonin_psychedelic', 'gaba', 'opioid', 'nmda', 'cannabinoid']\n"
     ]
    }
   ],
   "source": [
    "# Build supervised training set from inspo.json\n",
    "inspo_substances = inspo.get('substances') or {}\n",
    "train_names = sorted([k for k in inspo_substances.keys() if isinstance(k, str)])\n",
    "\n",
    "# Optional manual mapping for inspo naming quirks -> drugs.json naming\n",
    "INSPO_TO_DRUGS_ALIASES = {\n",
    "    'dxm': 'dextromethorphan',\n",
    "    'psilocybin': 'psilocin',\n",
    "    'thc': 'cannabis',\n",
    "}\n",
    "\n",
    "def resolve_inspo_name_to_drugs_key(name: str) -> Optional[str]:\n",
    "    n = normalize_name(name)\n",
    "    n = INSPO_TO_DRUGS_ALIASES.get(n, n)\n",
    "    n = apply_alias(n)\n",
    "    if is_excluded(n):\n",
    "        return None\n",
    "    # direct hit\n",
    "    direct = resolve_drugs_key(n)\n",
    "    if direct is not None:\n",
    "        return direct\n",
    "    # group fallback: use canonical or any member that exists in drugs.json\n",
    "    gid = tolerance_group_id(n)\n",
    "    if gid is not None:\n",
    "        g = TOL_GROUPS.get(gid) or {}\n",
    "        canon = g.get('canonical')\n",
    "        if isinstance(canon, str):\n",
    "            hit = resolve_drugs_key(canon)\n",
    "            if hit is not None:\n",
    "                return hit\n",
    "        for m in (g.get('members') or []):\n",
    "            if isinstance(m, str):\n",
    "                hit = resolve_drugs_key(m)\n",
    "                if hit is not None:\n",
    "                    return hit\n",
    "    return None\n",
    "\n",
    "def target_vector_from_inspo(substance: str) -> np.ndarray:\n",
    "    obj = inspo_substances.get(substance) or {}\n",
    "    nb = obj.get('neuro_buckets') or {}\n",
    "    y = np.zeros(len(BUCKETS), dtype=float)\n",
    "    if isinstance(nb, dict):\n",
    "        for i, b in enumerate(BUCKETS):\n",
    "            if b in nb and isinstance(nb[b], dict):\n",
    "                w = nb[b].get('weight', 0.0)\n",
    "                if isinstance(w, (int, float)):\n",
    "                    y[i] = float(w)\n",
    "    return np.clip(y, 0.0, 1.0)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "prior = []\n",
    "missing_from_drugs = []\n",
    "excluded_from_training = []\n",
    "for s in train_names:\n",
    "    s_key = resolve_inspo_name_to_drugs_key(s)\n",
    "    if s_key is None:\n",
    "        # either excluded or not found\n",
    "        if is_excluded(s):\n",
    "            excluded_from_training.append(s)\n",
    "        else:\n",
    "            missing_from_drugs.append(s)\n",
    "        continue\n",
    "    entry = drugs_raw[s_key]\n",
    "    X.append(extract_features(s_key, entry))\n",
    "    y.append(target_vector_from_inspo(s))\n",
    "    prior.append(heuristic_prior(s_key, entry))\n",
    "\n",
    "X = list(X)\n",
    "y = np.vstack(y) if y else np.zeros((0, len(BUCKETS)))\n",
    "prior = np.vstack(prior) if prior else np.zeros((0, len(BUCKETS)))\n",
    "print('✓ Training rows:', len(X))\n",
    "print('Missing inspo entries in drugs.json:', missing_from_drugs)\n",
    "print('Excluded inspo entries (yaml exclude):', excluded_from_training)\n",
    "print('Target buckets:', BUCKETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "62787509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Trained residual model\n",
      "Mean MAE vs inspo: 0.022414516931336892\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>substance</th>\n",
       "      <th>drugs_key</th>\n",
       "      <th>mae</th>\n",
       "      <th>true:stimulant</th>\n",
       "      <th>pred:stimulant</th>\n",
       "      <th>true:serotonin_release</th>\n",
       "      <th>pred:serotonin_release</th>\n",
       "      <th>true:serotonin_psychedelic</th>\n",
       "      <th>pred:serotonin_psychedelic</th>\n",
       "      <th>true:gaba</th>\n",
       "      <th>pred:gaba</th>\n",
       "      <th>true:opioid</th>\n",
       "      <th>pred:opioid</th>\n",
       "      <th>true:nmda</th>\n",
       "      <th>pred:nmda</th>\n",
       "      <th>true:cannabinoid</th>\n",
       "      <th>pred:cannabinoid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dexedrine</td>\n",
       "      <td>dexedrine</td>\n",
       "      <td>0.077709</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.563956</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043758</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>psilocybin</td>\n",
       "      <td>psilocin</td>\n",
       "      <td>0.075889</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041287</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.515304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mdma</td>\n",
       "      <td>mdma</td>\n",
       "      <td>0.075576</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.461749</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.867490</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.264027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bupropion</td>\n",
       "      <td>bupropion</td>\n",
       "      <td>0.043239</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.462803</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004774</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ghb</td>\n",
       "      <td>ghb</td>\n",
       "      <td>0.042571</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.045917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.766488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>morphine</td>\n",
       "      <td>morphine</td>\n",
       "      <td>0.019674</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.012572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099373</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alcohol</td>\n",
       "      <td>alcohol</td>\n",
       "      <td>0.015207</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.089972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.886200</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.308724</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.568530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>thc</td>\n",
       "      <td>cannabis</td>\n",
       "      <td>0.015017</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.016407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022935</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.975962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mdpv</td>\n",
       "      <td>mdpv</td>\n",
       "      <td>0.013769</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.906754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>caffeine</td>\n",
       "      <td>caffeine</td>\n",
       "      <td>0.011703</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.372908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>lsd</td>\n",
       "      <td>lsd</td>\n",
       "      <td>0.008316</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.031927</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004970</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.984183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4-ho-mipt</td>\n",
       "      <td>4-ho-mipt</td>\n",
       "      <td>0.008143</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002382</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.982942</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002487</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dxm</td>\n",
       "      <td>dextromethorphan</td>\n",
       "      <td>0.006949</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.172500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008127</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.689994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>nicotine</td>\n",
       "      <td>nicotine</td>\n",
       "      <td>0.005936</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.015371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003418</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>methylphenidate</td>\n",
       "      <td>methylphenidate</td>\n",
       "      <td>0.002638</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.985148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001298</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ketamine</td>\n",
       "      <td>ketamine</td>\n",
       "      <td>0.002549</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010807</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>diazepam</td>\n",
       "      <td>diazepam</td>\n",
       "      <td>0.000991</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bromazolam</td>\n",
       "      <td>bromazolam</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>flutoprazepam</td>\n",
       "      <td>flutoprazepam</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          substance         drugs_key       mae  true:stimulant  \\\n",
       "5         dexedrine         dexedrine  0.077709            1.00   \n",
       "17       psilocybin          psilocin  0.075889            0.00   \n",
       "12             mdma              mdma  0.075576            0.35   \n",
       "3         bupropion         bupropion  0.043239            0.20   \n",
       "9               ghb               ghb  0.042571            0.00   \n",
       "15         morphine          morphine  0.019674            0.00   \n",
       "1           alcohol           alcohol  0.015207            0.10   \n",
       "18              thc          cannabis  0.015017            0.00   \n",
       "13             mdpv              mdpv  0.013769            1.00   \n",
       "4          caffeine          caffeine  0.011703            0.30   \n",
       "11              lsd               lsd  0.008316            0.00   \n",
       "0         4-ho-mipt         4-ho-mipt  0.008143            0.00   \n",
       "7               dxm  dextromethorphan  0.006949            0.00   \n",
       "16         nicotine          nicotine  0.005936            0.05   \n",
       "14  methylphenidate   methylphenidate  0.002638            1.00   \n",
       "10         ketamine          ketamine  0.002549            0.00   \n",
       "6          diazepam          diazepam  0.000991            0.00   \n",
       "2        bromazolam        bromazolam  0.000000            0.00   \n",
       "8     flutoprazepam     flutoprazepam  0.000000            0.00   \n",
       "\n",
       "    pred:stimulant  true:serotonin_release  pred:serotonin_release  \\\n",
       "5         0.563956                     0.0                0.059948   \n",
       "17        0.000000                     0.0                0.041287   \n",
       "12        0.461749                     1.0                0.867490   \n",
       "3         0.462803                     0.0                0.031398   \n",
       "9         0.045917                     0.0                0.013714   \n",
       "15        0.012572                     0.0                0.000000   \n",
       "1         0.089972                     0.0                0.041307   \n",
       "18        0.016407                     0.0                0.001295   \n",
       "13        0.906754                     0.0                0.002193   \n",
       "4         0.372908                     0.0                0.000000   \n",
       "11        0.031927                     0.0                0.004970   \n",
       "0         0.000000                     0.0                0.002382   \n",
       "7         0.000000                     0.2                0.172500   \n",
       "16        0.015371                     0.0                0.003418   \n",
       "14        0.985148                     0.0                0.000000   \n",
       "10        0.000000                     0.0                0.010807   \n",
       "6         0.000000                     0.0                0.000000   \n",
       "2         0.000000                     0.0                0.000000   \n",
       "8         0.000000                     0.0                0.000000   \n",
       "\n",
       "    true:serotonin_psychedelic  pred:serotonin_psychedelic  true:gaba  \\\n",
       "5                          0.0                    0.000000        0.0   \n",
       "17                         1.0                    0.515304        0.0   \n",
       "12                         0.0                    0.264027        0.0   \n",
       "3                          0.0                    0.000000        0.0   \n",
       "9                          0.0                    0.000000        1.0   \n",
       "15                         0.0                    0.000000        0.0   \n",
       "1                          0.0                    0.000000        0.9   \n",
       "18                         0.0                    0.022935        0.0   \n",
       "13                         0.0                    0.000000        0.0   \n",
       "4                          0.0                    0.000000        0.0   \n",
       "11                         1.0                    0.984183        0.0   \n",
       "0                          1.0                    0.982942        0.0   \n",
       "7                          0.0                    0.002966        0.0   \n",
       "16                         0.0                    0.000000        0.0   \n",
       "14                         0.0                    0.000000        0.0   \n",
       "10                         0.0                    0.003101        0.0   \n",
       "6                          0.0                    0.000000        1.0   \n",
       "2                          0.0                    0.000000        1.0   \n",
       "8                          0.0                    0.000000        1.0   \n",
       "\n",
       "    pred:gaba  true:opioid  pred:opioid  true:nmda  pred:nmda  \\\n",
       "5    0.043758          0.0     0.000000        0.0   0.000686   \n",
       "17   0.000000          0.0     0.001001        0.0   0.000000   \n",
       "12   0.015572          0.0     0.000000        0.0   0.000000   \n",
       "3    0.000000          0.0     0.004774        0.0   0.000000   \n",
       "9    0.766488          0.0     0.000000        0.0   0.001675   \n",
       "15   0.099373          1.0     0.988299        0.0   0.013479   \n",
       "1    0.886200          0.3     0.308724        0.6   0.568530   \n",
       "18   0.037517          0.0     0.000000        0.0   0.002929   \n",
       "13   0.000000          0.0     0.000000        0.0   0.000000   \n",
       "4    0.006333          0.0     0.000075        0.0   0.002603   \n",
       "11   0.000000          0.0     0.000756        0.0   0.002549   \n",
       "0    0.030009          0.0     0.002487        0.0   0.001148   \n",
       "7    0.000000          0.0     0.008127        0.7   0.689994   \n",
       "16   0.000000          0.0     0.000000        0.0   0.003505   \n",
       "14   0.000000          0.0     0.000000        0.0   0.001298   \n",
       "10   0.000000          0.0     0.000000        1.0   0.999629   \n",
       "6    0.993062          0.0     0.000000        0.0   0.000000   \n",
       "2    1.000000          0.0     0.000000        0.0   0.000000   \n",
       "8    1.000000          0.0     0.000000        0.0   0.000000   \n",
       "\n",
       "    true:cannabinoid  pred:cannabinoid  \n",
       "5                0.0          0.003528  \n",
       "17               0.0          0.004238  \n",
       "12               0.0          0.005171  \n",
       "3                0.0          0.003697  \n",
       "9                0.0          0.003179  \n",
       "15               0.0          0.000596  \n",
       "1                0.0          0.001119  \n",
       "18               1.0          0.975962  \n",
       "13               0.0          0.000948  \n",
       "4                0.0          0.000000  \n",
       "11               0.0          0.002194  \n",
       "0                0.0          0.003917  \n",
       "7                0.0          0.000042  \n",
       "16               0.0          0.000000  \n",
       "14               0.0          0.002315  \n",
       "10               0.0          0.003562  \n",
       "6                0.0          0.000000  \n",
       "2                0.0          0.000000  \n",
       "8                0.0          0.000000  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train residual model: predicts (target - heuristic_prior) from drugs.json features\n",
    "# We disable intercept so unknown/unseen feature rows don't get a drifting baseline residual.\n",
    "residual = y - prior\n",
    "\n",
    "model: Pipeline = Pipeline([\n",
    "    ('vec', DictVectorizer(sparse=True)),\n",
    "    ('reg', MultiOutputRegressor(Ridge(alpha=2.0, fit_intercept=False, random_state=RANDOM_STATE))),\n",
    "])\n",
    "model.fit(X, residual)\n",
    "print('✓ Trained residual model')\n",
    "\n",
    "BUCKET_INDEX = {b: i for i, b in enumerate(BUCKETS)}\n",
    "\n",
    "def is_benzodiazepine_category(drugs_key: str) -> bool:\n",
    "    entry = drugs_raw.get(drugs_key) or {}\n",
    "    cats = set(get_categories_for(drugs_key, entry))\n",
    "    return ('benzodiazepine' in cats) or ('benzodiazepines' in cats)\n",
    "\n",
    "def predict_weights(drugs_key: str) -> np.ndarray:\n",
    "    k = normalize_name(drugs_key)\n",
    "    if is_excluded(k):\n",
    "        return np.zeros(len(BUCKETS), dtype=float)\n",
    "    entry = drugs_raw.get(drugs_key) or {}\n",
    "    p = heuristic_prior(drugs_key, entry)\n",
    "    r = model.predict([extract_features(drugs_key, entry)])[0]\n",
    "    w = np.clip(p + r, 0.0, 1.0)\n",
    "\n",
    "    # Rule: if category includes Benzodiazepine, only allow GABA bucket\n",
    "    if is_benzodiazepine_category(drugs_key) and 'gaba' in BUCKET_INDEX:\n",
    "        gaba_i = BUCKET_INDEX['gaba']\n",
    "        gaba_w = float(w[gaba_i])\n",
    "        w2 = np.zeros(len(BUCKETS), dtype=float)\n",
    "        w2[gaba_i] = np.clip(gaba_w if gaba_w > 0 else 0.7, 0.0, 1.0)\n",
    "        w = w2\n",
    "\n",
    "    if float(w.max()) <= 0.0:\n",
    "        idx = int(np.argmax(p)) if float(p.max()) > 0 else 0\n",
    "        w[idx] = 0.1\n",
    "    return w\n",
    "\n",
    "def eval_against_inspo() -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for s in train_names:\n",
    "        s_key = resolve_inspo_name_to_drugs_key(s)\n",
    "        if s_key is None:\n",
    "            continue\n",
    "        y_true = target_vector_from_inspo(s)\n",
    "        y_pred = predict_weights(s_key)\n",
    "        row = {'substance': s, 'drugs_key': s_key, 'mae': float(np.mean(np.abs(y_true - y_pred)))}\n",
    "        for i, b in enumerate(BUCKETS):\n",
    "            row[f'true:{b}'] = float(y_true[i])\n",
    "            row[f'pred:{b}'] = float(y_pred[i])\n",
    "        rows.append(row)\n",
    "    return pd.DataFrame(rows).sort_values('mae', ascending=False)\n",
    "\n",
    "df_eval = eval_against_inspo()\n",
    "print('Mean MAE vs inspo:', float(df_eval['mae'].mean()) if len(df_eval) else None)\n",
    "df_eval.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "484c1a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Export substances (after exclude + alias de-dup): 524\n",
      "✓ Wrote C:\\Users\\USER\\dev\\code\\mobile_drug_use_app\\backend\\ML\\drug_tolerance_model\\outputs\\tolerance_neuro_buckets.json\n",
      "Substances exported: 524\n",
      "Missing neuro_buckets: 0\n"
     ]
    }
   ],
   "source": [
    "# Export: neuro_buckets for all substances (JSONB-ready)\n",
    "import re\n",
    "\n",
    "DEFAULT_TOLERANCE_PARAMS = {\n",
    "    'half_life_hours': 12.0,\n",
    "    'active_threshold': 0.05,\n",
    "    'standard_unit': {'value': 10.0, 'unit': 'mg'},\n",
    "    'potency_multiplier': 1.0,\n",
    "    'duration_multiplier': 1.2,\n",
    "    'tolerance_gain_rate': 0.25,\n",
    "    'tolerance_decay_days': 5.0,\n",
    "}\n",
    "\n",
    "def parse_half_life_hours_from_drugs(entry: dict) -> Optional[float]:\n",
    "    \"\"\"Best-effort parse of drugs.json properties['half-life'] into hours.\"\"\"\n",
    "    props = entry.get('properties') or {}\n",
    "    if not isinstance(props, dict):\n",
    "        return None\n",
    "    hl = props.get('half-life') or props.get('half_life')\n",
    "    if not isinstance(hl, str):\n",
    "        return None\n",
    "    s = hl.strip().lower()\n",
    "    if not s:\n",
    "        return None\n",
    "    # Extract 1-2 numbers; if range, average\n",
    "    nums = [float(x) for x in re.findall(r'\\d+(?:\\.\\d+)?', s)[:2]]\n",
    "    if not nums:\n",
    "        return None\n",
    "    value = nums[0] if len(nums) == 1 else (nums[0] + nums[1]) / 2.0\n",
    "    # Unit handling\n",
    "    if 'minute' in s or 'min' in s:\n",
    "        return value / 60.0\n",
    "    if 'day' in s:\n",
    "        return value * 24.0\n",
    "    if 'hour' in s or 'hr' in s:\n",
    "        return value\n",
    "    # Unknown unit: assume hours only if the string mentions half-life in hours-like context\n",
    "    return None\n",
    "\n",
    "def parse_standard_unit_from_drugs(entry: dict) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Parse formatted_dose to find a 'Common' or 'Light' dose to use as standard unit.\n",
    "    Returns {'value': float, 'unit': str} or None.\n",
    "    \"\"\"\n",
    "    formatted = entry.get('formatted_dose') or {}\n",
    "    if not isinstance(formatted, dict):\n",
    "        return None\n",
    "    \n",
    "    # Priority: Oral -> Insufflated -> First Available\n",
    "    roa_data = formatted.get('Oral')\n",
    "    if not roa_data:\n",
    "        roa_data = formatted.get('Insufflated')\n",
    "    if not roa_data and formatted:\n",
    "        roa_data = formatted[list(formatted.keys())[0]]\n",
    "        \n",
    "    if not isinstance(roa_data, dict):\n",
    "        return None\n",
    "        \n",
    "    # Priority: Common -> Light -> Strong -> Threshold\n",
    "    dose_str = roa_data.get('Common') or roa_data.get('Light') or roa_data.get('Strong') or roa_data.get('Threshold')\n",
    "    if not isinstance(dose_str, str):\n",
    "        return None\n",
    "        \n",
    "    # Regex to extract range and unit\n",
    "    # Matches: \"50-100ug\", \"10mg\", \"1.5ml\", \"1 - 2 g\"\n",
    "    # Group 1: Min, Group 2: Max (optional), Group 3: Unit\n",
    "    match = re.search(r'([\\d\\.]+)(?:\\s*-\\s*([\\d\\.]+))?\\s*([a-zA-Zµ]+)', dose_str)\n",
    "    if not match:\n",
    "        return None\n",
    "        \n",
    "    val_min = float(match.group(1))\n",
    "    val_max = float(match.group(2)) if match.group(2) else val_min\n",
    "    unit = match.group(3).lower()\n",
    "    \n",
    "    # Normalize Unit\n",
    "    if unit in ['ug', 'µg', 'mcg']:\n",
    "        unit = 'mcg'\n",
    "    elif unit in ['g', 'gram', 'grams']:\n",
    "        unit = 'g'\n",
    "    elif unit in ['mg', 'milligram', 'milligrams']:\n",
    "        unit = 'mg'\n",
    "    elif unit in ['ml', 'milliliter', 'milliliters']:\n",
    "        unit = 'ml'\n",
    "    elif unit in ['oz']:\n",
    "        unit = 'oz' # Keep as is, or convert? standard_unit usually implies metric. \n",
    "                     # But let's keep what's in drugs.json for now to allow user interpretation.\n",
    "    \n",
    "    avg_val = (val_min + val_max) / 2.0\n",
    "    return {'value': round(avg_val, 4), 'unit': unit}\n",
    "\n",
    "def build_export_substances() -> List[str]:\n",
    "    \"\"\"\n",
    "    Build export list from drugs.json, applying YAML excludes and alias de-duplication.\n",
    "    \"\"\"\n",
    "    out: List[str] = []\n",
    "    seen = set()\n",
    "    for k in sorted(drugs_raw.keys()):\n",
    "        n = normalize_name(k)\n",
    "        if not n or is_excluded(n):\n",
    "            continue\n",
    "        # alias de-dup: if this key is an alias and its target exists, skip this key\n",
    "        if n in TOL_ALIAS_MAP:\n",
    "            target = TOL_ALIAS_MAP[n]\n",
    "            if target in DRUG_KEY_BY_NORM and not is_excluded(target):\n",
    "                continue\n",
    "        if n in seen:\n",
    "            continue\n",
    "        seen.add(n)\n",
    "        out.append(DRUG_KEY_BY_NORM.get(n, k))\n",
    "    return out\n",
    "\n",
    "BUCKET_INDEX = {b: i for i, b in enumerate(BUCKETS)}\n",
    "\n",
    "def weights_to_neuro_buckets(\n",
    "    w: np.ndarray,\n",
    "    *,\n",
    "    threshold: float = 0.05,\n",
    "    allowed_buckets: Optional[set] = None,\n",
    " ) -> Dict[str, dict]:\n",
    "    \"\"\"\n",
    "    Convert weight vector -> neuro_buckets map.\n",
    "    \"\"\"\n",
    "    out: Dict[str, dict] = {}\n",
    "    eps = 0.001\n",
    "    if allowed_buckets is None:\n",
    "        idx_sorted = list(np.argsort(w)[::-1])\n",
    "        for i in idx_sorted:\n",
    "            wi = float(w[i])\n",
    "            if wi >= threshold:\n",
    "                b = BUCKETS[i]\n",
    "                out[b] = {'weight': round(wi, 3), 'tolerance_type': b}\n",
    "    else:\n",
    "        # deterministic order: use BUCKETS order\n",
    "        for b in BUCKETS:\n",
    "            if b not in allowed_buckets:\n",
    "                continue\n",
    "            wi = float(w[BUCKET_INDEX[b]])\n",
    "            if wi <= 0.0:\n",
    "                wi = eps\n",
    "            # keep present even if below threshold\n",
    "            out[b] = {'weight': round(wi, 3), 'tolerance_type': b}\n",
    "\n",
    "    if not out:\n",
    "        # fallback: keep at least one bucket\n",
    "        i = int(np.argmax(w))\n",
    "        b = BUCKETS[i]\n",
    "        out[b] = {'weight': round(max(float(w[i]), 0.1), 3), 'tolerance_type': b}\n",
    "    return out\n",
    "\n",
    "export_keys = build_export_substances()\n",
    "print('✓ Export substances (after exclude + alias de-dup):', len(export_keys))\n",
    "\n",
    "# Map Inspo keys to Drugs keys to help with overrides\n",
    "DRUGS_KEY_TO_INSPO = {}\n",
    "for inspo_name, inspo_data in (inspo.get('substances') or {}).items():\n",
    "    d_key = resolve_inspo_name_to_drugs_key(inspo_name)\n",
    "    if d_key:\n",
    "        DRUGS_KEY_TO_INSPO[d_key] = inspo_data\n",
    "\n",
    "# For each YAML group, choose a reference substance and compute its bucket *set*;\n",
    "GROUP_ALLOWED_BUCKETS: Dict[str, set] = {}\n",
    "for gid, g in TOL_GROUPS.items():\n",
    "    members = [m for m in (g.get('members') or []) if isinstance(m, str)]\n",
    "    canon = g.get('canonical') if isinstance(g.get('canonical'), str) else None\n",
    "    ref = None\n",
    "    if canon is not None and resolve_drugs_key(canon) in drugs_raw:\n",
    "        ref = resolve_drugs_key(canon)\n",
    "    if ref is None:\n",
    "        for m in members:\n",
    "            hit = resolve_drugs_key(m)\n",
    "            if hit is not None:\n",
    "                ref = hit\n",
    "                break\n",
    "    if ref is None:\n",
    "        continue\n",
    "    w_ref = predict_weights(ref)\n",
    "    allowed = {BUCKETS[i] for i in range(len(BUCKETS)) if float(w_ref[i]) >= 0.05}\n",
    "    if not allowed:\n",
    "        allowed = {BUCKETS[int(np.argmax(w_ref))]}\n",
    "    GROUP_ALLOWED_BUCKETS[gid] = allowed\n",
    "\n",
    "payload = {\n",
    "    'metadata': {\n",
    "        'generated_at': pd.Timestamp.utcnow().isoformat(),\n",
    "        'source_files': {\n",
    "            'drugs_json': str(DRUGS_PATH),\n",
    "            'baseline_json': str(BASELINE_PATH),\n",
    "            'inspo_json': str(INSPO_PATH),\n",
    "            'drug_interaction_yaml': str(YAML_PATH),\n",
    "        },\n",
    "        'buckets': BUCKETS,\n",
    "        'yaml_config': {\n",
    "            'exclude': sorted(TOL_EXCLUDE_SET),\n",
    "            'aliases': dict(TOL_ALIAS_MAP),\n",
    "            'groups': {gid: {'canonical': g.get('canonical'), 'members': g.get('members')} for gid, g in TOL_GROUPS.items()},\n",
    "            'separate': sorted(TOL_SEPARATE_SET),\n",
    "        },\n",
    "        'default_tolerance_params': dict(DEFAULT_TOLERANCE_PARAMS),\n",
    "        'notes': [\n",
    "            'Bucket weights are inferred from drugs.json using a heuristic prior + residual ML fit to inspo.json.',\n",
    "            'Group members share the same neuro-bucket keys; weights may differ.',\n",
    "            'Standard units are derived from drugs.json (Common/Light dose) or inspo.json.',\n",
    "        ],\n",
    "    },\n",
    "    'substances': {},\n",
    "}\n",
    "\n",
    "def is_same_unit(u1, u2):\n",
    "    return normalize_name(u1) == normalize_name(u2)\n",
    "\n",
    "for s in export_keys:\n",
    "    gid = tolerance_group_id(s)\n",
    "    allowed = GROUP_ALLOWED_BUCKETS.get(gid) if gid is not None else None\n",
    "    entry = drugs_raw.get(s) or {}\n",
    "    w = predict_weights(s)\n",
    "    neuro = weights_to_neuro_buckets(w, allowed_buckets=allowed)\n",
    "\n",
    "    params = dict(DEFAULT_TOLERANCE_PARAMS)\n",
    "    \n",
    "    # 1. Half-Life\n",
    "    hl = parse_half_life_hours_from_drugs(entry)\n",
    "    if isinstance(hl, (int, float)) and float(hl) > 0:\n",
    "        params['half_life_hours'] = round(float(hl), 3)\n",
    "\n",
    "    # 2. Standard Unit\n",
    "    # Try parsing from drugs.json first\n",
    "    derived_su = parse_standard_unit_from_drugs(entry)\n",
    "    if derived_su:\n",
    "        params['standard_unit'] = derived_su\n",
    "    \n",
    "    # Check inspo for missing or correction or params\n",
    "    inspo_su = None\n",
    "    if s in DRUGS_KEY_TO_INSPO:\n",
    "        inspo_data = DRUGS_KEY_TO_INSPO[s]\n",
    "        inspo_su = inspo_data.get('standard_unit')\n",
    "        \n",
    "        # Apply potency params from inspo if available\n",
    "        for p_key in ['potency_multiplier', 'duration_multiplier', 'tolerance_gain_rate', 'tolerance_decay_days']:\n",
    "            if p_key in inspo_data and isinstance(inspo_data[p_key], (int, float)):\n",
    "                params[p_key] = float(inspo_data[p_key])\n",
    "\n",
    "    # Standard Unit Fallback / Override\n",
    "    if inspo_su and isinstance(inspo_su, dict):\n",
    "        if not derived_su:\n",
    "            params['standard_unit'] = inspo_su\n",
    "        else:\n",
    "            # Enforce inspo for specific targets (Bupropion/Caffeine/MDMA/Ketamine)\n",
    "            s_norm = normalize_name(s)\n",
    "            if any(x in s_norm for x in ['bupropion', 'caffeine', 'mdma', 'ketamine']):\n",
    "                 params['standard_unit'] = inspo_su\n",
    "    \n",
    "    # 3. Explicit Safety Overrides for High Impact Substances\n",
    "    # Reduce potency multiplier for weak stimulants that are often used daily\n",
    "    s_norm = normalize_name(s)\n",
    "    if 'bupropion' in s_norm:\n",
    "         # Reduce to 30% impact relative to Dexedrine (1.0)\n",
    "         params['potency_multiplier'] = 0.3\n",
    "    elif 'caffeine' in s_norm:\n",
    "         # Reduce to 15% impact\n",
    "         params['potency_multiplier'] = 0.15\n",
    "\n",
    "    payload['substances'][s] = {\n",
    "        'neuro_buckets': neuro,\n",
    "        **params,\n",
    "    }\n",
    "\n",
    "with open(OUTPUT_JSON, 'w', encoding='utf-8') as f:\n",
    "    json.dump(payload, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print('✓ Wrote', OUTPUT_JSON.resolve())\n",
    "print('Substances exported:', len(payload['substances']))\n",
    "\n",
    "missing = [k for k, v in payload['substances'].items() if not (v.get('neuro_buckets') or {})]\n",
    "print('Missing neuro_buckets:', len(missing))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
