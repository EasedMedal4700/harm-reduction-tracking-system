{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84e447fa",
   "metadata": {},
   "source": [
    "# Tolerance Model: Neuro Bucket Inference\n",
    "\n",
    "Uses:\n",
    "- `../drugs.json` for per-substance metadata\n",
    "- `baseline.json` for the canonical bucket set\n",
    "- `inspo.json` as a reference target set to calibrate against\n",
    "\n",
    "Outputs:\n",
    "- `outputs/tolerance_neuro_buckets.json` (single JSON document; JSONB-ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0e95596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRUGS_PATH: C:\\Users\\USER\\dev\\code\\mobile_drug_use_app\\backend\\ML\\drugs.json\n",
      "BASELINE_PATH: C:\\Users\\USER\\dev\\code\\mobile_drug_use_app\\backend\\ML\\drug_tolerance_model\\baseline.json\n",
      "INSPO_PATH: C:\\Users\\USER\\dev\\code\\mobile_drug_use_app\\backend\\ML\\drug_tolerance_model\\inspo.json\n",
      "YAML_PATH: C:\\Users\\USER\\dev\\code\\mobile_drug_use_app\\backend\\ML\\drug_interaction.yaml\n",
      "OUTPUT_JSON: C:\\Users\\USER\\dev\\code\\mobile_drug_use_app\\backend\\ML\\drug_tolerance_model\\outputs\\tolerance_neuro_buckets.json\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "rng = np.random.default_rng(RANDOM_STATE)\n",
    "\n",
    "HERE = Path.cwd()\n",
    "DRUGS_PATH = Path('..') / 'drugs.json'\n",
    "BASELINE_PATH = Path('baseline.json')\n",
    "INSPO_PATH = Path('inspo.json')\n",
    "# Shared canonicalization config (exclude/aliases/groups)\n",
    "YAML_PATH = Path('..') / 'drug_interaction.yaml'\n",
    "OUTPUT_DIR = Path('outputs')\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_JSON = OUTPUT_DIR / 'tolerance_neuro_buckets.json'\n",
    "\n",
    "print('DRUGS_PATH:', DRUGS_PATH.resolve())\n",
    "print('BASELINE_PATH:', BASELINE_PATH.resolve())\n",
    "print('INSPO_PATH:', INSPO_PATH.resolve())\n",
    "print('YAML_PATH:', YAML_PATH.resolve())\n",
    "print('OUTPUT_JSON:', OUTPUT_JSON.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ccea2020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded drugs: 551\n",
      "✓ Loaded baseline buckets: ['stimulant', 'serotonin_release', 'serotonin_psychedelic', 'gaba', 'opioid', 'nmda', 'cannabinoid']\n",
      "✓ Loaded inspo substances: 19\n"
     ]
    }
   ],
   "source": [
    "def load_json(path: Path) -> dict:\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "drugs_raw = load_json(DRUGS_PATH)\n",
    "baseline = load_json(BASELINE_PATH)\n",
    "inspo = load_json(INSPO_PATH)\n",
    "\n",
    "BUCKETS: List[str] = list((baseline.get('buckets') or {}).keys())\n",
    "if not BUCKETS:\n",
    "    raise ValueError('No buckets found in baseline.json')\n",
    "\n",
    "print('✓ Loaded drugs:', len(drugs_raw))\n",
    "print('✓ Loaded baseline buckets:', BUCKETS)\n",
    "print('✓ Loaded inspo substances:', len((inspo.get('substances') or {})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00810a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded drug_interaction.yaml for tolerance\n",
      "  exclude: 11 aliases: 11 groups: 10 separate: 1\n"
     ]
    }
   ],
   "source": [
    "# Load shared YAML canonicalization (exclude/aliases/groups)\n",
    "import yaml\n",
    "\n",
    "def normalize_name(name: str) -> str:\n",
    "    return (name or '').strip().lower()\n",
    "\n",
    "def load_yaml(path: Path) -> dict:\n",
    "    if not path.exists():\n",
    "        return {}\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        obj = yaml.safe_load(f)\n",
    "    return obj if isinstance(obj, dict) else {}\n",
    "\n",
    "TOL_CFG = load_yaml(YAML_PATH)\n",
    "TOL_EXCLUDE_SET = {normalize_name(x) for x in (TOL_CFG.get('exclude') or []) if isinstance(x, str)}\n",
    "TOL_SEPARATE_SET = {normalize_name(x) for x in (TOL_CFG.get('separate') or []) if isinstance(x, str)}\n",
    "TOL_ALIAS_MAP = {\n",
    "    normalize_name(k): normalize_name(v)\n",
    "    for k, v in (TOL_CFG.get('aliases') or {}).items()\n",
    "    if isinstance(k, str) and isinstance(v, str)\n",
    "}\n",
    "\n",
    "# Groups: we do NOT merge for tolerance; we use them to share the same bucket *set* across members.\n",
    "TOL_GROUPS: Dict[str, dict] = {}\n",
    "TOL_MEMBER_TO_GROUP: Dict[str, str] = {}\n",
    "for group_name, g in (TOL_CFG.get('groups') or {}).items():\n",
    "    if not isinstance(g, dict):\n",
    "        continue\n",
    "    group_norm = normalize_name(group_name)\n",
    "    canon = normalize_name(g.get('canonical', group_name))\n",
    "    members = []\n",
    "    for m in (g.get('members') or []):\n",
    "        if isinstance(m, str):\n",
    "            members.append(normalize_name(m))\n",
    "    # also treat the group key itself as a member label\n",
    "    if group_norm not in members:\n",
    "        members.append(group_norm)\n",
    "    if canon not in members:\n",
    "        members.append(canon)\n",
    "\n",
    "    TOL_GROUPS[group_norm] = {\n",
    "        'canonical': canon,\n",
    "        'members': sorted(set(members)),\n",
    "    }\n",
    "    for m in TOL_GROUPS[group_norm]['members']:\n",
    "        # Respect separate: keep separate members un-grouped\n",
    "        if m in TOL_SEPARATE_SET:\n",
    "            continue\n",
    "        TOL_MEMBER_TO_GROUP[m] = group_norm\n",
    "\n",
    "# Map from normalized drugs.json key -> original key\n",
    "DRUG_KEY_BY_NORM = {normalize_name(k): k for k in drugs_raw.keys()}\n",
    "\n",
    "def is_excluded(name: str) -> bool:\n",
    "    return normalize_name(name) in TOL_EXCLUDE_SET\n",
    "\n",
    "def apply_alias(name: str) -> str:\n",
    "    n = normalize_name(name)\n",
    "    return TOL_ALIAS_MAP.get(n, n)\n",
    "\n",
    "def resolve_drugs_key(name: str) -> Optional[str]:\n",
    "    \"\"\"Resolve name -> drugs.json key after aliasing; None if excluded.\"\"\"\n",
    "    n = apply_alias(name)\n",
    "    if not n or is_excluded(n):\n",
    "        return None\n",
    "    return DRUG_KEY_BY_NORM.get(n)\n",
    "\n",
    "def tolerance_group_id(name: str) -> Optional[str]:\n",
    "    n = normalize_name(name)\n",
    "    return TOL_MEMBER_TO_GROUP.get(n)\n",
    "\n",
    "print('✓ Loaded drug_interaction.yaml for tolerance')\n",
    "print('  exclude:', len(TOL_EXCLUDE_SET), 'aliases:', len(TOL_ALIAS_MAP), 'groups:', len(TOL_GROUPS), 'separate:', len(TOL_SEPARATE_SET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "010cbe50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Feature extractor ready\n"
     ]
    }
   ],
   "source": [
    "def norm(s: str) -> str:\n",
    "    return (s or '').strip().lower()\n",
    "\n",
    "def _iter_str_list(x) -> List[str]:\n",
    "    if isinstance(x, list):\n",
    "        return [norm(v) for v in x if isinstance(v, str)]\n",
    "    return []\n",
    "\n",
    "def extract_features(substance: str, entry: dict) -> Dict[str, float]:\n",
    "    feats: Dict[str, float] = {}\n",
    "\n",
    "    # Categories are the most stable structured signal we have.\n",
    "    for c in _iter_str_list(entry.get('categories')):\n",
    "        feats[f'cat:{c}'] = 1.0\n",
    "\n",
    "    # PsychonautWiki effect keys (structured-ish, useful for mechanism hints)\n",
    "    pwe = entry.get('pweffects') or {}\n",
    "    if isinstance(pwe, dict):\n",
    "        for k in pwe.keys():\n",
    "            if isinstance(k, str):\n",
    "                feats[f'pwe:{norm(k)}'] = 1.0\n",
    "\n",
    "    # Formatted effects list (e.g., Sedative, Stimulation)\n",
    "    for fx in _iter_str_list(entry.get('formatted_effects')):\n",
    "        feats[f'fx:{fx}'] = 1.0\n",
    "\n",
    "    # Minimal parsing from properties.avoid (warning-like field)\n",
    "    props = entry.get('properties') or {}\n",
    "    if isinstance(props, dict):\n",
    "        avoid = props.get('avoid')\n",
    "        if isinstance(avoid, str):\n",
    "            a = norm(avoid)\n",
    "            if 'cns depressant' in a:\n",
    "                feats['warn:cns_depressant'] = 1.0\n",
    "            if 'serotonergic' in a:\n",
    "                feats['warn:serotonergic'] = 1.0\n",
    "            if 'maoi' in a:\n",
    "                feats['warn:maoi'] = 1.0\n",
    "\n",
    "    return feats\n",
    "\n",
    "print('✓ Feature extractor ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "839cd44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Heuristic prior ready\n"
     ]
    }
   ],
   "source": [
    "# Heuristic prior: fast rule-based mapping from categories/effects -> bucket weights\n",
    "# These priors do most of the work; ML learns residual corrections against inspo.json.\n",
    "PRIOR_KEYWORDS = {\n",
    "    'stimulant': [\n",
    "        'stimulant', 'dopamine', 'norepinephrine', 'adrenergic', 'amphetamine', 'cathinone',\n",
    "        'pwe:stimulation', 'fx:stimulation',\n",
    "    ],\n",
    "    'serotonin_release': [\n",
    "        'entactogen', 'empathogen', 'serotonin', 'mdma', 'mda',\n",
    "        'pwe:empathy, love, and sociability enhancement',\n",
    "        'fx:empathy',\n",
    "        'warn:serotonergic',\n",
    "    ],\n",
    "    'serotonin_psychedelic': [\n",
    "        'psychedelic', 'tryptamine', 'lysergamide', 'phenethylamine', '5-ht2a',\n",
    "        'pwe:hallucinations', 'fx:hallucinations',\n",
    "    ],\n",
    "    'gaba': [\n",
    "        'benzodiazepine', 'benzo', 'z-drug', 'depressant', 'sedative', 'gaba',\n",
    "        'pwe:sedation', 'fx:sedative', 'fx:hypnotic',\n",
    "        'warn:cns_depressant',\n",
    "    ],\n",
    "    'opioid': [\n",
    "        'opioid', 'opiate', 'pwe:respiratory depression',\n",
    "    ],\n",
    "    'nmda': [\n",
    "        'dissociative', 'nmda', 'ketamine',\n",
    "        'pwe:dissociation',\n",
    "    ],\n",
    "    'cannabinoid': [\n",
    "        'cannabinoid', 'thc', 'cannabis',\n",
    "    ],\n",
    "}\n",
    "\n",
    "def heuristic_prior(substance: str, entry: dict) -> np.ndarray:\n",
    "    feats = extract_features(substance, entry)\n",
    "    # Token set: feature keys + raw cat values + raw name string\n",
    "    tokens = set(feats.keys())\n",
    "    tokens |= {k.split(':', 1)[1] for k in feats.keys() if k.startswith('cat:')}\n",
    "    tokens.add(norm(substance))\n",
    "    w = np.zeros(len(BUCKETS), dtype=float)\n",
    "    for i, b in enumerate(BUCKETS):\n",
    "        kws = PRIOR_KEYWORDS.get(b, [])\n",
    "        score = 0\n",
    "        for kw in kws:\n",
    "            if kw in tokens:\n",
    "                score += 2 if (kw.startswith('pwe:') or kw.startswith('fx:') or kw.startswith('warn:')) else 1\n",
    "        # convert score -> weight\n",
    "        if score >= 3:\n",
    "            w[i] = 1.0\n",
    "        elif score == 2:\n",
    "            w[i] = 0.7\n",
    "        elif score == 1:\n",
    "            w[i] = 0.4\n",
    "        else:\n",
    "            w[i] = 0.0\n",
    "    return w\n",
    "\n",
    "print('✓ Heuristic prior ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "050fcb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Training rows: 18\n",
      "Missing inspo entries in drugs.json: []\n",
      "Excluded inspo entries (yaml exclude): ['melatonin']\n",
      "Target buckets: ['stimulant', 'serotonin_release', 'serotonin_psychedelic', 'gaba', 'opioid', 'nmda', 'cannabinoid']\n"
     ]
    }
   ],
   "source": [
    "# Build supervised training set from inspo.json\n",
    "inspo_substances = inspo.get('substances') or {}\n",
    "train_names = sorted([k for k in inspo_substances.keys() if isinstance(k, str)])\n",
    "\n",
    "# Optional manual mapping for inspo naming quirks -> drugs.json naming\n",
    "INSPO_TO_DRUGS_ALIASES = {\n",
    "    'dxm': 'dextromethorphan',\n",
    "    'psilocybin': 'psilocin',\n",
    "    'thc': 'cannabis',\n",
    "}\n",
    "\n",
    "def resolve_inspo_name_to_drugs_key(name: str) -> Optional[str]:\n",
    "    n = normalize_name(name)\n",
    "    n = INSPO_TO_DRUGS_ALIASES.get(n, n)\n",
    "    n = apply_alias(n)\n",
    "    if is_excluded(n):\n",
    "        return None\n",
    "    # direct hit\n",
    "    direct = resolve_drugs_key(n)\n",
    "    if direct is not None:\n",
    "        return direct\n",
    "    # group fallback: use canonical or any member that exists in drugs.json\n",
    "    gid = tolerance_group_id(n)\n",
    "    if gid is not None:\n",
    "        g = TOL_GROUPS.get(gid) or {}\n",
    "        canon = g.get('canonical')\n",
    "        if isinstance(canon, str):\n",
    "            hit = resolve_drugs_key(canon)\n",
    "            if hit is not None:\n",
    "                return hit\n",
    "        for m in (g.get('members') or []):\n",
    "            if isinstance(m, str):\n",
    "                hit = resolve_drugs_key(m)\n",
    "                if hit is not None:\n",
    "                    return hit\n",
    "    return None\n",
    "\n",
    "def target_vector_from_inspo(substance: str) -> np.ndarray:\n",
    "    obj = inspo_substances.get(substance) or {}\n",
    "    nb = obj.get('neuro_buckets') or {}\n",
    "    y = np.zeros(len(BUCKETS), dtype=float)\n",
    "    if isinstance(nb, dict):\n",
    "        for i, b in enumerate(BUCKETS):\n",
    "            if b in nb and isinstance(nb[b], dict):\n",
    "                w = nb[b].get('weight', 0.0)\n",
    "                if isinstance(w, (int, float)):\n",
    "                    y[i] = float(w)\n",
    "    return np.clip(y, 0.0, 1.0)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "prior = []\n",
    "missing_from_drugs = []\n",
    "excluded_from_training = []\n",
    "for s in train_names:\n",
    "    s_key = resolve_inspo_name_to_drugs_key(s)\n",
    "    if s_key is None:\n",
    "        # either excluded or not found\n",
    "        if is_excluded(s):\n",
    "            excluded_from_training.append(s)\n",
    "        else:\n",
    "            missing_from_drugs.append(s)\n",
    "        continue\n",
    "    entry = drugs_raw[s_key]\n",
    "    X.append(extract_features(s_key, entry))\n",
    "    y.append(target_vector_from_inspo(s))\n",
    "    prior.append(heuristic_prior(s_key, entry))\n",
    "\n",
    "X = list(X)\n",
    "y = np.vstack(y) if y else np.zeros((0, len(BUCKETS)))\n",
    "prior = np.vstack(prior) if prior else np.zeros((0, len(BUCKETS)))\n",
    "print('✓ Training rows:', len(X))\n",
    "print('Missing inspo entries in drugs.json:', missing_from_drugs)\n",
    "print('Excluded inspo entries (yaml exclude):', excluded_from_training)\n",
    "print('Target buckets:', BUCKETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62787509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Trained residual model\n",
      "Mean MAE vs inspo: 0.026984240605400736\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>substance</th>\n",
       "      <th>drugs_key</th>\n",
       "      <th>mae</th>\n",
       "      <th>true:stimulant</th>\n",
       "      <th>pred:stimulant</th>\n",
       "      <th>true:serotonin_release</th>\n",
       "      <th>pred:serotonin_release</th>\n",
       "      <th>true:serotonin_psychedelic</th>\n",
       "      <th>pred:serotonin_psychedelic</th>\n",
       "      <th>true:gaba</th>\n",
       "      <th>pred:gaba</th>\n",
       "      <th>true:opioid</th>\n",
       "      <th>pred:opioid</th>\n",
       "      <th>true:nmda</th>\n",
       "      <th>pred:nmda</th>\n",
       "      <th>true:cannabinoid</th>\n",
       "      <th>pred:cannabinoid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mdma</td>\n",
       "      <td>mdma</td>\n",
       "      <td>0.093330</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.468550</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.786762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.298442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017865</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dexedrine</td>\n",
       "      <td>dexedrine</td>\n",
       "      <td>0.082608</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.563269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.101049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036802</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>psilocybin</td>\n",
       "      <td>psilocin</td>\n",
       "      <td>0.081186</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225552</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.665767</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bupropion</td>\n",
       "      <td>bupropion</td>\n",
       "      <td>0.047384</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.459196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005655</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ghb</td>\n",
       "      <td>ghb</td>\n",
       "      <td>0.044425</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.046636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.763992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>morphine</td>\n",
       "      <td>morphine</td>\n",
       "      <td>0.020259</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099216</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bromazolam</td>\n",
       "      <td>bromazolam</td>\n",
       "      <td>0.020016</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.036402</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.103709</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alcohol</td>\n",
       "      <td>alcohol</td>\n",
       "      <td>0.016669</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.185954</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001126</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.884178</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.214352</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.568439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mdpv</td>\n",
       "      <td>mdpv</td>\n",
       "      <td>0.014582</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.907213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>thc</td>\n",
       "      <td>cannabis</td>\n",
       "      <td>0.014257</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.013833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003043</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.976471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>caffeine</td>\n",
       "      <td>caffeine</td>\n",
       "      <td>0.011773</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.373561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002617</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>diazepam</td>\n",
       "      <td>diazepam</td>\n",
       "      <td>0.010355</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.008384</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.992032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>lsd</td>\n",
       "      <td>lsd</td>\n",
       "      <td>0.008739</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.023248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003850</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.974660</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002964</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dxm</td>\n",
       "      <td>dextromethorphan</td>\n",
       "      <td>0.006470</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.174867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007870</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.690002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>nicotine</td>\n",
       "      <td>nicotine</td>\n",
       "      <td>0.005857</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.017519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>methylphenidate</td>\n",
       "      <td>methylphenidate</td>\n",
       "      <td>0.003089</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.984268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ketamine</td>\n",
       "      <td>ketamine</td>\n",
       "      <td>0.002455</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999907</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>flutoprazepam</td>\n",
       "      <td>flutoprazepam</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012874</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001983</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          substance         drugs_key       mae  true:stimulant  \\\n",
       "11             mdma              mdma  0.093330            0.35   \n",
       "4         dexedrine         dexedrine  0.082608            1.00   \n",
       "16       psilocybin          psilocin  0.081186            0.00   \n",
       "2         bupropion         bupropion  0.047384            0.20   \n",
       "8               ghb               ghb  0.044425            0.00   \n",
       "14         morphine          morphine  0.020259            0.00   \n",
       "1        bromazolam        bromazolam  0.020016            0.00   \n",
       "0           alcohol           alcohol  0.016669            0.20   \n",
       "12             mdpv              mdpv  0.014582            1.00   \n",
       "17              thc          cannabis  0.014257            0.00   \n",
       "3          caffeine          caffeine  0.011773            0.30   \n",
       "5          diazepam          diazepam  0.010355            0.00   \n",
       "10              lsd               lsd  0.008739            0.00   \n",
       "6               dxm  dextromethorphan  0.006470            0.00   \n",
       "15         nicotine          nicotine  0.005857            0.05   \n",
       "13  methylphenidate   methylphenidate  0.003089            1.00   \n",
       "9          ketamine          ketamine  0.002455            0.00   \n",
       "7     flutoprazepam     flutoprazepam  0.002262            0.00   \n",
       "\n",
       "    pred:stimulant  true:serotonin_release  pred:serotonin_release  \\\n",
       "11        0.468550                     1.0                0.786762   \n",
       "4         0.563269                     0.0                0.101049   \n",
       "16        0.000000                     0.0                0.225552   \n",
       "2         0.459196                     0.0                0.063022   \n",
       "8         0.046636                     0.0                0.023770   \n",
       "14        0.014700                     0.0                0.000000   \n",
       "1         0.036402                     0.0                0.000000   \n",
       "0         0.185954                     0.0                0.038951   \n",
       "12        0.907213                     0.0                0.000000   \n",
       "17        0.013833                     0.0                0.000104   \n",
       "3         0.373561                     0.0                0.000000   \n",
       "5         0.008384                     0.0                0.000000   \n",
       "10        0.023248                     0.0                0.003850   \n",
       "6         0.000000                     0.2                0.174867   \n",
       "15        0.017519                     0.0                0.005136   \n",
       "13        0.984268                     0.0                0.002034   \n",
       "9         0.000000                     0.0                0.011481   \n",
       "7         0.000000                     0.0                0.012874   \n",
       "\n",
       "    true:serotonin_psychedelic  pred:serotonin_psychedelic  true:gaba  \\\n",
       "11                         0.0                    0.298442        0.0   \n",
       "4                          0.0                    0.000000        0.0   \n",
       "16                         1.0                    0.665767        0.0   \n",
       "2                          0.0                    0.000000        0.0   \n",
       "8                          0.0                    0.000000        1.0   \n",
       "14                         0.0                    0.000000        0.0   \n",
       "1                          0.0                    0.103709        1.0   \n",
       "0                          0.0                    0.001126        0.9   \n",
       "12                         0.0                    0.008167        0.0   \n",
       "17                         0.0                    0.018256        0.0   \n",
       "3                          0.0                    0.000000        0.0   \n",
       "5                          0.0                    0.000000        1.0   \n",
       "10                         1.0                    0.974660        0.0   \n",
       "6                          0.0                    0.002286        0.0   \n",
       "15                         0.0                    0.000000        0.0   \n",
       "13                         0.0                    0.000000        0.0   \n",
       "9                          0.0                    0.001160        0.0   \n",
       "7                          0.0                    0.000000        1.0   \n",
       "\n",
       "    pred:gaba  true:opioid  pred:opioid  true:nmda  pred:nmda  \\\n",
       "11   0.017865          0.0     0.000000        0.0   0.000000   \n",
       "4    0.036802          0.0     0.000000        0.0   0.000822   \n",
       "16   0.000000          0.0     0.005366        0.0   0.000870   \n",
       "2    0.000000          0.0     0.005655        0.0   0.000134   \n",
       "8    0.763992          0.0     0.000000        0.0   0.001670   \n",
       "14   0.099216          1.0     0.986169        0.0   0.013488   \n",
       "1    1.000000          0.0     0.000000        0.0   0.000000   \n",
       "0    0.884178          0.2     0.214352        0.6   0.568439   \n",
       "12   0.000000          0.0     0.000000        0.0   0.000000   \n",
       "17   0.041037          0.0     0.000000        0.0   0.003043   \n",
       "3    0.006230          0.0     0.000000        0.0   0.002617   \n",
       "5    0.992032          0.0     0.039586        0.0   0.012484   \n",
       "10   0.000000          0.0     0.002019        0.0   0.002964   \n",
       "6    0.000000          0.0     0.007870        0.7   0.690002   \n",
       "15   0.000000          0.0     0.000000        0.0   0.003386   \n",
       "13   0.000000          0.0     0.000000        0.0   0.001364   \n",
       "9    0.000000          0.0     0.000000        1.0   0.999907   \n",
       "7    1.000000          0.0     0.000000        0.0   0.001983   \n",
       "\n",
       "    true:cannabinoid  pred:cannabinoid  \n",
       "11               0.0          0.005214  \n",
       "4                0.0          0.002854  \n",
       "16               0.0          0.002281  \n",
       "2                0.0          0.003680  \n",
       "8                0.0          0.002894  \n",
       "14               0.0          0.000582  \n",
       "1                0.0          0.000000  \n",
       "0                0.0          0.000828  \n",
       "12               0.0          0.001119  \n",
       "17               1.0          0.976471  \n",
       "3                0.0          0.000000  \n",
       "5                0.0          0.004061  \n",
       "10               0.0          0.003755  \n",
       "6                0.0          0.000000  \n",
       "15               0.0          0.000000  \n",
       "13               0.0          0.002489  \n",
       "9                0.0          0.004448  \n",
       "7                0.0          0.000981  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train residual model: predicts (target - heuristic_prior) from drugs.json features\n",
    "# We disable intercept so unknown/unseen feature rows don't get a drifting baseline residual.\n",
    "residual = y - prior\n",
    "\n",
    "model: Pipeline = Pipeline([\n",
    "    ('vec', DictVectorizer(sparse=True)),\n",
    "    ('reg', MultiOutputRegressor(Ridge(alpha=2.0, fit_intercept=False, random_state=RANDOM_STATE))),\n",
    "])\n",
    "model.fit(X, residual)\n",
    "print('✓ Trained residual model')\n",
    "\n",
    "def predict_weights(drugs_key: str) -> np.ndarray:\n",
    "    k = normalize_name(drugs_key)\n",
    "    if is_excluded(k):\n",
    "        return np.zeros(len(BUCKETS), dtype=float)\n",
    "    entry = drugs_raw.get(drugs_key) or {}\n",
    "    p = heuristic_prior(drugs_key, entry)\n",
    "    r = model.predict([extract_features(drugs_key, entry)])[0]\n",
    "    w = np.clip(p + r, 0.0, 1.0)\n",
    "    if float(w.max()) <= 0.0:\n",
    "        idx = int(np.argmax(p)) if float(p.max()) > 0 else 0\n",
    "        w[idx] = 0.1\n",
    "    return w\n",
    "\n",
    "def eval_against_inspo() -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for s in train_names:\n",
    "        s_key = resolve_inspo_name_to_drugs_key(s)\n",
    "        if s_key is None:\n",
    "            continue\n",
    "        y_true = target_vector_from_inspo(s)\n",
    "        y_pred = predict_weights(s_key)\n",
    "        row = {'substance': s, 'drugs_key': s_key, 'mae': float(np.mean(np.abs(y_true - y_pred)))}\n",
    "        for i, b in enumerate(BUCKETS):\n",
    "            row[f'true:{b}'] = float(y_true[i])\n",
    "            row[f'pred:{b}'] = float(y_pred[i])\n",
    "        rows.append(row)\n",
    "    return pd.DataFrame(rows).sort_values('mae', ascending=False)\n",
    "\n",
    "df_eval = eval_against_inspo()\n",
    "print('Mean MAE vs inspo:', float(df_eval['mae'].mean()) if len(df_eval) else None)\n",
    "df_eval.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "484c1a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Export substances (after exclude + alias de-dup): 538\n",
      "✓ Wrote C:\\Users\\USER\\dev\\code\\mobile_drug_use_app\\backend\\ML\\drug_tolerance_model\\outputs\\tolerance_neuro_buckets.json\n",
      "Substances exported: 538\n",
      "Missing neuro_buckets: 0\n"
     ]
    }
   ],
   "source": [
    "# Export: neuro_buckets for all substances (JSONB-ready)\n",
    "import re\n",
    "\n",
    "DEFAULT_TOLERANCE_PARAMS = {\n",
    "    'half_life_hours': 12.0,\n",
    "    'active_threshold': 0.05,\n",
    "    'standard_unit_mg': 10.0,\n",
    "    'potency_multiplier': 1.0,\n",
    "    'duration_multiplier': 1.2,\n",
    "    'tolerance_gain_rate': 0.25,\n",
    "    'tolerance_decay_days': 5.0,\n",
    "}\n",
    "\n",
    "def parse_half_life_hours_from_drugs(entry: dict) -> Optional[float]:\n",
    "    \"\"\"Best-effort parse of drugs.json properties['half-life'] into hours.\"\"\"\n",
    "    props = entry.get('properties') or {}\n",
    "    if not isinstance(props, dict):\n",
    "        return None\n",
    "    hl = props.get('half-life') or props.get('half_life')\n",
    "    if not isinstance(hl, str):\n",
    "        return None\n",
    "    s = hl.strip().lower()\n",
    "    if not s:\n",
    "        return None\n",
    "    # Extract 1-2 numbers; if range, average\n",
    "    nums = [float(x) for x in re.findall(r'\\d+(?:\\.\\d+)?', s)[:2]]\n",
    "    if not nums:\n",
    "        return None\n",
    "    value = nums[0] if len(nums) == 1 else (nums[0] + nums[1]) / 2.0\n",
    "    # Unit handling\n",
    "    if 'minute' in s or 'min' in s:\n",
    "        return value / 60.0\n",
    "    if 'day' in s:\n",
    "        return value * 24.0\n",
    "    if 'hour' in s or 'hr' in s:\n",
    "        return value\n",
    "    # Unknown unit: assume hours only if the string mentions half-life in hours-like context\n",
    "    return None\n",
    "\n",
    "def build_export_substances() -> List[str]:\n",
    "    \"\"\"\n",
    "    Build export list from drugs.json, applying YAML excludes and alias de-duplication.\n",
    "\n",
    "    - Excluded substances are skipped\n",
    "    - Alias keys are skipped if their alias target exists in drugs.json\n",
    "    - Group members are NOT merged; they remain separate entries\n",
    "    \"\"\"\n",
    "    out: List[str] = []\n",
    "    seen = set()\n",
    "    for k in sorted(drugs_raw.keys()):\n",
    "        n = normalize_name(k)\n",
    "        if not n or is_excluded(n):\n",
    "            continue\n",
    "        # alias de-dup: if this key is an alias and its target exists, skip this key\n",
    "        if n in TOL_ALIAS_MAP:\n",
    "            target = TOL_ALIAS_MAP[n]\n",
    "            if target in DRUG_KEY_BY_NORM and not is_excluded(target):\n",
    "                continue\n",
    "        if n in seen:\n",
    "            continue\n",
    "        seen.add(n)\n",
    "        out.append(DRUG_KEY_BY_NORM.get(n, k))\n",
    "    return out\n",
    "\n",
    "BUCKET_INDEX = {b: i for i, b in enumerate(BUCKETS)}\n",
    "\n",
    "def weights_to_neuro_buckets(\n",
    "    w: np.ndarray,\n",
    "    *,\n",
    "    threshold: float = 0.05,\n",
    "    allowed_buckets: Optional[set] = None,\n",
    " ) -> Dict[str, dict]:\n",
    "    \"\"\"\n",
    "    Convert weight vector -> neuro_buckets map.\n",
    "\n",
    "    If allowed_buckets is provided, enforce the same bucket *set* for grouped substances,\n",
    "    while allowing weights to differ. Buckets in allowed_buckets are included even if below threshold\n",
    "    (floored slightly to keep the key present).\n",
    "    \"\"\"\n",
    "    out: Dict[str, dict] = {}\n",
    "    eps = 0.001\n",
    "    if allowed_buckets is None:\n",
    "        idx_sorted = list(np.argsort(w)[::-1])\n",
    "        for i in idx_sorted:\n",
    "            wi = float(w[i])\n",
    "            if wi >= threshold:\n",
    "                b = BUCKETS[i]\n",
    "                out[b] = {'weight': round(wi, 3), 'tolerance_type': b}\n",
    "    else:\n",
    "        # deterministic order: use BUCKETS order\n",
    "        for b in BUCKETS:\n",
    "            if b not in allowed_buckets:\n",
    "                continue\n",
    "            wi = float(w[BUCKET_INDEX[b]])\n",
    "            if wi <= 0.0:\n",
    "                wi = eps\n",
    "            # keep present even if below threshold\n",
    "            out[b] = {'weight': round(wi, 3), 'tolerance_type': b}\n",
    "\n",
    "    if not out:\n",
    "        # fallback: keep at least one bucket\n",
    "        i = int(np.argmax(w))\n",
    "        b = BUCKETS[i]\n",
    "        out[b] = {'weight': round(max(float(w[i]), 0.1), 3), 'tolerance_type': b}\n",
    "    return out\n",
    "\n",
    "export_keys = build_export_substances()\n",
    "print('✓ Export substances (after exclude + alias de-dup):', len(export_keys))\n",
    "\n",
    "# For each YAML group, choose a reference substance and compute its bucket *set*;\n",
    "# all members will share this set (weights may differ).\n",
    "GROUP_ALLOWED_BUCKETS: Dict[str, set] = {}\n",
    "for gid, g in TOL_GROUPS.items():\n",
    "    members = [m for m in (g.get('members') or []) if isinstance(m, str)]\n",
    "    canon = g.get('canonical') if isinstance(g.get('canonical'), str) else None\n",
    "    # pick reference: canonical if present, else first present member\n",
    "    ref = None\n",
    "    if canon is not None and resolve_drugs_key(canon) in drugs_raw:\n",
    "        ref = resolve_drugs_key(canon)\n",
    "    if ref is None:\n",
    "        for m in members:\n",
    "            hit = resolve_drugs_key(m)\n",
    "            if hit is not None:\n",
    "                ref = hit\n",
    "                break\n",
    "    if ref is None:\n",
    "        continue\n",
    "    w_ref = predict_weights(ref)\n",
    "    # determine bucket set from reference using normal thresholding\n",
    "    allowed = {BUCKETS[i] for i in range(len(BUCKETS)) if float(w_ref[i]) >= 0.05}\n",
    "    if not allowed:\n",
    "        allowed = {BUCKETS[int(np.argmax(w_ref))]}\n",
    "    GROUP_ALLOWED_BUCKETS[gid] = allowed\n",
    "\n",
    "payload = {\n",
    "    'metadata': {\n",
    "        'generated_at': pd.Timestamp.utcnow().isoformat(),\n",
    "        'source_files': {\n",
    "            'drugs_json': str(DRUGS_PATH),\n",
    "            'baseline_json': str(BASELINE_PATH),\n",
    "            'inspo_json': str(INSPO_PATH),\n",
    "            'drug_interaction_yaml': str(YAML_PATH),\n",
    "        },\n",
    "        'buckets': BUCKETS,\n",
    "        'yaml_config': {\n",
    "            'exclude': sorted(TOL_EXCLUDE_SET),\n",
    "            'aliases': dict(TOL_ALIAS_MAP),\n",
    "            'groups': {gid: {'canonical': g.get('canonical'), 'members': g.get('members')} for gid, g in TOL_GROUPS.items()},\n",
    "            'separate': sorted(TOL_SEPARATE_SET),\n",
    "        },\n",
    "        'default_tolerance_params': dict(DEFAULT_TOLERANCE_PARAMS),\n",
    "        'notes': [\n",
    "            'Bucket weights are inferred from drugs.json using a heuristic prior + residual ML fit to inspo.json.',\n",
    "            'Excluded substances (yaml) are omitted from the export.',\n",
    "            'Alias keys are de-duplicated (only the alias target is exported when present).',\n",
    "            'Group members share the same neuro-bucket keys; weights may differ per substance.',\n",
    "            'Tolerance parameters are exported per substance; half_life_hours is parsed from drugs.json when available, otherwise defaults apply.',\n",
    "            'This is a single JSON document suitable for Postgres JSONB.',\n",
    "        ],\n",
    "    },\n",
    "    'substances': {},\n",
    "}\n",
    "\n",
    "for s in export_keys:\n",
    "    gid = tolerance_group_id(s)\n",
    "    allowed = GROUP_ALLOWED_BUCKETS.get(gid) if gid is not None else None\n",
    "    entry = drugs_raw.get(s) or {}\n",
    "    w = predict_weights(s)\n",
    "    neuro = weights_to_neuro_buckets(w, allowed_buckets=allowed)\n",
    "\n",
    "    params = dict(DEFAULT_TOLERANCE_PARAMS)\n",
    "    hl = parse_half_life_hours_from_drugs(entry)\n",
    "    if isinstance(hl, (int, float)) and float(hl) > 0:\n",
    "        params['half_life_hours'] = round(float(hl), 3)\n",
    "\n",
    "    payload['substances'][s] = {\n",
    "        'neuro_buckets': neuro,\n",
    "        **params,\n",
    "    }\n",
    "\n",
    "with open(OUTPUT_JSON, 'w', encoding='utf-8') as f:\n",
    "    json.dump(payload, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print('✓ Wrote', OUTPUT_JSON.resolve())\n",
    "print('Substances exported:', len(payload['substances']))\n",
    "\n",
    "missing = [k for k, v in payload['substances'].items() if not (v.get('neuro_buckets') or {})]\n",
    "print('Missing neuro_buckets:', len(missing))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
