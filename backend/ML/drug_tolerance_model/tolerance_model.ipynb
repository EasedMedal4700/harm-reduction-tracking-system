{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84e447fa",
   "metadata": {},
   "source": [
    "# Tolerance Model: Neuro Bucket Inference\n",
    "\n",
    "Uses:\n",
    "- `../drugs.json` for per-substance metadata\n",
    "- `baseline.json` for the canonical bucket set\n",
    "- `inspo.json` as a reference target set to calibrate against\n",
    "\n",
    "Outputs:\n",
    "- `outputs/tolerance_neuro_buckets.json` (single JSON document; JSONB-ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d0e95596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRUGS_PATH: C:\\Users\\USER\\dev\\code\\mobile_drug_use_app\\backend\\ML\\drugs.json\n",
      "BASELINE_PATH: C:\\Users\\USER\\dev\\code\\mobile_drug_use_app\\backend\\ML\\drug_tolerance_model\\baseline.json\n",
      "INSPO_PATH: C:\\Users\\USER\\dev\\code\\mobile_drug_use_app\\backend\\ML\\drug_tolerance_model\\inspo.json\n",
      "YAML_PATH: C:\\Users\\USER\\dev\\code\\mobile_drug_use_app\\backend\\ML\\drug_interaction.yaml\n",
      "OUTPUT_JSON: C:\\Users\\USER\\dev\\code\\mobile_drug_use_app\\backend\\ML\\drug_tolerance_model\\outputs\\tolerance_neuro_buckets.json\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "rng = np.random.default_rng(RANDOM_STATE)\n",
    "\n",
    "HERE = Path.cwd()\n",
    "DRUGS_PATH = Path('..') / 'drugs.json'\n",
    "BASELINE_PATH = Path('baseline.json')\n",
    "INSPO_PATH = Path('inspo.json')\n",
    "# Shared canonicalization config (exclude/aliases/groups)\n",
    "YAML_PATH = Path('..') / 'drug_interaction.yaml'\n",
    "OUTPUT_DIR = Path('outputs')\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_JSON = OUTPUT_DIR / 'tolerance_neuro_buckets.json'\n",
    "\n",
    "print('DRUGS_PATH:', DRUGS_PATH.resolve())\n",
    "print('BASELINE_PATH:', BASELINE_PATH.resolve())\n",
    "print('INSPO_PATH:', INSPO_PATH.resolve())\n",
    "print('YAML_PATH:', YAML_PATH.resolve())\n",
    "print('OUTPUT_JSON:', OUTPUT_JSON.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ccea2020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded drugs: 555\n",
      "✓ Loaded baseline buckets: ['stimulant', 'serotonin_release', 'serotonin_psychedelic', 'gaba', 'opioid', 'nmda', 'cannabinoid']\n",
      "✓ Loaded inspo substances: 123\n"
     ]
    }
   ],
   "source": [
    "def load_json(path: Path) -> dict:\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "drugs_raw = load_json(DRUGS_PATH)\n",
    "baseline = load_json(BASELINE_PATH)\n",
    "inspo = load_json(INSPO_PATH)\n",
    "\n",
    "BUCKETS: List[str] = list((baseline.get('buckets') or {}).keys())\n",
    "if not BUCKETS:\n",
    "    raise ValueError('No buckets found in baseline.json')\n",
    "\n",
    "print('✓ Loaded drugs:', len(drugs_raw))\n",
    "print('✓ Loaded baseline buckets:', BUCKETS)\n",
    "print('✓ Loaded inspo substances:', len((inspo.get('substances') or {})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "00810a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded drug_interaction.yaml for tolerance\n",
      "  exclude_all: 26 exclude_neuro: 4 aliases: 11 groups: 10 separate: 1\n"
     ]
    }
   ],
   "source": [
    "# Load shared YAML canonicalization (exclude/aliases/groups)\n",
    "import yaml\n",
    "\n",
    "def normalize_name(name: str) -> str:\n",
    "    return (name or '').strip().lower()\n",
    "\n",
    "def load_yaml(path: Path) -> dict:\n",
    "    if not path.exists():\n",
    "        return {}\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        obj = yaml.safe_load(f)\n",
    "    return obj if isinstance(obj, dict) else {}\n",
    "\n",
    "def _yaml_list(cfg: dict, *keys: str) -> List[str]:\n",
    "    out: List[str] = []\n",
    "    for k in keys:\n",
    "        v = cfg.get(k)\n",
    "        if isinstance(v, list):\n",
    "            out.extend([x for x in v if isinstance(x, str)])\n",
    "    return out\n",
    "\n",
    "TOL_CFG = load_yaml(YAML_PATH)\n",
    "\n",
    "# YAML schema supports multiple keys (user-editable)\n",
    "# - exclude from all: excluded everywhere\n",
    "# - exlude from neuro-bucket: excluded only from tolerance model (typo preserved)\n",
    "EXCLUDE_ALL = _yaml_list(TOL_CFG, 'exclude', 'exclude from all', 'exclude_from_all')\n",
    "EXCLUDE_NEURO = _yaml_list(TOL_CFG, 'exclude from neuro-bucket', 'exlude from neuro-bucket', 'exclude_from_neuro_bucket', 'exclude_from_neuro-bucket')\n",
    "\n",
    "TOL_EXCLUDE_SET = {normalize_name(x) for x in (EXCLUDE_ALL + EXCLUDE_NEURO) if isinstance(x, str)}\n",
    "TOL_SEPARATE_SET = {normalize_name(x) for x in (TOL_CFG.get('separate') or []) if isinstance(x, str)}\n",
    "TOL_ALIAS_MAP = {\n",
    "    normalize_name(k): normalize_name(v)\n",
    "    for k, v in (TOL_CFG.get('aliases') or {}).items()\n",
    "    if isinstance(k, str) and isinstance(v, str)\n",
    "}\n",
    "\n",
    "# Groups: we do NOT merge for tolerance; we use them to share the same bucket *set* across members.\n",
    "TOL_GROUPS: Dict[str, dict] = {}\n",
    "TOL_MEMBER_TO_GROUP: Dict[str, str] = {}\n",
    "for group_name, g in (TOL_CFG.get('groups') or {}).items():\n",
    "    if not isinstance(g, dict):\n",
    "        continue\n",
    "    group_norm = normalize_name(group_name)\n",
    "    canon = normalize_name(g.get('canonical', group_name))\n",
    "    members = []\n",
    "    for m in (g.get('members') or []):\n",
    "        if isinstance(m, str):\n",
    "            members.append(normalize_name(m))\n",
    "    # also treat the group key itself as a member label\n",
    "    if group_norm not in members:\n",
    "        members.append(group_norm)\n",
    "    if canon not in members:\n",
    "        members.append(canon)\n",
    "\n",
    "    TOL_GROUPS[group_norm] = {\n",
    "        'canonical': canon,\n",
    "        'members': sorted(set(members)),\n",
    "    }\n",
    "    for m in TOL_GROUPS[group_norm]['members']:\n",
    "        # Respect separate: keep separate members un-grouped\n",
    "        if m in TOL_SEPARATE_SET:\n",
    "            continue\n",
    "        TOL_MEMBER_TO_GROUP[m] = group_norm\n",
    "\n",
    "# Map from normalized drugs.json key -> original key\n",
    "DRUG_KEY_BY_NORM = {normalize_name(k): k for k in drugs_raw.keys()}\n",
    "\n",
    "def is_excluded(name: str) -> bool:\n",
    "    return normalize_name(name) in TOL_EXCLUDE_SET\n",
    "\n",
    "def apply_alias(name: str) -> str:\n",
    "    n = normalize_name(name)\n",
    "    return TOL_ALIAS_MAP.get(n, n)\n",
    "\n",
    "def resolve_drugs_key(name: str) -> Optional[str]:\n",
    "    \"\"\"Resolve name -> drugs.json key after aliasing; None if excluded.\"\"\"\n",
    "    n = apply_alias(name)\n",
    "    if not n or is_excluded(n):\n",
    "        return None\n",
    "    return DRUG_KEY_BY_NORM.get(n)\n",
    "\n",
    "def tolerance_group_id(name: str) -> Optional[str]:\n",
    "    n = normalize_name(name)\n",
    "    return TOL_MEMBER_TO_GROUP.get(n)\n",
    "\n",
    "print('✓ Loaded drug_interaction.yaml for tolerance')\n",
    "print('  exclude_all:', len(EXCLUDE_ALL), 'exclude_neuro:', len(EXCLUDE_NEURO), 'aliases:', len(TOL_ALIAS_MAP), 'groups:', len(TOL_GROUPS), 'separate:', len(TOL_SEPARATE_SET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c3a32e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Supabase category refresh: ok (522 rows)\n"
     ]
    }
   ],
   "source": [
    "# Optional: Refresh categories from Supabase (drug_profiles table) to补 missing/updated categories in drugs.json\n",
    "# - Uses SUPABASE_URL and SUPABASE_ANON_KEY from .env at workspace root\n",
    "# - Does NOT print secrets\n",
    "import os\n",
    "import requests\n",
    "\n",
    "def load_dotenv_simple(dotenv_path: Path) -> None:\n",
    "    if not dotenv_path.exists():\n",
    "        return\n",
    "    for raw in dotenv_path.read_text(encoding='utf-8').splitlines():\n",
    "        line = raw.strip()\n",
    "        if not line or line.startswith('#') or '=' not in line:\n",
    "            continue\n",
    "        k, v = line.split('=', 1)\n",
    "        k = k.strip()\n",
    "        v = v.strip().strip('\"').strip(\"'\")\n",
    "        # don't override existing env vars\n",
    "        os.environ.setdefault(k, v)\n",
    "\n",
    "# repo root is two levels up from this notebook folder: backend/ML/drug_tolerance_model\n",
    "DOTENV_PATH = Path('..') / '..' / '..' / '.env'\n",
    "DOTENV_PATH = DOTENV_PATH.resolve()\n",
    "load_dotenv_simple(DOTENV_PATH)\n",
    "\n",
    "SUPABASE_URL = os.environ.get('SUPABASE_URL')\n",
    "SUPABASE_ANON_KEY = os.environ.get('SUPABASE_ANON_KEY')\n",
    "\n",
    "def _postgrest_get(table: str, select: str, limit: int = 10000) -> list:\n",
    "    if not SUPABASE_URL or not SUPABASE_ANON_KEY:\n",
    "        return []\n",
    "    url = SUPABASE_URL.rstrip('/') + f'/rest/v1/{table}'\n",
    "    headers = {\n",
    "        'apikey': SUPABASE_ANON_KEY,\n",
    "        'Authorization': f'Bearer {SUPABASE_ANON_KEY}',\n",
    "        'Accept': 'application/json',\n",
    "    }\n",
    "    params = {\n",
    "        'select': select,\n",
    "        'limit': str(limit),\n",
    "    }\n",
    "    resp = requests.get(url, headers=headers, params=params, timeout=20)\n",
    "    if resp.status_code >= 400:\n",
    "        raise RuntimeError(f'PostgREST error {resp.status_code}: {resp.text[:300]}')\n",
    "    data = resp.json()\n",
    "    return data if isinstance(data, list) else []\n",
    "\n",
    "def _extract_row_key(row: dict) -> Optional[str]:\n",
    "    # Try a few common column names\n",
    "    for k in ['substance', 'substance_key', 'drug_key', 'drug', 'name', 'slug', 'id']:\n",
    "        v = row.get(k)\n",
    "        if isinstance(v, str) and v.strip():\n",
    "            return v.strip()\n",
    "    return None\n",
    "\n",
    "def _normalize_categories(value) -> List[str]:\n",
    "    if value is None:\n",
    "        return []\n",
    "    if isinstance(value, list):\n",
    "        return [normalize_name(x) for x in value if isinstance(x, str) and x.strip()]\n",
    "    if isinstance(value, str):\n",
    "        # allow comma-separated strings\n",
    "        parts = [p.strip() for p in value.split(',')]\n",
    "        return [normalize_name(p) for p in parts if p]\n",
    "    return []\n",
    "\n",
    "DB_CATEGORIES_BY_NORM: Dict[str, List[str]] = {}\n",
    "DB_FETCH_STATUS = 'skipped'\n",
    "try:\n",
    "    if SUPABASE_URL and SUPABASE_ANON_KEY:\n",
    "        # Try a conservative select first; if schema differs, fall back to '*'\n",
    "        rows = []\n",
    "        try:\n",
    "            rows = _postgrest_get('drug_profiles', 'substance,categories')\n",
    "        except Exception:\n",
    "            rows = _postgrest_get('drug_profiles', '*')\n",
    "        for row in rows:\n",
    "            if not isinstance(row, dict):\n",
    "                continue\n",
    "            key = _extract_row_key(row)\n",
    "            if not key:\n",
    "                continue\n",
    "            cats = _normalize_categories(row.get('categories'))\n",
    "            if not cats:\n",
    "                continue\n",
    "            n = apply_alias(key)\n",
    "            if is_excluded(n):\n",
    "                continue\n",
    "            DB_CATEGORIES_BY_NORM[normalize_name(n)] = cats\n",
    "        DB_FETCH_STATUS = f'ok ({len(DB_CATEGORIES_BY_NORM)} rows)'\n",
    "    else:\n",
    "        DB_FETCH_STATUS = 'missing SUPABASE_URL/SUPABASE_ANON_KEY'\n",
    "except Exception as e:\n",
    "    DB_FETCH_STATUS = f'error: {type(e).__name__}: {e}'\n",
    "    DB_CATEGORIES_BY_NORM = {}\n",
    "\n",
    "def get_categories_for(drugs_key: str, entry: dict) -> List[str]:\n",
    "    \"\"\"Return categories using DB override when available; otherwise fall back to drugs.json.\"\"\"\n",
    "    n = normalize_name(drugs_key)\n",
    "    if n in DB_CATEGORIES_BY_NORM:\n",
    "        return DB_CATEGORIES_BY_NORM[n]\n",
    "    cats = entry.get('categories') or []\n",
    "    return [normalize_name(c) for c in cats if isinstance(c, str)]\n",
    "\n",
    "print('✓ Supabase category refresh:', DB_FETCH_STATUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "010cbe50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Feature extractor ready\n"
     ]
    }
   ],
   "source": [
    "def norm(s: str) -> str:\n",
    "    return (s or '').strip().lower()\n",
    "\n",
    "def _iter_str_list(x) -> List[str]:\n",
    "    if isinstance(x, list):\n",
    "        return [norm(v) for v in x if isinstance(v, str)]\n",
    "    return []\n",
    "\n",
    "def extract_features(substance: str, entry: dict) -> Dict[str, float]:\n",
    "    feats: Dict[str, float] = {}\n",
    "\n",
    "    # Categories are the most stable structured signal we have (DB-refreshed when available).\n",
    "    for c in get_categories_for(substance, entry):\n",
    "        feats[f'cat:{c}'] = 1.0\n",
    "\n",
    "    # PsychonautWiki effect keys (structured-ish, useful for mechanism hints)\n",
    "    pwe = entry.get('pweffects') or {}\n",
    "    if isinstance(pwe, dict):\n",
    "        for k in pwe.keys():\n",
    "            if isinstance(k, str):\n",
    "                feats[f'pwe:{norm(k)}'] = 1.0\n",
    "\n",
    "    # Formatted effects list (e.g., Sedative, Stimulation)\n",
    "    for fx in _iter_str_list(entry.get('formatted_effects')):\n",
    "        feats[f'fx:{fx}'] = 1.0\n",
    "\n",
    "    # Minimal parsing from properties.avoid (warning-like field)\n",
    "    props = entry.get('properties') or {}\n",
    "    if isinstance(props, dict):\n",
    "        avoid = props.get('avoid')\n",
    "        if isinstance(avoid, str):\n",
    "            a = norm(avoid)\n",
    "            if 'cns depressant' in a:\n",
    "                feats['warn:cns_depressant'] = 1.0\n",
    "            if 'serotonergic' in a:\n",
    "                feats['warn:serotonergic'] = 1.0\n",
    "            if 'maoi' in a:\n",
    "                feats['warn:maoi'] = 1.0\n",
    "\n",
    "    return feats\n",
    "\n",
    "print('✓ Feature extractor ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "839cd44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Heuristic prior ready\n"
     ]
    }
   ],
   "source": [
    "# Heuristic prior: fast rule-based mapping from categories/effects -> bucket weights\n",
    "# These priors do most of the work; ML learns residual corrections against inspo.json.\n",
    "PRIOR_KEYWORDS = {\n",
    "    'stimulant': [\n",
    "        'stimulant', 'dopamine', 'norepinephrine', 'adrenergic', 'amphetamine', 'cathinone',\n",
    "        'pwe:stimulation', 'fx:stimulation',\n",
    "    ],\n",
    "    'serotonin_release': [\n",
    "        'entactogen', 'empathogen', 'serotonin', 'mdma', 'mda',\n",
    "        'pwe:empathy, love, and sociability enhancement',\n",
    "        'fx:empathy',\n",
    "        'warn:serotonergic',\n",
    "    ],\n",
    "    'serotonin_psychedelic': [\n",
    "        'psychedelic', 'tryptamine', 'lysergamide', 'phenethylamine', '5-ht2a',\n",
    "        'pwe:hallucinations', 'fx:hallucinations',\n",
    "    ],\n",
    "    'gaba': [\n",
    "        'benzodiazepine', 'benzo', 'z-drug', 'depressant', 'sedative', 'gaba',\n",
    "        'pwe:sedation', 'fx:sedative', 'fx:hypnotic',\n",
    "        'warn:cns_depressant',\n",
    "    ],\n",
    "    'opioid': [\n",
    "        'opioid', 'opiate', 'pwe:respiratory depression',\n",
    "    ],\n",
    "    'nmda': [\n",
    "        'dissociative', 'nmda', 'ketamine',\n",
    "        'pwe:dissociation',\n",
    "    ],\n",
    "    'cannabinoid': [\n",
    "        'cannabinoid', 'thc', 'cannabis',\n",
    "    ],\n",
    "}\n",
    "\n",
    "def heuristic_prior(substance: str, entry: dict) -> np.ndarray:\n",
    "    feats = extract_features(substance, entry)\n",
    "    # Token set: feature keys + raw cat values + raw name string\n",
    "    tokens = set(feats.keys())\n",
    "    tokens |= {k.split(':', 1)[1] for k in feats.keys() if k.startswith('cat:')}\n",
    "    tokens.add(norm(substance))\n",
    "    w = np.zeros(len(BUCKETS), dtype=float)\n",
    "    for i, b in enumerate(BUCKETS):\n",
    "        kws = PRIOR_KEYWORDS.get(b, [])\n",
    "        score = 0\n",
    "        for kw in kws:\n",
    "            if kw in tokens:\n",
    "                score += 2 if (kw.startswith('pwe:') or kw.startswith('fx:') or kw.startswith('warn:')) else 1\n",
    "        # convert score -> weight\n",
    "        if score >= 3:\n",
    "            w[i] = 1.0\n",
    "        elif score == 2:\n",
    "            w[i] = 0.7\n",
    "        elif score == 1:\n",
    "            w[i] = 0.4\n",
    "        else:\n",
    "            w[i] = 0.0\n",
    "    return w\n",
    "\n",
    "print('✓ Heuristic prior ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "050fcb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Training rows: 117\n",
      "Missing inspo entries in drugs.json: ['4-pmc', 'alpha-pbp']\n",
      "Excluded inspo entries (yaml exclude): ['2-nmc', 'apap', 'db-mdbp', 'oxiracetam']\n",
      "Target buckets: ['stimulant', 'serotonin_release', 'serotonin_psychedelic', 'gaba', 'opioid', 'nmda', 'cannabinoid']\n"
     ]
    }
   ],
   "source": [
    "# Build supervised training set from inspo.json\n",
    "inspo_substances = inspo.get('substances') or {}\n",
    "train_names = sorted([k for k in inspo_substances.keys() if isinstance(k, str)])\n",
    "\n",
    "# Optional manual mapping for inspo naming quirks -> drugs.json naming\n",
    "INSPO_TO_DRUGS_ALIASES = {\n",
    "    'dxm': 'dextromethorphan',\n",
    "    'psilocybin': 'psilocin',\n",
    "    'thc': 'cannabis',\n",
    "}\n",
    "\n",
    "def resolve_inspo_name_to_drugs_key(name: str) -> Optional[str]:\n",
    "    n = normalize_name(name)\n",
    "    n = INSPO_TO_DRUGS_ALIASES.get(n, n)\n",
    "    n = apply_alias(n)\n",
    "    if is_excluded(n):\n",
    "        return None\n",
    "    # direct hit\n",
    "    direct = resolve_drugs_key(n)\n",
    "    if direct is not None:\n",
    "        return direct\n",
    "    # group fallback: use canonical or any member that exists in drugs.json\n",
    "    gid = tolerance_group_id(n)\n",
    "    if gid is not None:\n",
    "        g = TOL_GROUPS.get(gid) or {}\n",
    "        canon = g.get('canonical')\n",
    "        if isinstance(canon, str):\n",
    "            hit = resolve_drugs_key(canon)\n",
    "            if hit is not None:\n",
    "                return hit\n",
    "        for m in (g.get('members') or []):\n",
    "            if isinstance(m, str):\n",
    "                hit = resolve_drugs_key(m)\n",
    "                if hit is not None:\n",
    "                    return hit\n",
    "    return None\n",
    "\n",
    "def target_vector_from_inspo(substance: str) -> np.ndarray:\n",
    "    obj = inspo_substances.get(substance) or {}\n",
    "    nb = obj.get('neuro_buckets') or {}\n",
    "    y = np.zeros(len(BUCKETS), dtype=float)\n",
    "    if isinstance(nb, dict):\n",
    "        for i, b in enumerate(BUCKETS):\n",
    "            if b in nb and isinstance(nb[b], dict):\n",
    "                w = nb[b].get('weight', 0.0)\n",
    "                if isinstance(w, (int, float)):\n",
    "                    y[i] = float(w)\n",
    "    return np.clip(y, 0.0, 1.0)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "prior = []\n",
    "missing_from_drugs = []\n",
    "excluded_from_training = []\n",
    "for s in train_names:\n",
    "    s_key = resolve_inspo_name_to_drugs_key(s)\n",
    "    if s_key is None:\n",
    "        # either excluded or not found\n",
    "        if is_excluded(s):\n",
    "            excluded_from_training.append(s)\n",
    "        else:\n",
    "            missing_from_drugs.append(s)\n",
    "        continue\n",
    "    entry = drugs_raw[s_key]\n",
    "    X.append(extract_features(s_key, entry))\n",
    "    y.append(target_vector_from_inspo(s))\n",
    "    prior.append(heuristic_prior(s_key, entry))\n",
    "\n",
    "X = list(X)\n",
    "y = np.vstack(y) if y else np.zeros((0, len(BUCKETS)))\n",
    "prior = np.vstack(prior) if prior else np.zeros((0, len(BUCKETS)))\n",
    "print('✓ Training rows:', len(X))\n",
    "print('Missing inspo entries in drugs.json:', missing_from_drugs)\n",
    "print('Excluded inspo entries (yaml exclude):', excluded_from_training)\n",
    "print('Target buckets:', BUCKETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "62787509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Trained residual model\n",
      "Mean MAE vs inspo: 0.04932683479552811\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>substance</th>\n",
       "      <th>drugs_key</th>\n",
       "      <th>mae</th>\n",
       "      <th>true:stimulant</th>\n",
       "      <th>pred:stimulant</th>\n",
       "      <th>true:serotonin_release</th>\n",
       "      <th>pred:serotonin_release</th>\n",
       "      <th>true:serotonin_psychedelic</th>\n",
       "      <th>pred:serotonin_psychedelic</th>\n",
       "      <th>true:gaba</th>\n",
       "      <th>pred:gaba</th>\n",
       "      <th>true:opioid</th>\n",
       "      <th>pred:opioid</th>\n",
       "      <th>true:nmda</th>\n",
       "      <th>pred:nmda</th>\n",
       "      <th>true:cannabinoid</th>\n",
       "      <th>pred:cannabinoid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>dimemebfe</td>\n",
       "      <td>dimemebfe</td>\n",
       "      <td>0.289040</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.039195</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.395491</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.585536</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2-mppp</td>\n",
       "      <td>2-mppp</td>\n",
       "      <td>0.259301</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.888969</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.029190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006289</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.135831</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>marinol</td>\n",
       "      <td>marinol</td>\n",
       "      <td>0.222411</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.068499</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.095186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.449037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.102116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>mbdb</td>\n",
       "      <td>mbdb</td>\n",
       "      <td>0.180361</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.775769</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.429801</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.075151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>5f-pb-22</td>\n",
       "      <td>5f-pb-22</td>\n",
       "      <td>0.175855</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.216125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.009705</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.099742</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.205753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>ab-chminaca</td>\n",
       "      <td>ab-chminaca</td>\n",
       "      <td>0.175855</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.216125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.009705</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.099742</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.205753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>mdai</td>\n",
       "      <td>mdai</td>\n",
       "      <td>0.170410</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.573522</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.547516</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.286863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>ethylcathinone</td>\n",
       "      <td>ethylcathinone</td>\n",
       "      <td>0.149224</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.621955</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.153957</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.512564</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>fluorophenibut</td>\n",
       "      <td>fluorophenibut</td>\n",
       "      <td>0.137283</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.099635</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.022639</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.455411</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.190624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>butyrfentanyl</td>\n",
       "      <td>butyrfentanyl</td>\n",
       "      <td>0.128726</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.066520</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.023180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.528264</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.785041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3-meo-pcpy</td>\n",
       "      <td>3-meo-pcpy</td>\n",
       "      <td>0.120742</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.069254</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.016094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.424186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044390</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.741354</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>u-49900</td>\n",
       "      <td>u-49900</td>\n",
       "      <td>0.116724</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.067985</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.003491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.745271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.490863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4,4-dmar</td>\n",
       "      <td>4,4-dmar</td>\n",
       "      <td>0.113553</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.695665</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.414202</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021607</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>mdma</td>\n",
       "      <td>mdma</td>\n",
       "      <td>0.102271</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.545934</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.825996</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.285078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>ethyl-pentedrone</td>\n",
       "      <td>ethyl-pentedrone</td>\n",
       "      <td>0.091433</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.744632</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.370004</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014660</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2-chloro-ephenidine</td>\n",
       "      <td>2-chloro-ephenidine</td>\n",
       "      <td>0.089043</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.109661</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.069795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032808</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.646289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>5-apdb</td>\n",
       "      <td>5-apdb</td>\n",
       "      <td>0.088441</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.421883</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.673698</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.165129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>5-meo-dipt</td>\n",
       "      <td>5-meo-dipt</td>\n",
       "      <td>0.087967</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.277889</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.687042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>parafluorofentanyl</td>\n",
       "      <td>parafluorofentanyl</td>\n",
       "      <td>0.084751</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.057960</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.183097</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.771350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.123069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>bupropion</td>\n",
       "      <td>bupropion</td>\n",
       "      <td>0.077258</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.639213</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.086333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>6-apb</td>\n",
       "      <td>6-apb</td>\n",
       "      <td>0.069844</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.210133</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.836425</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.110622</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2-fdck</td>\n",
       "      <td>2-fdck</td>\n",
       "      <td>0.069031</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.060694</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.009611</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030700</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.703423</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>halothane</td>\n",
       "      <td>halothane</td>\n",
       "      <td>0.066148</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.068499</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.095186</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.449037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.102116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>doc</td>\n",
       "      <td>doc</td>\n",
       "      <td>0.063615</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.551273</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.004946</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.857124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>dexedrine</td>\n",
       "      <td>dexedrine</td>\n",
       "      <td>0.063083</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.691728</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.080413</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048236</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004661</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               substance            drugs_key       mae  true:stimulant  \\\n",
       "65             dimemebfe            dimemebfe  0.289040            1.00   \n",
       "17                2-mppp               2-mppp  0.259301            0.00   \n",
       "91               marinol              marinol  0.222411            0.00   \n",
       "92                  mbdb                 mbdb  0.180361            0.10   \n",
       "43              5f-pb-22             5f-pb-22  0.175855            0.00   \n",
       "46           ab-chminaca          ab-chminaca  0.175855            0.00   \n",
       "93                  mdai                 mdai  0.170410            0.12   \n",
       "76        ethylcathinone       ethylcathinone  0.149224            1.00   \n",
       "77        fluorophenibut       fluorophenibut  0.137283            0.00   \n",
       "54         butyrfentanyl        butyrfentanyl  0.128726            0.00   \n",
       "31            3-meo-pcpy           3-meo-pcpy  0.120742            0.00   \n",
       "115              u-49900              u-49900  0.116724            0.00   \n",
       "33              4,4-dmar             4,4-dmar  0.113553            1.00   \n",
       "94                  mdma                 mdma  0.102271            0.35   \n",
       "75      ethyl-pentedrone     ethyl-pentedrone  0.091433            1.00   \n",
       "6    2-chloro-ephenidine  2-chloro-ephenidine  0.089043            0.00   \n",
       "39                5-apdb               5-apdb  0.088441            0.15   \n",
       "40            5-meo-dipt           5-meo-dipt  0.087967            0.00   \n",
       "104   parafluorofentanyl   parafluorofentanyl  0.084751            0.00   \n",
       "53             bupropion            bupropion  0.077258            0.20   \n",
       "44                 6-apb                6-apb  0.069844            0.00   \n",
       "9                 2-fdck               2-fdck  0.069031            0.00   \n",
       "83             halothane            halothane  0.066148            0.00   \n",
       "66                   doc                  doc  0.063615            0.15   \n",
       "63             dexedrine            dexedrine  0.063083            1.00   \n",
       "\n",
       "     pred:stimulant  true:serotonin_release  pred:serotonin_release  \\\n",
       "65         0.039195                    0.00                0.395491   \n",
       "17         0.888969                    0.00                0.000000   \n",
       "91         0.068499                    0.00                0.000000   \n",
       "92         0.775769                    0.90                0.429801   \n",
       "43         0.216125                    0.00                0.009705   \n",
       "46         0.216125                    0.00                0.009705   \n",
       "93         0.573522                    1.00                0.547516   \n",
       "76         0.621955                    0.00                0.153957   \n",
       "77         0.099635                    0.00                0.000000   \n",
       "54         0.066520                    0.00                0.000000   \n",
       "31         0.069254                    0.00                0.001900   \n",
       "115        0.067985                    0.00                0.000000   \n",
       "33         0.695665                    0.00                0.414202   \n",
       "94         0.545934                    1.00                0.825996   \n",
       "75         0.744632                    0.00                0.370004   \n",
       "6          0.109661                    0.00                0.000000   \n",
       "39         0.421883                    0.85                0.673698   \n",
       "40         0.000000                    0.00                0.277889   \n",
       "104        0.057960                    0.00                0.000483   \n",
       "53         0.639213                    0.00                0.086333   \n",
       "44         0.210133                    1.00                0.836425   \n",
       "9          0.060694                    0.00                0.009611   \n",
       "83         0.068499                    0.00                0.000000   \n",
       "66         0.551273                    0.00                0.004946   \n",
       "63         0.691728                    0.00                0.080413   \n",
       "\n",
       "     true:serotonin_psychedelic  pred:serotonin_psychedelic  true:gaba  \\\n",
       "65                         0.00                    0.585536        0.0   \n",
       "17                         0.00                    0.029190        0.0   \n",
       "91                         0.00                    0.095186        0.0   \n",
       "92                         0.00                    0.000000        0.0   \n",
       "43                         0.00                    0.099742        0.0   \n",
       "46                         0.00                    0.099742        0.0   \n",
       "93                         0.00                    0.286863        0.0   \n",
       "76                         0.00                    0.512564        0.0   \n",
       "77                         0.00                    0.022639        1.0   \n",
       "54                         0.00                    0.023180        0.0   \n",
       "31                         0.00                    0.016094        0.0   \n",
       "115                        0.00                    0.003491        0.0   \n",
       "33                         0.00                    0.000000        0.0   \n",
       "94                         0.00                    0.285078        0.0   \n",
       "75                         0.00                    0.000000        0.0   \n",
       "6                          0.00                    0.069795        0.0   \n",
       "39                         0.00                    0.165129        0.0   \n",
       "40                         1.00                    0.687042        0.0   \n",
       "104                        0.00                    0.000000        0.0   \n",
       "53                         0.00                    0.000000        0.0   \n",
       "44                         0.00                    0.110622        0.0   \n",
       "9                          0.00                    0.000000        0.0   \n",
       "83                         0.00                    0.095186        0.6   \n",
       "66                         0.85                    0.857124        0.0   \n",
       "63                         0.00                    0.000000        0.0   \n",
       "\n",
       "     pred:gaba  true:opioid  pred:opioid  true:nmda  pred:nmda  \\\n",
       "65    0.000000          0.0     0.021844        0.0   0.000550   \n",
       "17    0.006289          1.0     0.135831        0.0   0.003864   \n",
       "91    0.449037          0.0     0.046271        0.0   0.000000   \n",
       "92    0.000000          0.0     0.027276        0.0   0.014134   \n",
       "43    0.000000          0.0     0.052735        0.0   0.058429   \n",
       "46    0.000000          0.0     0.052735        0.0   0.058429   \n",
       "93    0.000000          0.0     0.000000        0.0   0.000000   \n",
       "76    0.000000          0.0     0.000000        0.0   0.000000   \n",
       "77    0.455411          0.0     0.058888        0.0   0.044605   \n",
       "54    0.528264          1.0     0.785041        0.0   0.000000   \n",
       "31    0.424186          0.0     0.044390        1.0   0.741354   \n",
       "115   0.000000          1.0     0.745271        0.0   0.490863   \n",
       "33    0.027224          0.0     0.012551        0.0   0.021607   \n",
       "94    0.060879          0.0     0.000000        0.0   0.000000   \n",
       "75    0.000000          0.0     0.014660        0.0   0.000000   \n",
       "6     0.000000          0.0     0.032808        1.0   0.646289   \n",
       "39    0.000000          0.0     0.000000        0.0   0.005770   \n",
       "40    0.000000          0.0     0.000000        0.0   0.001628   \n",
       "104   0.183097          1.0     0.771350        0.0   0.000000   \n",
       "53    0.006283          0.0     0.000000        0.0   0.008977   \n",
       "44    0.000000          0.0     0.000000        0.0   0.004577   \n",
       "9     0.000000          0.0     0.030700        1.0   0.703423   \n",
       "83    0.449037          0.0     0.046271        0.0   0.000000   \n",
       "66    0.031959          0.0     0.000000        0.0   0.000000   \n",
       "63    0.048236          0.0     0.000000        0.0   0.004661   \n",
       "\n",
       "     true:cannabinoid  pred:cannabinoid  \n",
       "65                0.0          0.059056  \n",
       "17                0.0          0.022629  \n",
       "91                1.0          0.102116  \n",
       "92                0.0          0.075151  \n",
       "43                1.0          0.205753  \n",
       "46                1.0          0.205753  \n",
       "93                0.0          0.000000  \n",
       "76                0.0          0.000000  \n",
       "77                0.0          0.190624  \n",
       "54                0.0          0.068158  \n",
       "31                0.0          0.030722  \n",
       "115               0.0          0.000000  \n",
       "33                0.0          0.014952  \n",
       "94                0.0          0.000000  \n",
       "75                0.0          0.000000  \n",
       "6                 0.0          0.057324  \n",
       "39                0.0          0.000000  \n",
       "40                0.0          0.023298  \n",
       "104               0.0          0.123069  \n",
       "53                0.0          0.000000  \n",
       "44                0.0          0.000000  \n",
       "9                 0.0          0.085633  \n",
       "83                0.0          0.102116  \n",
       "66                0.0          0.000000  \n",
       "63                0.0          0.000000  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train residual model: predicts (target - heuristic_prior) from drugs.json features\n",
    "# We disable intercept so unknown/unseen feature rows don't get a drifting baseline residual.\n",
    "residual = y - prior\n",
    "\n",
    "model: Pipeline = Pipeline([\n",
    "    ('vec', DictVectorizer(sparse=True)),\n",
    "    ('reg', MultiOutputRegressor(Ridge(alpha=2.0, fit_intercept=False, random_state=RANDOM_STATE))),\n",
    "])\n",
    "model.fit(X, residual)\n",
    "print('✓ Trained residual model')\n",
    "\n",
    "BUCKET_INDEX = {b: i for i, b in enumerate(BUCKETS)}\n",
    "\n",
    "def is_benzodiazepine_category(drugs_key: str) -> bool:\n",
    "    entry = drugs_raw.get(drugs_key) or {}\n",
    "    cats = set(get_categories_for(drugs_key, entry))\n",
    "    return ('benzodiazepine' in cats) or ('benzodiazepines' in cats)\n",
    "\n",
    "def predict_weights(drugs_key: str) -> np.ndarray:\n",
    "    k = normalize_name(drugs_key)\n",
    "    if is_excluded(k):\n",
    "        return np.zeros(len(BUCKETS), dtype=float)\n",
    "    entry = drugs_raw.get(drugs_key) or {}\n",
    "    p = heuristic_prior(drugs_key, entry)\n",
    "    r = model.predict([extract_features(drugs_key, entry)])[0]\n",
    "    w = np.clip(p + r, 0.0, 1.0)\n",
    "\n",
    "    # Rule: if category includes Benzodiazepine, only allow GABA bucket\n",
    "    if is_benzodiazepine_category(drugs_key) and 'gaba' in BUCKET_INDEX:\n",
    "        gaba_i = BUCKET_INDEX['gaba']\n",
    "        gaba_w = float(w[gaba_i])\n",
    "        w2 = np.zeros(len(BUCKETS), dtype=float)\n",
    "        w2[gaba_i] = np.clip(gaba_w if gaba_w > 0 else 0.7, 0.0, 1.0)\n",
    "        w = w2\n",
    "\n",
    "    if float(w.max()) <= 0.0:\n",
    "        idx = int(np.argmax(p)) if float(p.max()) > 0 else 0\n",
    "        w[idx] = 0.1\n",
    "    return w\n",
    "\n",
    "def eval_against_inspo() -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for s in train_names:\n",
    "        s_key = resolve_inspo_name_to_drugs_key(s)\n",
    "        if s_key is None:\n",
    "            continue\n",
    "        y_true = target_vector_from_inspo(s)\n",
    "        y_pred = predict_weights(s_key)\n",
    "        row = {'substance': s, 'drugs_key': s_key, 'mae': float(np.mean(np.abs(y_true - y_pred)))}\n",
    "        for i, b in enumerate(BUCKETS):\n",
    "            row[f'true:{b}'] = float(y_true[i])\n",
    "            row[f'pred:{b}'] = float(y_pred[i])\n",
    "        rows.append(row)\n",
    "    return pd.DataFrame(rows).sort_values('mae', ascending=False)\n",
    "\n",
    "df_eval = eval_against_inspo()\n",
    "print('Mean MAE vs inspo:', float(df_eval['mae'].mean()) if len(df_eval) else None)\n",
    "df_eval.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "484c1a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Export substances (after exclude + alias de-dup): 525\n",
      "Default anchor weight from rules: 1.0\n",
      "Generating output for anchor weight: 0.5\n",
      "✓ Wrote C:\\Users\\USER\\dev\\code\\mobile_drug_use_app\\backend\\ML\\drug_tolerance_model\\outputs\\tolerance_neuro_buckets_0.5.json\n",
      "Generating output for anchor weight: 1.0\n",
      "✓ Wrote C:\\Users\\USER\\dev\\code\\mobile_drug_use_app\\backend\\ML\\drug_tolerance_model\\outputs\\tolerance_neuro_buckets_1.0.json\n",
      "Generating output for anchor weight: 2.0\n",
      "✓ Wrote C:\\Users\\USER\\dev\\code\\mobile_drug_use_app\\backend\\ML\\drug_tolerance_model\\outputs\\tolerance_neuro_buckets_2.0.json\n",
      "Done generating all requested variations.\n"
     ]
    }
   ],
   "source": [
    "# Export: neuro_buckets for all substances (JSONB-ready)\n",
    "import re\n",
    "import yaml\n",
    "\n",
    "DEFAULT_TOLERANCE_PARAMS = {\n",
    "    'half_life_hours': 12.0,\n",
    "    'active_threshold': 0.05,\n",
    "    'standard_unit': {'value': 10.0, 'unit': 'mg'},\n",
    "    'potency_multiplier': 1.0,\n",
    "    'duration_multiplier': 1.2,\n",
    "    'tolerance_gain_rate': 0.25,\n",
    "    'tolerance_decay_days': 5.0,\n",
    "}\n",
    "\n",
    "def parse_half_life_hours_from_drugs(entry: dict) -> Optional[float]:\n",
    "    \"\"\"Best-effort parse of drugs.json properties['half-life'] into hours.\"\"\"\n",
    "    props = entry.get('properties') or {}\n",
    "    if not isinstance(props, dict):\n",
    "        return None\n",
    "    hl = props.get('half-life') or props.get('half_life')\n",
    "    if not isinstance(hl, str):\n",
    "        return None\n",
    "    s = hl.strip().lower()\n",
    "    if not s:\n",
    "        return None\n",
    "    # Extract 1-2 numbers; if range, average\n",
    "    nums = [float(x) for x in re.findall(r'\\d+(?:\\.\\d+)?', s)[:2]]\n",
    "    if not nums:\n",
    "        return None\n",
    "    value = nums[0] if len(nums) == 1 else (nums[0] + nums[1]) / 2.0\n",
    "    # Unit handling\n",
    "    if 'minute' in s or 'min' in s:\n",
    "        return value / 60.0\n",
    "    if 'day' in s:\n",
    "        return value * 24.0\n",
    "    if 'hour' in s or 'hr' in s:\n",
    "        return value\n",
    "    # Unknown unit: assume hours only if the string mentions half-life in hours-like context\n",
    "    return None\n",
    "\n",
    "def parse_standard_unit_from_drugs(entry: dict) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Parse formatted_dose to find a 'Common' or 'Light' dose to use as standard unit.\n",
    "    Returns {'value': float, 'unit': str} or None.\n",
    "    \"\"\"\n",
    "    formatted = entry.get('formatted_dose') or {}\n",
    "    if not isinstance(formatted, dict):\n",
    "        return None\n",
    "    \n",
    "    # Priority: Oral -> Insufflated -> First Available\n",
    "    roa_data = formatted.get('Oral')\n",
    "    if not roa_data:\n",
    "        roa_data = formatted.get('Insufflated')\n",
    "    if not roa_data and formatted:\n",
    "        roa_data = formatted[list(formatted.keys())[0]]\n",
    "        \n",
    "    if not isinstance(roa_data, dict):\n",
    "        return None\n",
    "        \n",
    "    # Priority: Common -> Light -> Strong -> Threshold\n",
    "    dose_str = roa_data.get('Common') or roa_data.get('Light') or roa_data.get('Strong') or roa_data.get('Threshold')\n",
    "    if not isinstance(dose_str, str):\n",
    "        return None\n",
    "        \n",
    "    # Regex to extract range and unit\n",
    "    # Matches: \"50-100ug\", \"10mg\", \"1.5ml\", \"1 - 2 g\"\n",
    "    # Group 1: Min, Group 2: Max (optional), Group 3: Unit\n",
    "    match = re.search(r'([\\d\\.]+)(?:\\s*-\\s*([\\d\\.]+))?\\s*([a-zA-Zµ]+)', dose_str)\n",
    "    if not match:\n",
    "        return None\n",
    "        \n",
    "    val_min = float(match.group(1))\n",
    "    val_max = float(match.group(2)) if match.group(2) else val_min\n",
    "    unit = match.group(3).lower()\n",
    "    \n",
    "    # Normalize Unit\n",
    "    if unit in ['ug', 'µg', 'mcg']:\n",
    "        unit = 'mcg'\n",
    "    elif unit in ['g', 'gram', 'grams']:\n",
    "        unit = 'g'\n",
    "    elif unit in ['mg', 'milligram', 'milligrams']:\n",
    "        unit = 'mg'\n",
    "    elif unit in ['ml', 'milliliter', 'milliliters']:\n",
    "        unit = 'ml'\n",
    "    elif unit in ['oz']:\n",
    "        unit = 'oz' # Keep as is, or convert? standard_unit usually implies metric. \n",
    "                     # But let's keep what's in drugs.json for now to allow user interpretation.\n",
    "    \n",
    "    avg_val = (val_min + val_max) / 2.0\n",
    "    return {'value': round(avg_val, 4), 'unit': unit}\n",
    "\n",
    "def build_export_substances() -> List[str]:\n",
    "    \"\"\"\n",
    "    Build export list from drugs.json, applying YAML excludes and alias de-duplication.\n",
    "    \"\"\"\n",
    "    out: List[str] = []\n",
    "    seen = set()\n",
    "    for k in sorted(drugs_raw.keys()):\n",
    "        n = normalize_name(k)\n",
    "        if not n or is_excluded(n):\n",
    "            continue\n",
    "        # alias de-dup: if this key is an alias and its target exists, skip this key\n",
    "        if n in TOL_ALIAS_MAP:\n",
    "            target = TOL_ALIAS_MAP[n]\n",
    "            if target in DRUG_KEY_BY_NORM and not is_excluded(target):\n",
    "                continue\n",
    "        if n in seen:\n",
    "            continue\n",
    "        seen.add(n)\n",
    "        out.append(DRUG_KEY_BY_NORM.get(n, k))\n",
    "    return out\n",
    "\n",
    "BUCKET_INDEX = {b: i for i, b in enumerate(BUCKETS)}\n",
    "\n",
    "def weights_to_neuro_buckets(\n",
    "    w: np.ndarray,\n",
    "    *,\n",
    "    threshold: float = 0.05,\n",
    "    allowed_buckets: Optional[set] = None,\n",
    " ) -> Dict[str, dict]:\n",
    "    \"\"\"\n",
    "    Convert weight vector -> neuro_buckets map.\n",
    "    \"\"\"\n",
    "    out: Dict[str, dict] = {}\n",
    "    eps = 0.001\n",
    "    if allowed_buckets is None:\n",
    "        idx_sorted = list(np.argsort(w)[::-1])\n",
    "        for i in idx_sorted:\n",
    "            wi = float(w[i])\n",
    "            if wi >= threshold:\n",
    "                b = BUCKETS[i]\n",
    "                out[b] = {'weight': round(wi, 3), 'tolerance_type': b}\n",
    "    else:\n",
    "        # deterministic order: use BUCKETS order\n",
    "        for b in BUCKETS:\n",
    "            if b not in allowed_buckets:\n",
    "                continue\n",
    "            wi = float(w[BUCKET_INDEX[b]])\n",
    "            if wi <= 0.0:\n",
    "                wi = eps\n",
    "            # keep present even if below threshold\n",
    "            out[b] = {'weight': round(wi, 3), 'tolerance_type': b}\n",
    "\n",
    "    if not out:\n",
    "        # fallback: keep at least one bucket\n",
    "        i = int(np.argmax(w))\n",
    "        b = BUCKETS[i]\n",
    "        out[b] = {'weight': round(max(float(w[i]), 0.1), 3), 'tolerance_type': b}\n",
    "    return out\n",
    "\n",
    "export_keys = build_export_substances()\n",
    "print('✓ Export substances (after exclude + alias de-dup):', len(export_keys))\n",
    "\n",
    "# Map Inspo keys to Drugs keys to help with overrides\n",
    "DRUGS_KEY_TO_INSPO = {}\n",
    "for inspo_name, inspo_data in (inspo.get('substances') or {}).items():\n",
    "    d_key = resolve_inspo_name_to_drugs_key(inspo_name)\n",
    "    if d_key:\n",
    "        DRUGS_KEY_TO_INSPO[d_key] = inspo_data\n",
    "\n",
    "# For each YAML group, choose a reference substance and compute its bucket *set*;\n",
    "GROUP_ALLOWED_BUCKETS: Dict[str, set] = {}\n",
    "for gid, g in TOL_GROUPS.items():\n",
    "    members = [m for m in (g.get('members') or []) if isinstance(m, str)]\n",
    "    canon = g.get('canonical') if isinstance(g.get('canonical'), str) else None\n",
    "    ref = None\n",
    "    if canon is not None and resolve_drugs_key(canon) in drugs_raw:\n",
    "        ref = resolve_drugs_key(canon)\n",
    "    if ref is None:\n",
    "        for m in members:\n",
    "            hit = resolve_drugs_key(m)\n",
    "            if hit is not None:\n",
    "                ref = hit\n",
    "                break\n",
    "    if ref is None:\n",
    "        continue\n",
    "    w_ref = predict_weights(ref)\n",
    "    allowed = {BUCKETS[i] for i in range(len(BUCKETS)) if float(w_ref[i]) >= 0.05}\n",
    "    if not allowed:\n",
    "        allowed = {BUCKETS[int(np.argmax(w_ref))]}\n",
    "    GROUP_ALLOWED_BUCKETS[gid] = allowed\n",
    "\n",
    "def is_same_unit(u1, u2):\n",
    "    return normalize_name(u1) == normalize_name(u2)\n",
    "\n",
    "# ---- ANCHORING LOGIC START ----\n",
    "RULES_FILE = Path('substances_rules.yaml')\n",
    "DEFAULT_ANCHOR_WEIGHT = 1.0\n",
    "if RULES_FILE.exists():\n",
    "    with open(RULES_FILE, 'r', encoding='utf-8') as f:\n",
    "        rules_data = yaml.safe_load(f) or {}\n",
    "    DEFAULT_ANCHOR_WEIGHT = float(rules_data.get('inspo_anchor', {}).get('weight', 1.0))\n",
    "\n",
    "print('Default anchor weight from rules:', DEFAULT_ANCHOR_WEIGHT)\n",
    "\n",
    "# Explicitly running for these 3 weights as requested\n",
    "ANCHOR_WEIGHTS_TO_RUN = [0.5, 1.0, 2.0]\n",
    "\n",
    "def get_inspo_vector(inspo_data: dict) -> np.ndarray:\n",
    "    nb = inspo_data.get('neuro_buckets') or {}\n",
    "    y = np.zeros(len(BUCKETS), dtype=float)\n",
    "    if isinstance(nb, dict):\n",
    "        for i, b in enumerate(BUCKETS):\n",
    "            if b in nb and isinstance(nb[b], dict):\n",
    "                w = nb[b].get('weight', 0.0)\n",
    "                if isinstance(w, (int, float)):\n",
    "                    y[i] = float(w)\n",
    "    return np.clip(y, 0.0, 1.0)\n",
    "# ---- ANCHORING LOGIC END ----\n",
    "\n",
    "for anchor_w in ANCHOR_WEIGHTS_TO_RUN:\n",
    "    print(f'Generating output for anchor weight: {anchor_w}')\n",
    "    \n",
    "    payload = {\n",
    "        'metadata': {\n",
    "            'generated_at': pd.Timestamp.utcnow().isoformat(),\n",
    "            'source_files': {\n",
    "                'drugs_json': str(DRUGS_PATH),\n",
    "                'baseline_json': str(BASELINE_PATH),\n",
    "                'inspo_json': str(INSPO_PATH),\n",
    "                'drug_interaction_yaml': str(YAML_PATH),\n",
    "                'substances_rules_yaml': str(RULES_FILE) if RULES_FILE.exists() else None,\n",
    "            },\n",
    "            'buckets': BUCKETS,\n",
    "            'yaml_config': {\n",
    "                'exclude': sorted(TOL_EXCLUDE_SET),\n",
    "                'aliases': dict(TOL_ALIAS_MAP),\n",
    "                'groups': {gid: {'canonical': g.get('canonical'), 'members': g.get('members')} for gid, g in TOL_GROUPS.items()},\n",
    "                'separate': sorted(TOL_SEPARATE_SET),\n",
    "            },\n",
    "            'default_tolerance_params': dict(DEFAULT_TOLERANCE_PARAMS),\n",
    "            'inspo_anchor': {\n",
    "                'weight': anchor_w,\n",
    "                'formula': '(inspo * weight + ml) / (weight + 1)',\n",
    "            },\n",
    "            'notes': [\n",
    "                'Bucket weights are inferred from drugs.json using a heuristic prior + residual ML fit to inspo.json.',\n",
    "                'Globally anchored to inspo priors using weighted average.',\n",
    "                'Group members share the same neuro-bucket keys; weights may differ.',\n",
    "                'Standard units are derived from drugs.json (Common/Light dose) or inspo.json.',\n",
    "            ],\n",
    "        },\n",
    "        'substances': {},\n",
    "    }\n",
    "\n",
    "    for s in export_keys:\n",
    "        gid = tolerance_group_id(s)\n",
    "        allowed = GROUP_ALLOWED_BUCKETS.get(gid) if gid is not None else None\n",
    "        entry = drugs_raw.get(s) or {}\n",
    "        \n",
    "        # 1. Get Base ML Weight (Prior + Residual)\n",
    "        w_ml = predict_weights(s)\n",
    "\n",
    "        # 2. Apply Inspo Anchoring (if inspo has data)\n",
    "        w_final = w_ml\n",
    "        if s in DRUGS_KEY_TO_INSPO:\n",
    "            w_inspo = get_inspo_vector(DRUGS_KEY_TO_INSPO[s])\n",
    "            w_final = (w_inspo * anchor_w + w_ml) / (anchor_w + 1.0)\n",
    "        \n",
    "        # 3. Convert to buckets\n",
    "        neuro = weights_to_neuro_buckets(w_final, allowed_buckets=allowed)\n",
    "\n",
    "        params = dict(DEFAULT_TOLERANCE_PARAMS)\n",
    "        \n",
    "        # 1. Half-Life\n",
    "        hl = parse_half_life_hours_from_drugs(entry)\n",
    "        if isinstance(hl, (int, float)) and float(hl) > 0:\n",
    "            params['half_life_hours'] = round(float(hl), 3)\n",
    "\n",
    "        # 2. Standard Unit\n",
    "        # Try parsing from drugs.json first\n",
    "        derived_su = parse_standard_unit_from_drugs(entry)\n",
    "        if derived_su:\n",
    "            params['standard_unit'] = derived_su\n",
    "        \n",
    "        # Check inspo for missing or correction or params\n",
    "        inspo_su = None\n",
    "        if s in DRUGS_KEY_TO_INSPO:\n",
    "            inspo_data = DRUGS_KEY_TO_INSPO[s]\n",
    "            inspo_su = inspo_data.get('standard_unit')\n",
    "            \n",
    "            # Apply potency params from inspo if available\n",
    "            for p_key in ['potency_multiplier', 'duration_multiplier', 'tolerance_gain_rate', 'tolerance_decay_days']:\n",
    "                if p_key in inspo_data and isinstance(inspo_data[p_key], (int, float)):\n",
    "                    params[p_key] = float(inspo_data[p_key])\n",
    "\n",
    "        # Standard Unit Fallback / Override\n",
    "        if inspo_su and isinstance(inspo_su, dict):\n",
    "            if not derived_su:\n",
    "                params['standard_unit'] = inspo_su\n",
    "            else:\n",
    "                # Enforce inspo for specific targets (Bupropion/Caffeine/MDMA/Ketamine)\n",
    "                s_norm = normalize_name(s)\n",
    "                if any(x in s_norm for x in ['bupropion', 'caffeine', 'mdma', 'ketamine']):\n",
    "                    params['standard_unit'] = inspo_su\n",
    "        \n",
    "        # 3. Explicit Safety Overrides for High Impact Substances\n",
    "        # Reduce potency multiplier for weak stimulants that are often used daily\n",
    "        s_norm = normalize_name(s)\n",
    "        if 'bupropion' in s_norm:\n",
    "            # Reduce to 30% impact relative to Dexedrine (1.0)\n",
    "            params['potency_multiplier'] = 0.3\n",
    "        elif 'caffeine' in s_norm:\n",
    "            # Reduce to 15% impact\n",
    "            params['potency_multiplier'] = 0.15\n",
    "\n",
    "        payload['substances'][s] = {\n",
    "            'neuro_buckets': neuro,\n",
    "            **params,\n",
    "        }\n",
    "\n",
    "    # Use unique filename per weight\n",
    "    file_weight_suffix = str(anchor_w)\n",
    "    out_file = OUTPUT_DIR / f'tolerance_neuro_buckets_{file_weight_suffix}.json'\n",
    "    \n",
    "    with open(out_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(payload, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print('✓ Wrote', out_file.resolve())\n",
    "\n",
    "print('Done generating all requested variations.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
